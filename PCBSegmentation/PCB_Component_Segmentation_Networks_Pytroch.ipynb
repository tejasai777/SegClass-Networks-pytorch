{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOgZyCGoMPY0",
        "outputId": "1a05da84-fcb0-4609-e50f-47931aa346cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/drive/MyDrive/projects/Finaldraft.zip -d /content/project_root_seg\n",
        "%cd /content/project_root_seg/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTovWOHGNOK5",
        "outputId": "538884a3-a345-4620-90ea-250f0921ba67"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/project_root_seg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import shutil\n",
        "\n",
        "# dir_path = \"/content/project_root_seg\"\n",
        "# shutil.rmtree(dir_path)  # This deletes the directory and its contents"
      ],
      "metadata": {
        "id": "nKY22jzrbJKW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Core libs\n",
        "!pip install -q torch torchvision albumentations scikit-learn opencv-python\n",
        "\n",
        "# If you included segmentation-models-pytorch for DeepLabV3+:\n",
        "!pip install -q segmentation-models-pytorch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eThVFRDfNYJj",
        "outputId": "11714f96-b88f-453a-9df5-3d91acbeac43"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m128.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m93.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m109.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/project_root_seg/Finaldraft/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJqaTUJfQg_W",
        "outputId": "e3960d2b-ea82-4e14-a775-6f2fad1d1124"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/project_root_seg/Finaldraft\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/project_root_seg/Finaldraft\n",
        "!mkdir -p outputs\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WAPVxQTdxZJ",
        "outputId": "9aae63d9-b38b-4998-a77b-bed8f4e5b644"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/project_root_seg/Finaldraft\n",
            "augmentation.py  models      __pycache__       train.py\n",
            "data\t\t network.py  README.md\t       visualize.py\n",
            "eval.py\t\t outputs     requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from inside /content/project_root_seg\n",
        "!python train.py \\\n",
        "  --model unet_vgg16 \\\n",
        "  --data-dir data \\\n",
        "  --output-dir /content/project_root_seg/Finaldraft/outputs \\\n",
        "  --img-size 640 \\\n",
        "  --batch-size 8 \\\n",
        "  --epochs 80 \\\n",
        "  --lr 1e-4 \\\n",
        "  --patience 20"
      ],
      "metadata": {
        "id": "Tnf9Ynt0NxUu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e0d331e-570b-4c11-f6a4-0126fef5a397"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:111: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "Epoch 1/80 - Train Loss: 1.0389 | Val Loss: 0.8515\n",
            "✔️ Best model saved at epoch 1\n",
            "Epoch 2/80 - Train Loss: 0.9530 | Val Loss: 0.7698\n",
            "✔️ Best model saved at epoch 2\n",
            "Epoch 3/80 - Train Loss: 0.8841 | Val Loss: 0.7186\n",
            "✔️ Best model saved at epoch 3\n",
            "Epoch 4/80 - Train Loss: 0.8407 | Val Loss: 0.6877\n",
            "✔️ Best model saved at epoch 4\n",
            "Epoch 5/80 - Train Loss: 0.8101 | Val Loss: 0.6751\n",
            "✔️ Best model saved at epoch 5\n",
            "Epoch 6/80 - Train Loss: 0.8060 | Val Loss: 0.6468\n",
            "✔️ Best model saved at epoch 6\n",
            "Epoch 7/80 - Train Loss: 0.7830 | Val Loss: 0.6263\n",
            "✔️ Best model saved at epoch 7\n",
            "Epoch 8/80 - Train Loss: 0.7572 | Val Loss: 0.6304\n",
            "Epoch 9/80 - Train Loss: 0.7716 | Val Loss: 0.8009\n",
            "Epoch 10/80 - Train Loss: 0.7559 | Val Loss: 0.5945\n",
            "✔️ Best model saved at epoch 10\n",
            "Epoch 11/80 - Train Loss: 0.7470 | Val Loss: 0.5766\n",
            "✔️ Best model saved at epoch 11\n",
            "Epoch 12/80 - Train Loss: 0.7307 | Val Loss: 0.5720\n",
            "✔️ Best model saved at epoch 12\n",
            "Epoch 13/80 - Train Loss: 0.7266 | Val Loss: 0.5641\n",
            "✔️ Best model saved at epoch 13\n",
            "Epoch 14/80 - Train Loss: 0.7103 | Val Loss: 0.5472\n",
            "✔️ Best model saved at epoch 14\n",
            "Epoch 15/80 - Train Loss: 0.7007 | Val Loss: 0.5312\n",
            "✔️ Best model saved at epoch 15\n",
            "Epoch 16/80 - Train Loss: 0.6776 | Val Loss: 0.5821\n",
            "Epoch 17/80 - Train Loss: 0.6822 | Val Loss: 0.5337\n",
            "Epoch 18/80 - Train Loss: 0.6576 | Val Loss: 0.4768\n",
            "✔️ Best model saved at epoch 18\n",
            "Epoch 19/80 - Train Loss: 0.6258 | Val Loss: 0.4691\n",
            "✔️ Best model saved at epoch 19\n",
            "Epoch 20/80 - Train Loss: 0.6230 | Val Loss: 0.4664\n",
            "✔️ Best model saved at epoch 20\n",
            "Epoch 21/80 - Train Loss: 0.6128 | Val Loss: 0.4356\n",
            "✔️ Best model saved at epoch 21\n",
            "Epoch 22/80 - Train Loss: 0.5966 | Val Loss: 0.4562\n",
            "Epoch 23/80 - Train Loss: 0.5767 | Val Loss: 0.4270\n",
            "✔️ Best model saved at epoch 23\n",
            "Epoch 24/80 - Train Loss: 0.5731 | Val Loss: 0.4328\n",
            "Epoch 25/80 - Train Loss: 0.5630 | Val Loss: 0.3992\n",
            "✔️ Best model saved at epoch 25\n",
            "Epoch 26/80 - Train Loss: 0.5314 | Val Loss: 0.3763\n",
            "✔️ Best model saved at epoch 26\n",
            "Epoch 27/80 - Train Loss: 0.5356 | Val Loss: 0.3877\n",
            "Epoch 28/80 - Train Loss: 0.5147 | Val Loss: 0.3528\n",
            "✔️ Best model saved at epoch 28\n",
            "Epoch 29/80 - Train Loss: 0.5199 | Val Loss: 0.3917\n",
            "Epoch 30/80 - Train Loss: 0.5043 | Val Loss: 0.3375\n",
            "✔️ Best model saved at epoch 30\n",
            "Epoch 31/80 - Train Loss: 0.4799 | Val Loss: 0.3229\n",
            "✔️ Best model saved at epoch 31\n",
            "Epoch 32/80 - Train Loss: 0.4604 | Val Loss: 0.3403\n",
            "Epoch 33/80 - Train Loss: 0.4600 | Val Loss: 0.3308\n",
            "Epoch 34/80 - Train Loss: 0.4569 | Val Loss: 0.3089\n",
            "✔️ Best model saved at epoch 34\n",
            "Epoch 35/80 - Train Loss: 0.4436 | Val Loss: 0.2956\n",
            "✔️ Best model saved at epoch 35\n",
            "Epoch 36/80 - Train Loss: 0.4363 | Val Loss: 0.3259\n",
            "Epoch 37/80 - Train Loss: 0.4271 | Val Loss: 0.3493\n",
            "Epoch 38/80 - Train Loss: 0.4212 | Val Loss: 0.2834\n",
            "✔️ Best model saved at epoch 38\n",
            "Epoch 39/80 - Train Loss: 0.4298 | Val Loss: 0.2922\n",
            "Epoch 40/80 - Train Loss: 0.3904 | Val Loss: 0.2746\n",
            "✔️ Best model saved at epoch 40\n",
            "Epoch 41/80 - Train Loss: 0.3775 | Val Loss: 0.2638\n",
            "✔️ Best model saved at epoch 41\n",
            "Epoch 42/80 - Train Loss: 0.3825 | Val Loss: 0.2691\n",
            "Epoch 43/80 - Train Loss: 0.3896 | Val Loss: 0.2475\n",
            "✔️ Best model saved at epoch 43\n",
            "Epoch 44/80 - Train Loss: 0.3699 | Val Loss: 0.2497\n",
            "Epoch 45/80 - Train Loss: 0.3750 | Val Loss: 0.2399\n",
            "✔️ Best model saved at epoch 45\n",
            "Epoch 46/80 - Train Loss: 0.3730 | Val Loss: 0.2263\n",
            "✔️ Best model saved at epoch 46\n",
            "Epoch 47/80 - Train Loss: 0.3465 | Val Loss: 0.2220\n",
            "✔️ Best model saved at epoch 47\n",
            "Epoch 48/80 - Train Loss: 0.3330 | Val Loss: 0.2318\n",
            "Epoch 49/80 - Train Loss: 0.3309 | Val Loss: 0.2170\n",
            "✔️ Best model saved at epoch 49\n",
            "Epoch 50/80 - Train Loss: 0.3297 | Val Loss: 0.2099\n",
            "✔️ Best model saved at epoch 50\n",
            "Epoch 51/80 - Train Loss: 0.3447 | Val Loss: 0.2128\n",
            "Epoch 52/80 - Train Loss: 0.3312 | Val Loss: 0.2042\n",
            "✔️ Best model saved at epoch 52\n",
            "Epoch 53/80 - Train Loss: 0.3237 | Val Loss: 0.2083\n",
            "Epoch 54/80 - Train Loss: 0.3147 | Val Loss: 0.1998\n",
            "✔️ Best model saved at epoch 54\n",
            "Epoch 55/80 - Train Loss: 0.3251 | Val Loss: 0.2059\n",
            "Epoch 56/80 - Train Loss: 0.3145 | Val Loss: 0.1859\n",
            "✔️ Best model saved at epoch 56\n",
            "Epoch 57/80 - Train Loss: 0.2972 | Val Loss: 0.1878\n",
            "Epoch 58/80 - Train Loss: 0.2976 | Val Loss: 0.1849\n",
            "✔️ Best model saved at epoch 58\n",
            "Epoch 59/80 - Train Loss: 0.2742 | Val Loss: 0.1855\n",
            "Epoch 60/80 - Train Loss: 0.2935 | Val Loss: 0.1857\n",
            "Epoch 61/80 - Train Loss: 0.2822 | Val Loss: 0.1682\n",
            "✔️ Best model saved at epoch 61\n",
            "Epoch 62/80 - Train Loss: 0.2666 | Val Loss: 0.1709\n",
            "Epoch 63/80 - Train Loss: 0.2636 | Val Loss: 0.1714\n",
            "Epoch 64/80 - Train Loss: 0.2653 | Val Loss: 0.1711\n",
            "Epoch 65/80 - Train Loss: 0.2663 | Val Loss: 0.1592\n",
            "✔️ Best model saved at epoch 65\n",
            "Epoch 66/80 - Train Loss: 0.2499 | Val Loss: 0.1584\n",
            "✔️ Best model saved at epoch 66\n",
            "Epoch 67/80 - Train Loss: 0.2478 | Val Loss: 0.1558\n",
            "✔️ Best model saved at epoch 67\n",
            "Epoch 68/80 - Train Loss: 0.2495 | Val Loss: 0.1446\n",
            "✔️ Best model saved at epoch 68\n",
            "Epoch 69/80 - Train Loss: 0.2331 | Val Loss: 0.1507\n",
            "Epoch 70/80 - Train Loss: 0.2242 | Val Loss: 0.1408\n",
            "✔️ Best model saved at epoch 70\n",
            "Epoch 71/80 - Train Loss: 0.2319 | Val Loss: 0.1427\n",
            "Epoch 72/80 - Train Loss: 0.2280 | Val Loss: 0.1499\n",
            "Epoch 73/80 - Train Loss: 0.2196 | Val Loss: 0.1815\n",
            "Epoch 74/80 - Train Loss: 0.2187 | Val Loss: 0.1366\n",
            "✔️ Best model saved at epoch 74\n",
            "Epoch 75/80 - Train Loss: 0.2210 | Val Loss: 0.1424\n",
            "Epoch 76/80 - Train Loss: 0.2111 | Val Loss: 0.1345\n",
            "✔️ Best model saved at epoch 76\n",
            "Epoch 77/80 - Train Loss: 0.2004 | Val Loss: 0.1413\n",
            "Epoch 78/80 - Train Loss: 0.2092 | Val Loss: 0.1373\n",
            "Epoch 79/80 - Train Loss: 0.2081 | Val Loss: 0.1263\n",
            "✔️ Best model saved at epoch 79\n",
            "Epoch 80/80 - Train Loss: 0.2022 | Val Loss: 0.1419\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.117904..2.6399999].\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.117904..2.4285712].\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.117904..2.4308496].\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.117904..2.6399999].\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.117904..2.6399999].\n",
            "Evaluation Metrics:\n",
            "pixel_accuracy: 0.9784371363863031\n",
            "precision: [0.98192015 0.90050243 0.92505233 0.8818864 ]\n",
            "recall: [0.99547786 0.77394295 0.59502418 0.25343285]\n",
            "f1_score: [0.98865252 0.83243982 0.72421157 0.39372005]\n",
            "iou: [0.97755969 0.7129738  0.56765806 0.24511298]\n",
            "dice_score: [0.98865252 0.83243982 0.72421157 0.39372005]\n",
            "Total params: 41,896,932\n",
            "Model size: 159.82 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from inside /content/project_root_seg\n",
        "!python train.py \\\n",
        "  --model attunet \\\n",
        "  --data-dir data \\\n",
        "  --output-dir /content/project_root_seg/Finaldraft/outputs \\\n",
        "  --img-size 640 \\\n",
        "  --batch-size 8 \\\n",
        "  --epochs 80 \\\n",
        "  --lr 1e-4 \\\n",
        "  --patience 20"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vt_DT6gIQZsb",
        "outputId": "66824cc6-eaac-4962-d470-e4f564979ac5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:111: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "Epoch 1/80 - Train Loss: 0.9608 | Val Loss: 0.7698\n",
            "✔️ Best model saved at epoch 1\n",
            "Epoch 2/80 - Train Loss: 0.8236 | Val Loss: 0.7700\n",
            "Epoch 3/80 - Train Loss: 0.7382 | Val Loss: 0.5916\n",
            "✔️ Best model saved at epoch 3\n",
            "Epoch 4/80 - Train Loss: 0.7044 | Val Loss: 1.2377\n",
            "Epoch 5/80 - Train Loss: 0.7060 | Val Loss: 0.5532\n",
            "✔️ Best model saved at epoch 5\n",
            "Epoch 6/80 - Train Loss: 0.6769 | Val Loss: 0.5195\n",
            "✔️ Best model saved at epoch 6\n",
            "Epoch 7/80 - Train Loss: 0.6406 | Val Loss: 0.4692\n",
            "✔️ Best model saved at epoch 7\n",
            "Epoch 8/80 - Train Loss: 0.6242 | Val Loss: 0.4722\n",
            "Epoch 9/80 - Train Loss: 0.5877 | Val Loss: 0.4271\n",
            "✔️ Best model saved at epoch 9\n",
            "Epoch 10/80 - Train Loss: 0.5832 | Val Loss: 0.4321\n",
            "Epoch 11/80 - Train Loss: 0.5679 | Val Loss: 0.4236\n",
            "✔️ Best model saved at epoch 11\n",
            "Epoch 12/80 - Train Loss: 0.5475 | Val Loss: 0.3885\n",
            "✔️ Best model saved at epoch 12\n",
            "Epoch 13/80 - Train Loss: 0.5242 | Val Loss: 0.3550\n",
            "✔️ Best model saved at epoch 13\n",
            "Epoch 14/80 - Train Loss: 0.5032 | Val Loss: 0.3353\n",
            "✔️ Best model saved at epoch 14\n",
            "Epoch 15/80 - Train Loss: 0.4689 | Val Loss: 0.3435\n",
            "Epoch 16/80 - Train Loss: 0.4674 | Val Loss: 0.3149\n",
            "✔️ Best model saved at epoch 16\n",
            "Epoch 17/80 - Train Loss: 0.4486 | Val Loss: 0.3086\n",
            "✔️ Best model saved at epoch 17\n",
            "Epoch 18/80 - Train Loss: 0.4407 | Val Loss: 0.2962\n",
            "✔️ Best model saved at epoch 18\n",
            "Epoch 19/80 - Train Loss: 0.4271 | Val Loss: 0.2947\n",
            "✔️ Best model saved at epoch 19\n",
            "Epoch 20/80 - Train Loss: 0.4147 | Val Loss: 0.2757\n",
            "✔️ Best model saved at epoch 20\n",
            "Epoch 21/80 - Train Loss: 0.4085 | Val Loss: 0.2717\n",
            "✔️ Best model saved at epoch 21\n",
            "Epoch 22/80 - Train Loss: 0.4135 | Val Loss: 0.2541\n",
            "✔️ Best model saved at epoch 22\n",
            "Epoch 23/80 - Train Loss: 0.4092 | Val Loss: 0.2528\n",
            "✔️ Best model saved at epoch 23\n",
            "Epoch 24/80 - Train Loss: 0.3749 | Val Loss: 0.2626\n",
            "Epoch 25/80 - Train Loss: 0.3642 | Val Loss: 0.2217\n",
            "✔️ Best model saved at epoch 25\n",
            "Epoch 26/80 - Train Loss: 0.3421 | Val Loss: 0.2190\n",
            "✔️ Best model saved at epoch 26\n",
            "Epoch 27/80 - Train Loss: 0.3253 | Val Loss: 0.2318\n",
            "Epoch 28/80 - Train Loss: 0.3379 | Val Loss: 0.2277\n",
            "Epoch 29/80 - Train Loss: 0.3046 | Val Loss: 0.2005\n",
            "✔️ Best model saved at epoch 29\n",
            "Epoch 30/80 - Train Loss: 0.3053 | Val Loss: 0.1998\n",
            "✔️ Best model saved at epoch 30\n",
            "Epoch 31/80 - Train Loss: 0.3041 | Val Loss: 0.1849\n",
            "✔️ Best model saved at epoch 31\n",
            "Epoch 32/80 - Train Loss: 0.2912 | Val Loss: 0.1788\n",
            "✔️ Best model saved at epoch 32\n",
            "Epoch 33/80 - Train Loss: 0.2831 | Val Loss: 0.1782\n",
            "✔️ Best model saved at epoch 33\n",
            "Epoch 34/80 - Train Loss: 0.2772 | Val Loss: 0.2042\n",
            "Epoch 35/80 - Train Loss: 0.2743 | Val Loss: 0.1919\n",
            "Epoch 36/80 - Train Loss: 0.2538 | Val Loss: 0.1600\n",
            "✔️ Best model saved at epoch 36\n",
            "Epoch 37/80 - Train Loss: 0.2516 | Val Loss: 0.1701\n",
            "Epoch 38/80 - Train Loss: 0.2641 | Val Loss: 0.2125\n",
            "Epoch 39/80 - Train Loss: 0.2447 | Val Loss: 0.1433\n",
            "✔️ Best model saved at epoch 39\n",
            "Epoch 40/80 - Train Loss: 0.2422 | Val Loss: 0.1451\n",
            "Epoch 41/80 - Train Loss: 0.2459 | Val Loss: 0.1587\n",
            "Epoch 42/80 - Train Loss: 0.2368 | Val Loss: 0.1485\n",
            "Epoch 43/80 - Train Loss: 0.2070 | Val Loss: 0.1387\n",
            "✔️ Best model saved at epoch 43\n",
            "Epoch 44/80 - Train Loss: 0.1946 | Val Loss: 0.1287\n",
            "✔️ Best model saved at epoch 44\n",
            "Epoch 45/80 - Train Loss: 0.1983 | Val Loss: 0.1282\n",
            "✔️ Best model saved at epoch 45\n",
            "Epoch 46/80 - Train Loss: 0.2084 | Val Loss: 0.1246\n",
            "✔️ Best model saved at epoch 46\n",
            "Epoch 47/80 - Train Loss: 0.2047 | Val Loss: 0.1289\n",
            "Epoch 48/80 - Train Loss: 0.1709 | Val Loss: 0.1289\n",
            "Epoch 49/80 - Train Loss: 0.1801 | Val Loss: 0.1180\n",
            "✔️ Best model saved at epoch 49\n",
            "Epoch 50/80 - Train Loss: 0.1686 | Val Loss: 0.1167\n",
            "✔️ Best model saved at epoch 50\n",
            "Epoch 51/80 - Train Loss: 0.1802 | Val Loss: 0.1141\n",
            "✔️ Best model saved at epoch 51\n",
            "Epoch 52/80 - Train Loss: 0.1747 | Val Loss: 0.1219\n",
            "Epoch 53/80 - Train Loss: 0.1624 | Val Loss: 0.1206\n",
            "Epoch 54/80 - Train Loss: 0.1639 | Val Loss: 0.1303\n",
            "Epoch 55/80 - Train Loss: 0.1540 | Val Loss: 0.1041\n",
            "✔️ Best model saved at epoch 55\n",
            "Epoch 56/80 - Train Loss: 0.1666 | Val Loss: 0.1194\n",
            "Epoch 57/80 - Train Loss: 0.1622 | Val Loss: 0.1060\n",
            "Epoch 58/80 - Train Loss: 0.1450 | Val Loss: 0.1111\n",
            "Epoch 59/80 - Train Loss: 0.1581 | Val Loss: 0.1253\n",
            "Epoch 60/80 - Train Loss: 0.1590 | Val Loss: 0.1194\n",
            "Epoch 61/80 - Train Loss: 0.1512 | Val Loss: 0.1086\n",
            "Epoch 62/80 - Train Loss: 0.1540 | Val Loss: 0.1433\n",
            "Epoch 63/80 - Train Loss: 0.1559 | Val Loss: 0.1034\n",
            "✔️ Best model saved at epoch 63\n",
            "Epoch 64/80 - Train Loss: 0.1394 | Val Loss: 0.1045\n",
            "Epoch 65/80 - Train Loss: 0.1379 | Val Loss: 0.1093\n",
            "Epoch 66/80 - Train Loss: 0.1250 | Val Loss: 0.1007\n",
            "✔️ Best model saved at epoch 66\n",
            "Epoch 67/80 - Train Loss: 0.1297 | Val Loss: 0.1274\n",
            "Epoch 68/80 - Train Loss: 0.1301 | Val Loss: 0.1096\n",
            "Epoch 69/80 - Train Loss: 0.1362 | Val Loss: 0.1178\n",
            "Epoch 70/80 - Train Loss: 0.1449 | Val Loss: 0.1090\n",
            "Epoch 71/80 - Train Loss: 0.1374 | Val Loss: 0.1338\n",
            "Epoch 72/80 - Train Loss: 0.1539 | Val Loss: 0.1135\n",
            "Epoch 73/80 - Train Loss: 0.1258 | Val Loss: 0.1063\n",
            "Epoch 74/80 - Train Loss: 0.1363 | Val Loss: 0.1110\n",
            "Epoch 75/80 - Train Loss: 0.1273 | Val Loss: 0.0996\n",
            "✔️ Best model saved at epoch 75\n",
            "Epoch 76/80 - Train Loss: 0.1255 | Val Loss: 0.1089\n",
            "Epoch 77/80 - Train Loss: 0.1167 | Val Loss: 0.1036\n",
            "Epoch 78/80 - Train Loss: 0.1186 | Val Loss: 0.1099\n",
            "Epoch 79/80 - Train Loss: 0.1293 | Val Loss: 0.1320\n",
            "Epoch 80/80 - Train Loss: 0.1081 | Val Loss: 0.1028\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.117904..2.6399999].\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.117904..2.4285712].\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.117904..2.4308496].\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.117904..2.6399999].\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.117904..2.6399999].\n",
            "Evaluation Metrics:\n",
            "pixel_accuracy: 0.9812855821974734\n",
            "precision: [0.98375639 0.93162831 0.93556999 0.84107816]\n",
            "recall: [0.99660006 0.8075126  0.61758169 0.28170005]\n",
            "f1_score: [0.99013657 0.86514162 0.74402378 0.42204553]\n",
            "iou: [0.98046582 0.76233444 0.59238684 0.26746369]\n",
            "dice_score: [0.99013657 0.86514162 0.74402378 0.42204553]\n",
            "Total params: 34,878,768\n",
            "Model size: 133.05 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from inside /content/project_root_seg\n",
        "!python train.py \\\n",
        "  --model unetpp \\\n",
        "  --data-dir data \\\n",
        "  --output-dir /content/project_root_seg/Finaldraft/outputs \\\n",
        "  --img-size 640 \\\n",
        "  --batch-size 8 \\\n",
        "  --epochs 80 \\\n",
        "  --lr 1e-4 \\\n",
        "  --patience 20"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDxkl7CbhWNn",
        "outputId": "78317ff0-ef63-4a08-ca41-f42e058d2641"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:111: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "Epoch 1/80 - Train Loss: 1.0645 | Val Loss: 0.8566\n",
            "✔️ Best model saved at epoch 1\n",
            "Epoch 2/80 - Train Loss: 0.9243 | Val Loss: 0.7483\n",
            "✔️ Best model saved at epoch 2\n",
            "Epoch 3/80 - Train Loss: 0.8692 | Val Loss: 0.7972\n",
            "Epoch 4/80 - Train Loss: 0.8334 | Val Loss: 0.7044\n",
            "✔️ Best model saved at epoch 4\n",
            "Epoch 5/80 - Train Loss: 0.8257 | Val Loss: 0.8327\n",
            "Epoch 6/80 - Train Loss: 0.7915 | Val Loss: 0.6302\n",
            "✔️ Best model saved at epoch 6\n",
            "Epoch 7/80 - Train Loss: 0.7784 | Val Loss: 0.7207\n",
            "Epoch 8/80 - Train Loss: 0.7426 | Val Loss: 0.6657\n",
            "Epoch 9/80 - Train Loss: 0.7276 | Val Loss: 0.6370\n",
            "Epoch 10/80 - Train Loss: 0.7097 | Val Loss: 0.6164\n",
            "✔️ Best model saved at epoch 10\n",
            "Epoch 11/80 - Train Loss: 0.7032 | Val Loss: 0.6150\n",
            "✔️ Best model saved at epoch 11\n",
            "Epoch 12/80 - Train Loss: 0.7032 | Val Loss: 0.7341\n",
            "Epoch 13/80 - Train Loss: 0.6741 | Val Loss: 0.5593\n",
            "✔️ Best model saved at epoch 13\n",
            "Epoch 14/80 - Train Loss: 0.6584 | Val Loss: 0.5268\n",
            "✔️ Best model saved at epoch 14\n",
            "Epoch 15/80 - Train Loss: 0.6663 | Val Loss: 0.5244\n",
            "✔️ Best model saved at epoch 15\n",
            "Epoch 16/80 - Train Loss: 0.6371 | Val Loss: 0.5223\n",
            "✔️ Best model saved at epoch 16\n",
            "Epoch 17/80 - Train Loss: 0.6276 | Val Loss: 0.5013\n",
            "✔️ Best model saved at epoch 17\n",
            "Epoch 18/80 - Train Loss: 0.5981 | Val Loss: 0.4670\n",
            "✔️ Best model saved at epoch 18\n",
            "Epoch 19/80 - Train Loss: 0.5918 | Val Loss: 0.4402\n",
            "✔️ Best model saved at epoch 19\n",
            "Epoch 20/80 - Train Loss: 0.5705 | Val Loss: 0.4591\n",
            "Epoch 21/80 - Train Loss: 0.5608 | Val Loss: 0.4215\n",
            "✔️ Best model saved at epoch 21\n",
            "Epoch 22/80 - Train Loss: 0.5448 | Val Loss: 0.4009\n",
            "✔️ Best model saved at epoch 22\n",
            "Epoch 23/80 - Train Loss: 0.5281 | Val Loss: 0.4151\n",
            "Epoch 24/80 - Train Loss: 0.5260 | Val Loss: 0.4051\n",
            "Epoch 25/80 - Train Loss: 0.5151 | Val Loss: 0.3879\n",
            "✔️ Best model saved at epoch 25\n",
            "Epoch 26/80 - Train Loss: 0.4789 | Val Loss: 0.3604\n",
            "✔️ Best model saved at epoch 26\n",
            "Epoch 27/80 - Train Loss: 0.4715 | Val Loss: 0.3672\n",
            "Epoch 28/80 - Train Loss: 0.4608 | Val Loss: 0.3353\n",
            "✔️ Best model saved at epoch 28\n",
            "Epoch 29/80 - Train Loss: 0.4653 | Val Loss: 0.3301\n",
            "✔️ Best model saved at epoch 29\n",
            "Epoch 30/80 - Train Loss: 0.4522 | Val Loss: 0.3212\n",
            "✔️ Best model saved at epoch 30\n",
            "Epoch 31/80 - Train Loss: 0.4593 | Val Loss: 0.3260\n",
            "Epoch 32/80 - Train Loss: 0.4306 | Val Loss: 0.3016\n",
            "✔️ Best model saved at epoch 32\n",
            "Epoch 33/80 - Train Loss: 0.4284 | Val Loss: 0.2844\n",
            "✔️ Best model saved at epoch 33\n",
            "Epoch 34/80 - Train Loss: 0.4018 | Val Loss: 0.2945\n",
            "Epoch 35/80 - Train Loss: 0.3925 | Val Loss: 0.2720\n",
            "✔️ Best model saved at epoch 35\n",
            "Epoch 36/80 - Train Loss: 0.4079 | Val Loss: 0.2811\n",
            "Epoch 37/80 - Train Loss: 0.3959 | Val Loss: 0.2828\n",
            "Epoch 38/80 - Train Loss: 0.3796 | Val Loss: 0.2642\n",
            "✔️ Best model saved at epoch 38\n",
            "Epoch 39/80 - Train Loss: 0.3619 | Val Loss: 0.2534\n",
            "✔️ Best model saved at epoch 39\n",
            "Epoch 40/80 - Train Loss: 0.3704 | Val Loss: 0.2485\n",
            "✔️ Best model saved at epoch 40\n",
            "Epoch 41/80 - Train Loss: 0.3735 | Val Loss: 0.2653\n",
            "Epoch 42/80 - Train Loss: 0.3470 | Val Loss: 0.2430\n",
            "✔️ Best model saved at epoch 42\n",
            "Epoch 43/80 - Train Loss: 0.3531 | Val Loss: 0.2504\n",
            "Epoch 44/80 - Train Loss: 0.3328 | Val Loss: 0.2326\n",
            "✔️ Best model saved at epoch 44\n",
            "Epoch 45/80 - Train Loss: 0.3328 | Val Loss: 0.2270\n",
            "✔️ Best model saved at epoch 45\n",
            "Epoch 46/80 - Train Loss: 0.3221 | Val Loss: 0.2157\n",
            "✔️ Best model saved at epoch 46\n",
            "Epoch 47/80 - Train Loss: 0.3269 | Val Loss: 0.2120\n",
            "✔️ Best model saved at epoch 47\n",
            "Epoch 48/80 - Train Loss: 0.3218 | Val Loss: 0.2039\n",
            "✔️ Best model saved at epoch 48\n",
            "Epoch 49/80 - Train Loss: 0.2877 | Val Loss: 0.1995\n",
            "✔️ Best model saved at epoch 49\n",
            "Epoch 50/80 - Train Loss: 0.3002 | Val Loss: 0.2064\n",
            "Epoch 51/80 - Train Loss: 0.2845 | Val Loss: 0.1969\n",
            "✔️ Best model saved at epoch 51\n",
            "Epoch 52/80 - Train Loss: 0.2838 | Val Loss: 0.1908\n",
            "✔️ Best model saved at epoch 52\n",
            "Epoch 53/80 - Train Loss: 0.2757 | Val Loss: 0.1956\n",
            "Epoch 54/80 - Train Loss: 0.2732 | Val Loss: 0.1828\n",
            "✔️ Best model saved at epoch 54\n",
            "Epoch 55/80 - Train Loss: 0.2932 | Val Loss: 0.1866\n",
            "Epoch 56/80 - Train Loss: 0.2666 | Val Loss: 0.1939\n",
            "Epoch 57/80 - Train Loss: 0.2677 | Val Loss: 0.1954\n",
            "Epoch 58/80 - Train Loss: 0.2653 | Val Loss: 0.1682\n",
            "✔️ Best model saved at epoch 58\n",
            "Epoch 59/80 - Train Loss: 0.2508 | Val Loss: 0.1707\n",
            "Epoch 60/80 - Train Loss: 0.2465 | Val Loss: 0.1708\n",
            "Epoch 61/80 - Train Loss: 0.2416 | Val Loss: 0.1708\n",
            "Epoch 62/80 - Train Loss: 0.2391 | Val Loss: 0.1612\n",
            "✔️ Best model saved at epoch 62\n",
            "Epoch 63/80 - Train Loss: 0.2517 | Val Loss: 0.1684\n",
            "Epoch 64/80 - Train Loss: 0.2358 | Val Loss: 0.1589\n",
            "✔️ Best model saved at epoch 64\n",
            "Epoch 65/80 - Train Loss: 0.2331 | Val Loss: 0.1533\n",
            "✔️ Best model saved at epoch 65\n",
            "Epoch 66/80 - Train Loss: 0.2396 | Val Loss: 0.1503\n",
            "✔️ Best model saved at epoch 66\n",
            "Epoch 67/80 - Train Loss: 0.2164 | Val Loss: 0.1492\n",
            "✔️ Best model saved at epoch 67\n",
            "Epoch 68/80 - Train Loss: 0.2236 | Val Loss: 0.1574\n",
            "Epoch 69/80 - Train Loss: 0.2217 | Val Loss: 0.1486\n",
            "✔️ Best model saved at epoch 69\n",
            "Epoch 70/80 - Train Loss: 0.2273 | Val Loss: 0.1433\n",
            "✔️ Best model saved at epoch 70\n",
            "Epoch 71/80 - Train Loss: 0.2002 | Val Loss: 0.1410\n",
            "✔️ Best model saved at epoch 71\n",
            "Epoch 72/80 - Train Loss: 0.2056 | Val Loss: 0.1693\n",
            "Epoch 73/80 - Train Loss: 0.1965 | Val Loss: 0.1365\n",
            "✔️ Best model saved at epoch 73\n",
            "Epoch 74/80 - Train Loss: 0.1873 | Val Loss: 0.1359\n",
            "✔️ Best model saved at epoch 74\n",
            "Epoch 75/80 - Train Loss: 0.2056 | Val Loss: 0.1528\n",
            "Epoch 76/80 - Train Loss: 0.1746 | Val Loss: 0.1309\n",
            "✔️ Best model saved at epoch 76\n",
            "Epoch 77/80 - Train Loss: 0.1799 | Val Loss: 0.1313\n",
            "Epoch 78/80 - Train Loss: 0.1794 | Val Loss: 0.1334\n",
            "Epoch 79/80 - Train Loss: 0.1860 | Val Loss: 0.1284\n",
            "✔️ Best model saved at epoch 79\n",
            "Epoch 80/80 - Train Loss: 0.1611 | Val Loss: 0.1226\n",
            "✔️ Best model saved at epoch 80\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.117904..2.6399999].\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.117904..2.4285712].\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.117904..2.4308496].\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.117904..2.6399999].\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.117904..2.6399999].\n",
            "Evaluation Metrics:\n",
            "pixel_accuracy: 0.9823621904089096\n",
            "precision: [0.98555385 0.93432897 0.87729809 0.79996143]\n",
            "recall: [0.99588885 0.82425453 0.67698263 0.37075852]\n",
            "f1_score: [0.99069439 0.87584682 0.76423204 0.50668397]\n",
            "iou: [0.98156038 0.77911697 0.61842682 0.33930123]\n",
            "dice_score: [0.99069439 0.87584682 0.76423204 0.50668397]\n",
            "Total params: 9,163,428\n",
            "Model size: 34.96 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from inside /content/project_root_seg\n",
        "!python train.py \\\n",
        "  --model unet_mobilenet \\\n",
        "  --data-dir data \\\n",
        "  --output-dir /content/project_root_seg/Finaldraft/outputs \\\n",
        "  --img-size 640 \\\n",
        "  --batch-size 8 \\\n",
        "  --epochs 80 \\\n",
        "  --lr 1e-4 \\\n",
        "  --patience 20"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGVqN8j2pQ3_",
        "outputId": "b3e2d2c8-7916-4ef1-bdfc-6f75f6c07c6d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:111: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "Epoch 1/80 - Train Loss: 1.0356 | Val Loss: 0.7951\n",
            "✔️ Best model saved at epoch 1\n",
            "Epoch 2/80 - Train Loss: 0.8730 | Val Loss: 0.6996\n",
            "✔️ Best model saved at epoch 2\n",
            "Epoch 3/80 - Train Loss: 0.8285 | Val Loss: 0.6819\n",
            "✔️ Best model saved at epoch 3\n",
            "Epoch 4/80 - Train Loss: 0.8016 | Val Loss: 0.6381\n",
            "✔️ Best model saved at epoch 4\n",
            "Epoch 5/80 - Train Loss: 0.7565 | Val Loss: 0.6750\n",
            "Epoch 6/80 - Train Loss: 0.7291 | Val Loss: 0.6287\n",
            "✔️ Best model saved at epoch 6\n",
            "Epoch 7/80 - Train Loss: 0.7182 | Val Loss: 0.5631\n",
            "✔️ Best model saved at epoch 7\n",
            "Epoch 8/80 - Train Loss: 0.7057 | Val Loss: 0.5867\n",
            "Epoch 9/80 - Train Loss: 0.6908 | Val Loss: 0.5399\n",
            "✔️ Best model saved at epoch 9\n",
            "Epoch 10/80 - Train Loss: 0.6602 | Val Loss: 0.4990\n",
            "✔️ Best model saved at epoch 10\n",
            "Epoch 11/80 - Train Loss: 0.6652 | Val Loss: 0.5150\n",
            "Epoch 12/80 - Train Loss: 0.6500 | Val Loss: 0.4804\n",
            "✔️ Best model saved at epoch 12\n",
            "Epoch 13/80 - Train Loss: 0.6312 | Val Loss: 0.4612\n",
            "✔️ Best model saved at epoch 13\n",
            "Epoch 14/80 - Train Loss: 0.6034 | Val Loss: 0.9678\n",
            "Epoch 15/80 - Train Loss: 0.5984 | Val Loss: 0.4266\n",
            "✔️ Best model saved at epoch 15\n",
            "Epoch 16/80 - Train Loss: 0.5784 | Val Loss: 0.4477\n",
            "Epoch 17/80 - Train Loss: 0.5611 | Val Loss: 0.6273\n",
            "Epoch 18/80 - Train Loss: 0.5553 | Val Loss: 0.4028\n",
            "✔️ Best model saved at epoch 18\n",
            "Epoch 19/80 - Train Loss: 0.5595 | Val Loss: 0.3908\n",
            "✔️ Best model saved at epoch 19\n",
            "Epoch 20/80 - Train Loss: 0.5357 | Val Loss: 0.4163\n",
            "Epoch 21/80 - Train Loss: 0.5419 | Val Loss: 0.3940\n",
            "Epoch 22/80 - Train Loss: 0.5292 | Val Loss: 0.3753\n",
            "✔️ Best model saved at epoch 22\n",
            "Epoch 23/80 - Train Loss: 0.5209 | Val Loss: 0.3983\n",
            "Epoch 24/80 - Train Loss: 0.5086 | Val Loss: 0.3623\n",
            "✔️ Best model saved at epoch 24\n",
            "Epoch 25/80 - Train Loss: 0.4900 | Val Loss: 0.4004\n",
            "Epoch 26/80 - Train Loss: 0.4729 | Val Loss: 0.3940\n",
            "Epoch 27/80 - Train Loss: 0.4934 | Val Loss: 0.3662\n",
            "Epoch 28/80 - Train Loss: 0.4893 | Val Loss: 0.3470\n",
            "✔️ Best model saved at epoch 28\n",
            "Epoch 29/80 - Train Loss: 0.4747 | Val Loss: 0.3195\n",
            "✔️ Best model saved at epoch 29\n",
            "Epoch 30/80 - Train Loss: 0.4677 | Val Loss: 0.3364\n",
            "Epoch 31/80 - Train Loss: 0.4501 | Val Loss: 0.3162\n",
            "✔️ Best model saved at epoch 31\n",
            "Epoch 32/80 - Train Loss: 0.4566 | Val Loss: 0.3611\n",
            "Epoch 33/80 - Train Loss: 0.4662 | Val Loss: 0.3113\n",
            "✔️ Best model saved at epoch 33\n",
            "Epoch 34/80 - Train Loss: 0.4511 | Val Loss: 0.3135\n",
            "Epoch 35/80 - Train Loss: 0.4548 | Val Loss: 0.3056\n",
            "✔️ Best model saved at epoch 35\n",
            "Epoch 36/80 - Train Loss: 0.4405 | Val Loss: 0.2951\n",
            "✔️ Best model saved at epoch 36\n",
            "Epoch 37/80 - Train Loss: 0.4528 | Val Loss: 0.3320\n",
            "Epoch 38/80 - Train Loss: 0.4319 | Val Loss: 0.2802\n",
            "✔️ Best model saved at epoch 38\n",
            "Epoch 39/80 - Train Loss: 0.4401 | Val Loss: 0.2854\n",
            "Epoch 40/80 - Train Loss: 0.4298 | Val Loss: 0.3093\n",
            "Epoch 41/80 - Train Loss: 0.4300 | Val Loss: 0.2849\n",
            "Epoch 42/80 - Train Loss: 0.4070 | Val Loss: 0.3127\n",
            "Epoch 43/80 - Train Loss: 0.4102 | Val Loss: 0.3983\n",
            "Epoch 44/80 - Train Loss: 0.4124 | Val Loss: 0.3045\n",
            "Epoch 45/80 - Train Loss: 0.4037 | Val Loss: 0.2631\n",
            "✔️ Best model saved at epoch 45\n",
            "Epoch 46/80 - Train Loss: 0.4181 | Val Loss: 0.2594\n",
            "✔️ Best model saved at epoch 46\n",
            "Epoch 47/80 - Train Loss: 0.3934 | Val Loss: 0.2539\n",
            "✔️ Best model saved at epoch 47\n",
            "Epoch 48/80 - Train Loss: 0.3951 | Val Loss: 0.3009\n",
            "Epoch 49/80 - Train Loss: 0.3937 | Val Loss: 0.2799\n",
            "Epoch 50/80 - Train Loss: 0.3954 | Val Loss: 0.3083\n",
            "Epoch 51/80 - Train Loss: 0.3776 | Val Loss: 0.2677\n",
            "Epoch 52/80 - Train Loss: 0.3770 | Val Loss: 0.2514\n",
            "✔️ Best model saved at epoch 52\n",
            "Epoch 53/80 - Train Loss: 0.3609 | Val Loss: 0.2365\n",
            "✔️ Best model saved at epoch 53\n",
            "Epoch 54/80 - Train Loss: 0.3470 | Val Loss: 0.3012\n",
            "Epoch 55/80 - Train Loss: 0.3720 | Val Loss: 0.2529\n",
            "Epoch 56/80 - Train Loss: 0.3457 | Val Loss: 0.2555\n",
            "Epoch 57/80 - Train Loss: 0.3467 | Val Loss: 0.2465\n",
            "Epoch 58/80 - Train Loss: 0.3461 | Val Loss: 0.2158\n",
            "✔️ Best model saved at epoch 58\n",
            "Epoch 59/80 - Train Loss: 0.3305 | Val Loss: 0.2246\n",
            "Epoch 60/80 - Train Loss: 0.3403 | Val Loss: 0.2303\n",
            "Epoch 61/80 - Train Loss: 0.3156 | Val Loss: 0.2358\n",
            "Epoch 62/80 - Train Loss: 0.3401 | Val Loss: 0.2123\n",
            "✔️ Best model saved at epoch 62\n",
            "Epoch 63/80 - Train Loss: 0.3049 | Val Loss: 0.2129\n",
            "Epoch 64/80 - Train Loss: 0.3160 | Val Loss: 0.2046\n",
            "✔️ Best model saved at epoch 64\n",
            "Epoch 65/80 - Train Loss: 0.3125 | Val Loss: 0.2178\n",
            "Epoch 66/80 - Train Loss: 0.3042 | Val Loss: 0.1982\n",
            "✔️ Best model saved at epoch 66\n",
            "Epoch 67/80 - Train Loss: 0.2873 | Val Loss: 0.2022\n",
            "Epoch 68/80 - Train Loss: 0.3047 | Val Loss: 0.1893\n",
            "✔️ Best model saved at epoch 68\n",
            "Epoch 69/80 - Train Loss: 0.2874 | Val Loss: 0.1874\n",
            "✔️ Best model saved at epoch 69\n",
            "Epoch 70/80 - Train Loss: 0.2965 | Val Loss: 0.1876\n",
            "Epoch 71/80 - Train Loss: 0.2824 | Val Loss: 0.1900\n",
            "Epoch 72/80 - Train Loss: 0.2920 | Val Loss: 0.1876\n",
            "Epoch 73/80 - Train Loss: 0.2937 | Val Loss: 0.1890\n",
            "Epoch 74/80 - Train Loss: 0.2662 | Val Loss: 0.1721\n",
            "✔️ Best model saved at epoch 74\n",
            "Epoch 75/80 - Train Loss: 0.2668 | Val Loss: 0.2276\n",
            "Epoch 76/80 - Train Loss: 0.2586 | Val Loss: 0.1688\n",
            "✔️ Best model saved at epoch 76\n",
            "Epoch 77/80 - Train Loss: 0.2626 | Val Loss: 0.1666\n",
            "✔️ Best model saved at epoch 77\n",
            "Epoch 78/80 - Train Loss: 0.2667 | Val Loss: 0.1696\n",
            "Epoch 79/80 - Train Loss: 0.2546 | Val Loss: 0.1688\n",
            "Epoch 80/80 - Train Loss: 0.2620 | Val Loss: 0.1799\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.117904..2.6399999].\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.117904..2.4285712].\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.117904..2.4308496].\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.117904..2.6399999].\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.117904..2.6399999].\n",
            "Evaluation Metrics:\n",
            "pixel_accuracy: 0.9519819024268616\n",
            "precision: [0.98320368 0.57583413 0.54570915 0.46737977]\n",
            "recall: [0.96603219 0.75519577 0.6057213  0.67907221]\n",
            "f1_score: [0.9745423  0.65343009 0.57415131 0.55368147]\n",
            "iou: [0.95034861 0.48525524 0.40267339 0.38282126]\n",
            "dice_score: [0.9745423  0.65343009 0.57415131 0.55368147]\n",
            "Total params: 15,112,876\n",
            "Model size: 57.65 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.make_archive('/content/project_root_seg', 'zip', '/content/project_root_seg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "MF_mdL6avm_R",
        "outputId": "f63d3c7b-463a-4596-8b14-20166e3a296c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/project_root_seg.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/project_root_seg.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "h2CGdlr70Uk8",
        "outputId": "6166193d-f445-4ecd-81ce-9e09d8b6c1d5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d8f1fe5e-ce5e-4d2e-8e4a-2a1f87819940\", \"project_root_seg.zip\", 496349112)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3nqUwWl10c-d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FOgZyCGoMPY0"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTovWOHGNOK5",
        "outputId": "8f7d1826-c6f4-4f6c-8062-1599c658820a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!unzip -q /content/drive/MyDrive/projects/project_root_seg.zip -d /content/\n",
        "%cd /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eThVFRDfNYJj",
        "outputId": "3db7053d-4c40-457a-da6b-60f841a5a19e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m123.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m96.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m104.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# !pip install -q torch torchvision albumentations scikit-learn opencv-python\n",
        "# !pip install -q segmentation-models-pytorch\n",
        "\n",
        "\n",
        "!pip install -r /content/Requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJqaTUJfQg_W",
        "outputId": "25918f38-7d1d-4aeb-f92c-3d31dcd0370f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/Finaldraft\n"
          ]
        }
      ],
      "source": [
        "%cd /content/Finaldraft/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WAPVxQTdxZJ",
        "outputId": "e8fdbdc3-bb41-43c9-becc-d41c0ae8e9fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/Finaldraft\n",
            "augmentation.py  models      __pycache__       train.py\n",
            "data\t\t network.py  README.md\t       visualize.py\n",
            "eval.py\t\t outputs     requirements.txt\n"
          ]
        }
      ],
      "source": [
        "%cd /content/Finaldraft\n",
        "!mkdir -p outputs\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tnf9Ynt0NxUu",
        "outputId": "69e2fd00-1ced-4ed3-ee86-f4136349fc51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:111: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "Epoch 1/80 - Train Loss: 1.0034 | Val Loss: 0.8157\n",
            "✔️ Best model saved at epoch 1\n",
            "Epoch 2/80 - Train Loss: 0.8058 | Val Loss: 0.6418\n",
            "✔️ Best model saved at epoch 2\n",
            "Epoch 3/80 - Train Loss: 0.7451 | Val Loss: 0.6037\n",
            "✔️ Best model saved at epoch 3\n",
            "Epoch 4/80 - Train Loss: 0.7109 | Val Loss: 0.5535\n",
            "✔️ Best model saved at epoch 4\n",
            "Epoch 5/80 - Train Loss: 0.6896 | Val Loss: 0.5209\n",
            "✔️ Best model saved at epoch 5\n",
            "Epoch 6/80 - Train Loss: 0.6604 | Val Loss: 0.4991\n",
            "✔️ Best model saved at epoch 6\n",
            "Epoch 7/80 - Train Loss: 0.6608 | Val Loss: 0.4867\n",
            "✔️ Best model saved at epoch 7\n",
            "Epoch 8/80 - Train Loss: 0.6370 | Val Loss: 0.4698\n",
            "✔️ Best model saved at epoch 8\n",
            "Epoch 9/80 - Train Loss: 0.6195 | Val Loss: 0.4444\n",
            "✔️ Best model saved at epoch 9\n",
            "Epoch 10/80 - Train Loss: 0.6075 | Val Loss: 0.4321\n",
            "✔️ Best model saved at epoch 10\n",
            "Epoch 11/80 - Train Loss: 0.5993 | Val Loss: 0.4095\n",
            "✔️ Best model saved at epoch 11\n",
            "Epoch 12/80 - Train Loss: 0.5871 | Val Loss: 0.4174\n",
            "Epoch 13/80 - Train Loss: 0.5555 | Val Loss: 0.4100\n",
            "Epoch 14/80 - Train Loss: 0.5662 | Val Loss: 0.3936\n",
            "✔️ Best model saved at epoch 14\n",
            "Epoch 15/80 - Train Loss: 0.5412 | Val Loss: 0.4481\n",
            "Epoch 16/80 - Train Loss: 0.5338 | Val Loss: 0.4015\n",
            "Epoch 17/80 - Train Loss: 0.5224 | Val Loss: 0.3571\n",
            "✔️ Best model saved at epoch 17\n",
            "Epoch 18/80 - Train Loss: 0.5151 | Val Loss: 0.3584\n",
            "Epoch 19/80 - Train Loss: 0.4974 | Val Loss: 0.3291\n",
            "✔️ Best model saved at epoch 19\n",
            "Epoch 20/80 - Train Loss: 0.4730 | Val Loss: 0.3070\n",
            "✔️ Best model saved at epoch 20\n",
            "Epoch 21/80 - Train Loss: 0.4897 | Val Loss: 0.3317\n",
            "Epoch 22/80 - Train Loss: 0.4610 | Val Loss: 0.3007\n",
            "✔️ Best model saved at epoch 22\n",
            "Epoch 23/80 - Train Loss: 0.4366 | Val Loss: 0.2984\n",
            "✔️ Best model saved at epoch 23\n",
            "Epoch 24/80 - Train Loss: 0.4211 | Val Loss: 0.2873\n",
            "✔️ Best model saved at epoch 24\n",
            "Epoch 25/80 - Train Loss: 0.4146 | Val Loss: 0.2747\n",
            "✔️ Best model saved at epoch 25\n",
            "Epoch 26/80 - Train Loss: 0.4158 | Val Loss: 0.2626\n",
            "✔️ Best model saved at epoch 26\n",
            "Epoch 27/80 - Train Loss: 0.4024 | Val Loss: 0.2473\n",
            "✔️ Best model saved at epoch 27\n",
            "Epoch 28/80 - Train Loss: 0.3888 | Val Loss: 0.2568\n",
            "Epoch 29/80 - Train Loss: 0.3895 | Val Loss: 0.2812\n",
            "Epoch 30/80 - Train Loss: 0.3866 | Val Loss: 0.2312\n",
            "✔️ Best model saved at epoch 30\n",
            "Epoch 31/80 - Train Loss: 0.3566 | Val Loss: 0.2525\n",
            "Epoch 32/80 - Train Loss: 0.3655 | Val Loss: 0.2042\n",
            "✔️ Best model saved at epoch 32\n",
            "Epoch 33/80 - Train Loss: 0.3263 | Val Loss: 0.1996\n",
            "✔️ Best model saved at epoch 33\n",
            "Epoch 34/80 - Train Loss: 0.3216 | Val Loss: 0.2175\n",
            "Epoch 35/80 - Train Loss: 0.3324 | Val Loss: 0.2013\n",
            "Epoch 36/80 - Train Loss: 0.3266 | Val Loss: 0.2008\n",
            "Epoch 37/80 - Train Loss: 0.3181 | Val Loss: 0.2102\n",
            "Epoch 38/80 - Train Loss: 0.3010 | Val Loss: 0.1730\n",
            "✔️ Best model saved at epoch 38\n",
            "Epoch 39/80 - Train Loss: 0.2898 | Val Loss: 0.1817\n",
            "Epoch 40/80 - Train Loss: 0.2854 | Val Loss: 0.1658\n",
            "✔️ Best model saved at epoch 40\n",
            "Epoch 41/80 - Train Loss: 0.3130 | Val Loss: 0.1712\n",
            "Epoch 42/80 - Train Loss: 0.2808 | Val Loss: 0.1686\n",
            "Epoch 43/80 - Train Loss: 0.2844 | Val Loss: 0.1563\n",
            "✔️ Best model saved at epoch 43\n",
            "Epoch 44/80 - Train Loss: 0.2770 | Val Loss: 0.1607\n",
            "Epoch 45/80 - Train Loss: 0.2423 | Val Loss: 0.1675\n",
            "Epoch 46/80 - Train Loss: 0.2437 | Val Loss: 0.1510\n",
            "✔️ Best model saved at epoch 46\n",
            "Epoch 47/80 - Train Loss: 0.2387 | Val Loss: 0.1366\n",
            "✔️ Best model saved at epoch 47\n",
            "Epoch 48/80 - Train Loss: 0.2461 | Val Loss: 0.1480\n",
            "Epoch 49/80 - Train Loss: 0.2271 | Val Loss: 0.1442\n",
            "Epoch 50/80 - Train Loss: 0.2326 | Val Loss: 0.1370\n",
            "Epoch 51/80 - Train Loss: 0.2255 | Val Loss: 0.1428\n",
            "Epoch 52/80 - Train Loss: 0.2130 | Val Loss: 0.1335\n",
            "✔️ Best model saved at epoch 52\n",
            "Epoch 53/80 - Train Loss: 0.2161 | Val Loss: 0.1291\n",
            "✔️ Best model saved at epoch 53\n",
            "Epoch 54/80 - Train Loss: 0.2174 | Val Loss: 0.1177\n",
            "✔️ Best model saved at epoch 54\n",
            "Epoch 55/80 - Train Loss: 0.1878 | Val Loss: 0.1263\n",
            "Epoch 56/80 - Train Loss: 0.1966 | Val Loss: 0.1322\n",
            "Epoch 57/80 - Train Loss: 0.1871 | Val Loss: 0.1405\n",
            "Epoch 58/80 - Train Loss: 0.1958 | Val Loss: 0.1313\n",
            "Epoch 59/80 - Train Loss: 0.2000 | Val Loss: 0.1275\n",
            "Epoch 60/80 - Train Loss: 0.1842 | Val Loss: 0.1245\n",
            "Epoch 61/80 - Train Loss: 0.1826 | Val Loss: 0.1320\n",
            "Epoch 62/80 - Train Loss: 0.1561 | Val Loss: 0.1165\n",
            "✔️ Best model saved at epoch 62\n",
            "Epoch 63/80 - Train Loss: 0.1531 | Val Loss: 0.1175\n",
            "Epoch 64/80 - Train Loss: 0.1521 | Val Loss: 0.1160\n",
            "✔️ Best model saved at epoch 64\n",
            "Epoch 65/80 - Train Loss: 0.1559 | Val Loss: 0.1062\n",
            "✔️ Best model saved at epoch 65\n",
            "Epoch 66/80 - Train Loss: 0.1563 | Val Loss: 0.1164\n",
            "Epoch 67/80 - Train Loss: 0.1437 | Val Loss: 0.1235\n",
            "Epoch 68/80 - Train Loss: 0.1605 | Val Loss: 0.1164\n",
            "Epoch 69/80 - Train Loss: 0.1544 | Val Loss: 0.1155\n",
            "Epoch 70/80 - Train Loss: 0.1508 | Val Loss: 0.1144\n",
            "Epoch 71/80 - Train Loss: 0.1553 | Val Loss: 0.0976\n",
            "✔️ Best model saved at epoch 71\n",
            "Epoch 72/80 - Train Loss: 0.1484 | Val Loss: 0.1163\n",
            "Epoch 73/80 - Train Loss: 0.1463 | Val Loss: 0.1213\n",
            "Epoch 74/80 - Train Loss: 0.1504 | Val Loss: 0.0965\n",
            "✔️ Best model saved at epoch 74\n",
            "Epoch 75/80 - Train Loss: 0.1314 | Val Loss: 0.1018\n",
            "Epoch 76/80 - Train Loss: 0.1331 | Val Loss: 0.1357\n",
            "Epoch 77/80 - Train Loss: 0.1501 | Val Loss: 0.1066\n",
            "Epoch 78/80 - Train Loss: 0.1382 | Val Loss: 0.0965\n",
            "Epoch 79/80 - Train Loss: 0.1163 | Val Loss: 0.0976\n",
            "Epoch 80/80 - Train Loss: 0.1354 | Val Loss: 0.1097\n",
            "Evaluation Metrics:\n",
            "pixel_accuracy: 0.9804003386801862\n",
            "precision: [0.98393204 0.91476703 0.95233047 0.51850934]\n",
            "recall: [0.99564959 0.82278981 0.60917151 0.16369284]\n",
            "f1_score: [0.98975614 0.86634401 0.74304431 0.24883023]\n",
            "iou: [0.97972003 0.76420363 0.591146   0.14209373]\n",
            "dice_score: [0.98975614 0.86634401 0.74304431 0.24883023]\n",
            "Total params: 31,037,828\n",
            "Model size: 118.40 MB\n"
          ]
        }
      ],
      "source": [
        "# run training\n",
        "!python train.py \\\n",
        "  --model unet \\\n",
        "  --data-dir data \\\n",
        "  --output-dir /content/Finaldraft/outputs \\\n",
        "  --img-size 640 \\\n",
        "  --batch-size 8 \\\n",
        "  --epochs 80 \\\n",
        "  --lr 1e-4 \\\n",
        "  --patience 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOc_aDOPgc2T",
        "outputId": "17ff3de9-3c79-4c92-9700-8a499545a175"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:111: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "Epoch 1/80 - Train Loss: 1.0692 | Val Loss: 0.9292\n",
            "✔️ Best model saved at epoch 1\n",
            "Epoch 2/80 - Train Loss: 0.9460 | Val Loss: 0.8511\n",
            "✔️ Best model saved at epoch 2\n",
            "Epoch 3/80 - Train Loss: 0.8919 | Val Loss: 0.7094\n",
            "✔️ Best model saved at epoch 3\n",
            "Epoch 4/80 - Train Loss: 0.8395 | Val Loss: 0.7223\n",
            "Epoch 5/80 - Train Loss: 0.8197 | Val Loss: 0.6777\n",
            "✔️ Best model saved at epoch 5\n",
            "Epoch 6/80 - Train Loss: 0.8027 | Val Loss: 0.6494\n",
            "✔️ Best model saved at epoch 6\n",
            "Epoch 7/80 - Train Loss: 0.8107 | Val Loss: 0.6273\n",
            "✔️ Best model saved at epoch 7\n",
            "Epoch 8/80 - Train Loss: 0.7817 | Val Loss: 0.6197\n",
            "✔️ Best model saved at epoch 8\n",
            "Epoch 9/80 - Train Loss: 0.7760 | Val Loss: 0.6079\n",
            "✔️ Best model saved at epoch 9\n",
            "Epoch 10/80 - Train Loss: 0.7476 | Val Loss: 0.5872\n",
            "✔️ Best model saved at epoch 10\n",
            "Epoch 11/80 - Train Loss: 0.7325 | Val Loss: 0.5674\n",
            "✔️ Best model saved at epoch 11\n",
            "Epoch 12/80 - Train Loss: 0.7235 | Val Loss: 0.5639\n",
            "✔️ Best model saved at epoch 12\n",
            "Epoch 13/80 - Train Loss: 0.7086 | Val Loss: 0.5371\n",
            "✔️ Best model saved at epoch 13\n",
            "Epoch 14/80 - Train Loss: 0.6947 | Val Loss: 0.5226\n",
            "✔️ Best model saved at epoch 14\n",
            "Epoch 15/80 - Train Loss: 0.6695 | Val Loss: 0.5108\n",
            "✔️ Best model saved at epoch 15\n",
            "Epoch 16/80 - Train Loss: 0.6677 | Val Loss: 0.5423\n",
            "Epoch 17/80 - Train Loss: 0.6469 | Val Loss: 0.5024\n",
            "✔️ Best model saved at epoch 17\n",
            "Epoch 18/80 - Train Loss: 0.6284 | Val Loss: 0.4681\n",
            "✔️ Best model saved at epoch 18\n",
            "Epoch 19/80 - Train Loss: 0.6149 | Val Loss: 0.4691\n",
            "Epoch 20/80 - Train Loss: 0.6143 | Val Loss: 0.4206\n",
            "✔️ Best model saved at epoch 20\n",
            "Epoch 21/80 - Train Loss: 0.5834 | Val Loss: 0.4251\n",
            "Epoch 22/80 - Train Loss: 0.5707 | Val Loss: 0.3999\n",
            "✔️ Best model saved at epoch 22\n",
            "Epoch 23/80 - Train Loss: 0.5585 | Val Loss: 0.4087\n",
            "Epoch 24/80 - Train Loss: 0.5640 | Val Loss: 0.3906\n",
            "✔️ Best model saved at epoch 24\n",
            "Epoch 25/80 - Train Loss: 0.5372 | Val Loss: 0.3772\n",
            "✔️ Best model saved at epoch 25\n",
            "Epoch 26/80 - Train Loss: 0.5145 | Val Loss: 0.3664\n",
            "✔️ Best model saved at epoch 26\n",
            "Epoch 27/80 - Train Loss: 0.4994 | Val Loss: 0.3558\n",
            "✔️ Best model saved at epoch 27\n",
            "Epoch 28/80 - Train Loss: 0.5162 | Val Loss: 0.3894\n",
            "Epoch 29/80 - Train Loss: 0.4950 | Val Loss: 0.3576\n",
            "Epoch 30/80 - Train Loss: 0.4834 | Val Loss: 0.3336\n",
            "✔️ Best model saved at epoch 30\n",
            "Epoch 31/80 - Train Loss: 0.4497 | Val Loss: 0.3210\n",
            "✔️ Best model saved at epoch 31\n",
            "Epoch 32/80 - Train Loss: 0.4679 | Val Loss: 0.3391\n",
            "Epoch 33/80 - Train Loss: 0.4375 | Val Loss: 0.3030\n",
            "✔️ Best model saved at epoch 33\n",
            "Epoch 34/80 - Train Loss: 0.4276 | Val Loss: 0.2951\n",
            "✔️ Best model saved at epoch 34\n",
            "Epoch 35/80 - Train Loss: 0.4289 | Val Loss: 0.2903\n",
            "✔️ Best model saved at epoch 35\n",
            "Epoch 36/80 - Train Loss: 0.4161 | Val Loss: 0.2725\n",
            "✔️ Best model saved at epoch 36\n",
            "Epoch 37/80 - Train Loss: 0.4163 | Val Loss: 0.2677\n",
            "✔️ Best model saved at epoch 37\n",
            "Epoch 38/80 - Train Loss: 0.4062 | Val Loss: 0.2694\n",
            "Epoch 39/80 - Train Loss: 0.3855 | Val Loss: 0.2704\n",
            "Epoch 40/80 - Train Loss: 0.3961 | Val Loss: 0.2575\n",
            "✔️ Best model saved at epoch 40\n",
            "Epoch 41/80 - Train Loss: 0.3704 | Val Loss: 0.2387\n",
            "✔️ Best model saved at epoch 41\n",
            "Epoch 42/80 - Train Loss: 0.3646 | Val Loss: 0.2367\n",
            "✔️ Best model saved at epoch 42\n",
            "Epoch 43/80 - Train Loss: 0.3508 | Val Loss: 0.2371\n",
            "Epoch 44/80 - Train Loss: 0.3759 | Val Loss: 0.2378\n",
            "Epoch 45/80 - Train Loss: 0.3595 | Val Loss: 0.2306\n",
            "✔️ Best model saved at epoch 45\n",
            "Epoch 46/80 - Train Loss: 0.3545 | Val Loss: 0.2267\n",
            "✔️ Best model saved at epoch 46\n",
            "Epoch 47/80 - Train Loss: 0.3560 | Val Loss: 0.2075\n",
            "✔️ Best model saved at epoch 47\n",
            "Epoch 48/80 - Train Loss: 0.3379 | Val Loss: 0.2089\n",
            "Epoch 49/80 - Train Loss: 0.3270 | Val Loss: 0.2107\n",
            "Epoch 50/80 - Train Loss: 0.3390 | Val Loss: 0.2370\n",
            "Epoch 51/80 - Train Loss: 0.3262 | Val Loss: 0.2120\n",
            "Epoch 52/80 - Train Loss: 0.3195 | Val Loss: 0.2019\n",
            "✔️ Best model saved at epoch 52\n",
            "Epoch 53/80 - Train Loss: 0.3148 | Val Loss: 0.1949\n",
            "✔️ Best model saved at epoch 53\n",
            "Epoch 54/80 - Train Loss: 0.3116 | Val Loss: 0.1884\n",
            "✔️ Best model saved at epoch 54\n",
            "Epoch 55/80 - Train Loss: 0.3223 | Val Loss: 0.2083\n",
            "Epoch 56/80 - Train Loss: 0.3074 | Val Loss: 0.1747\n",
            "✔️ Best model saved at epoch 56\n",
            "Epoch 57/80 - Train Loss: 0.2905 | Val Loss: 0.1744\n",
            "✔️ Best model saved at epoch 57\n",
            "Epoch 58/80 - Train Loss: 0.2848 | Val Loss: 0.1845\n",
            "Epoch 59/80 - Train Loss: 0.2870 | Val Loss: 0.1760\n",
            "Epoch 60/80 - Train Loss: 0.2847 | Val Loss: 0.1659\n",
            "✔️ Best model saved at epoch 60\n",
            "Epoch 61/80 - Train Loss: 0.2786 | Val Loss: 0.1647\n",
            "✔️ Best model saved at epoch 61\n",
            "Epoch 62/80 - Train Loss: 0.2757 | Val Loss: 0.1672\n",
            "Epoch 63/80 - Train Loss: 0.2768 | Val Loss: 0.1965\n",
            "Epoch 64/80 - Train Loss: 0.2704 | Val Loss: 0.1687\n",
            "Epoch 65/80 - Train Loss: 0.2743 | Val Loss: 0.1515\n",
            "✔️ Best model saved at epoch 65\n",
            "Epoch 66/80 - Train Loss: 0.2505 | Val Loss: 0.1539\n",
            "Epoch 67/80 - Train Loss: 0.2522 | Val Loss: 0.1683\n",
            "Epoch 68/80 - Train Loss: 0.2566 | Val Loss: 0.1533\n",
            "Epoch 69/80 - Train Loss: 0.2198 | Val Loss: 0.1468\n",
            "✔️ Best model saved at epoch 69\n",
            "Epoch 70/80 - Train Loss: 0.2577 | Val Loss: 0.1524\n",
            "Epoch 71/80 - Train Loss: 0.2481 | Val Loss: 0.1464\n",
            "✔️ Best model saved at epoch 71\n",
            "Epoch 72/80 - Train Loss: 0.2322 | Val Loss: 0.1756\n",
            "Epoch 73/80 - Train Loss: 0.2400 | Val Loss: 0.1405\n",
            "✔️ Best model saved at epoch 73\n",
            "Epoch 74/80 - Train Loss: 0.2268 | Val Loss: 0.1297\n",
            "✔️ Best model saved at epoch 74\n",
            "Epoch 75/80 - Train Loss: 0.2492 | Val Loss: 0.1574\n",
            "Epoch 76/80 - Train Loss: 0.2125 | Val Loss: 0.1364\n",
            "Epoch 77/80 - Train Loss: 0.2174 | Val Loss: 0.1343\n",
            "Epoch 78/80 - Train Loss: 0.2073 | Val Loss: 0.1295\n",
            "✔️ Best model saved at epoch 78\n",
            "Epoch 79/80 - Train Loss: 0.1871 | Val Loss: 0.1310\n",
            "Epoch 80/80 - Train Loss: 0.2136 | Val Loss: 0.1261\n",
            "✔️ Best model saved at epoch 80\n",
            "Evaluation Metrics:\n",
            "pixel_accuracy: 0.9812122880651596\n",
            "precision: [0.98587755 0.91999663 0.80773671 0.76621458]\n",
            "recall: [0.99434474 0.8163671  0.75846092 0.32443605]\n",
            "f1_score: [0.99009304 0.86508946 0.78232365 0.45585199]\n",
            "iou: [0.98038045 0.76225344 0.64247258 0.29521263]\n",
            "dice_score: [0.99009304 0.86508946 0.78232365 0.45585199]\n",
            "Total params: 41,896,932\n",
            "Model size: 159.82 MB\n"
          ]
        }
      ],
      "source": [
        "# run training\n",
        "!python train.py \\\n",
        "  --model unet_vgg16 \\\n",
        "  --data-dir data \\\n",
        "  --output-dir /content/Finaldraft/outputs \\\n",
        "  --img-size 640 \\\n",
        "  --batch-size 8 \\\n",
        "  --epochs 80 \\\n",
        "  --lr 1e-4 \\\n",
        "  --patience 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vt_DT6gIQZsb",
        "outputId": "f7413c35-95d4-4ccf-dabf-f8a6d8f7a17e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:111: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "Epoch 1/80 - Train Loss: 0.8550 | Val Loss: 0.7257\n",
            "✔️ Best model saved at epoch 1\n",
            "Epoch 2/80 - Train Loss: 0.7238 | Val Loss: 0.5798\n",
            "✔️ Best model saved at epoch 2\n",
            "Epoch 3/80 - Train Loss: 0.6501 | Val Loss: 0.4979\n",
            "✔️ Best model saved at epoch 3\n",
            "Epoch 4/80 - Train Loss: 0.6235 | Val Loss: 0.4964\n",
            "✔️ Best model saved at epoch 4\n",
            "Epoch 5/80 - Train Loss: 0.6159 | Val Loss: 0.4453\n",
            "✔️ Best model saved at epoch 5\n",
            "Epoch 6/80 - Train Loss: 0.5850 | Val Loss: 0.4368\n",
            "✔️ Best model saved at epoch 6\n",
            "Epoch 7/80 - Train Loss: 0.5652 | Val Loss: 0.4089\n",
            "✔️ Best model saved at epoch 7\n",
            "Epoch 8/80 - Train Loss: 0.5355 | Val Loss: 0.3864\n",
            "✔️ Best model saved at epoch 8\n",
            "Epoch 9/80 - Train Loss: 0.5302 | Val Loss: 0.3789\n",
            "✔️ Best model saved at epoch 9\n",
            "Epoch 10/80 - Train Loss: 0.5112 | Val Loss: 0.3474\n",
            "✔️ Best model saved at epoch 10\n",
            "Epoch 11/80 - Train Loss: 0.4742 | Val Loss: 0.3291\n",
            "✔️ Best model saved at epoch 11\n",
            "Epoch 12/80 - Train Loss: 0.4849 | Val Loss: 0.3429\n",
            "Epoch 13/80 - Train Loss: 0.4704 | Val Loss: 0.3271\n",
            "✔️ Best model saved at epoch 13\n",
            "Epoch 14/80 - Train Loss: 0.4510 | Val Loss: 0.3050\n",
            "✔️ Best model saved at epoch 14\n",
            "Epoch 15/80 - Train Loss: 0.4331 | Val Loss: 0.2887\n",
            "✔️ Best model saved at epoch 15\n",
            "Epoch 16/80 - Train Loss: 0.4200 | Val Loss: 0.2668\n",
            "✔️ Best model saved at epoch 16\n",
            "Epoch 17/80 - Train Loss: 0.3903 | Val Loss: 0.2671\n",
            "Epoch 18/80 - Train Loss: 0.3709 | Val Loss: 0.2521\n",
            "✔️ Best model saved at epoch 18\n",
            "Epoch 19/80 - Train Loss: 0.3705 | Val Loss: 0.2480\n",
            "✔️ Best model saved at epoch 19\n",
            "Epoch 20/80 - Train Loss: 0.3735 | Val Loss: 0.2526\n",
            "Epoch 21/80 - Train Loss: 0.3484 | Val Loss: 0.2333\n",
            "✔️ Best model saved at epoch 21\n",
            "Epoch 22/80 - Train Loss: 0.3482 | Val Loss: 0.2055\n",
            "✔️ Best model saved at epoch 22\n",
            "Epoch 23/80 - Train Loss: 0.3285 | Val Loss: 0.2031\n",
            "✔️ Best model saved at epoch 23\n",
            "Epoch 24/80 - Train Loss: 0.3286 | Val Loss: 0.2133\n",
            "Epoch 25/80 - Train Loss: 0.3208 | Val Loss: 0.2225\n",
            "Epoch 26/80 - Train Loss: 0.3095 | Val Loss: 0.1974\n",
            "✔️ Best model saved at epoch 26\n",
            "Epoch 27/80 - Train Loss: 0.3086 | Val Loss: 0.2036\n",
            "Epoch 28/80 - Train Loss: 0.2941 | Val Loss: 0.2086\n",
            "Epoch 29/80 - Train Loss: 0.2917 | Val Loss: 0.2147\n",
            "Epoch 30/80 - Train Loss: 0.2669 | Val Loss: 0.1852\n",
            "✔️ Best model saved at epoch 30\n",
            "Epoch 31/80 - Train Loss: 0.2724 | Val Loss: 0.1655\n",
            "✔️ Best model saved at epoch 31\n",
            "Epoch 32/80 - Train Loss: 0.2722 | Val Loss: 0.1648\n",
            "✔️ Best model saved at epoch 32\n",
            "Epoch 33/80 - Train Loss: 0.2493 | Val Loss: 0.1774\n",
            "Epoch 34/80 - Train Loss: 0.2542 | Val Loss: 0.1507\n",
            "✔️ Best model saved at epoch 34\n",
            "Epoch 35/80 - Train Loss: 0.2360 | Val Loss: 0.1769\n",
            "Epoch 36/80 - Train Loss: 0.2271 | Val Loss: 0.1653\n",
            "Epoch 37/80 - Train Loss: 0.2345 | Val Loss: 0.1379\n",
            "✔️ Best model saved at epoch 37\n",
            "Epoch 38/80 - Train Loss: 0.2217 | Val Loss: 0.1725\n",
            "Epoch 39/80 - Train Loss: 0.2085 | Val Loss: 0.1661\n",
            "Epoch 40/80 - Train Loss: 0.2246 | Val Loss: 0.1491\n",
            "Epoch 41/80 - Train Loss: 0.2103 | Val Loss: 0.1335\n",
            "✔️ Best model saved at epoch 41\n",
            "Epoch 42/80 - Train Loss: 0.2004 | Val Loss: 0.1291\n",
            "✔️ Best model saved at epoch 42\n",
            "Epoch 43/80 - Train Loss: 0.2118 | Val Loss: 0.1282\n",
            "✔️ Best model saved at epoch 43\n",
            "Epoch 44/80 - Train Loss: 0.1836 | Val Loss: 0.1481\n",
            "Epoch 45/80 - Train Loss: 0.1822 | Val Loss: 0.1934\n",
            "Epoch 46/80 - Train Loss: 0.2002 | Val Loss: 0.1402\n",
            "Epoch 47/80 - Train Loss: 0.1871 | Val Loss: 0.1187\n",
            "✔️ Best model saved at epoch 47\n",
            "Epoch 48/80 - Train Loss: 0.1612 | Val Loss: 0.1313\n",
            "Epoch 49/80 - Train Loss: 0.1640 | Val Loss: 0.1153\n",
            "✔️ Best model saved at epoch 49\n",
            "Epoch 50/80 - Train Loss: 0.1704 | Val Loss: 0.1145\n",
            "✔️ Best model saved at epoch 50\n",
            "Epoch 51/80 - Train Loss: 0.1597 | Val Loss: 0.1092\n",
            "✔️ Best model saved at epoch 51\n",
            "Epoch 52/80 - Train Loss: 0.1544 | Val Loss: 0.1093\n",
            "Epoch 53/80 - Train Loss: 0.1727 | Val Loss: 0.1146\n",
            "Epoch 54/80 - Train Loss: 0.1610 | Val Loss: 0.1190\n",
            "Epoch 55/80 - Train Loss: 0.1551 | Val Loss: 0.1141\n",
            "Epoch 56/80 - Train Loss: 0.1295 | Val Loss: 0.1018\n",
            "✔️ Best model saved at epoch 56\n",
            "Epoch 57/80 - Train Loss: 0.1503 | Val Loss: 0.1082\n",
            "Epoch 58/80 - Train Loss: 0.1602 | Val Loss: 0.1113\n",
            "Epoch 59/80 - Train Loss: 0.1441 | Val Loss: 0.1252\n",
            "Epoch 60/80 - Train Loss: 0.1418 | Val Loss: 0.1051\n",
            "Epoch 61/80 - Train Loss: 0.1412 | Val Loss: 0.1133\n",
            "Epoch 62/80 - Train Loss: 0.1515 | Val Loss: 0.1048\n",
            "Epoch 63/80 - Train Loss: 0.1375 | Val Loss: 0.1109\n",
            "Epoch 64/80 - Train Loss: 0.1314 | Val Loss: 0.1081\n",
            "Epoch 65/80 - Train Loss: 0.1410 | Val Loss: 0.1162\n",
            "Epoch 66/80 - Train Loss: 0.1208 | Val Loss: 0.1086\n",
            "Epoch 67/80 - Train Loss: 0.1443 | Val Loss: 0.1196\n",
            "Epoch 68/80 - Train Loss: 0.1278 | Val Loss: 0.1162\n",
            "Epoch 69/80 - Train Loss: 0.1210 | Val Loss: 0.1085\n",
            "Epoch 70/80 - Train Loss: 0.1153 | Val Loss: 0.1028\n",
            "Epoch 71/80 - Train Loss: 0.1139 | Val Loss: 0.0938\n",
            "✔️ Best model saved at epoch 71\n",
            "Epoch 72/80 - Train Loss: 0.1188 | Val Loss: 0.1057\n",
            "Epoch 73/80 - Train Loss: 0.1111 | Val Loss: 0.1032\n",
            "Epoch 74/80 - Train Loss: 0.1072 | Val Loss: 0.1072\n",
            "Epoch 75/80 - Train Loss: 0.1032 | Val Loss: 0.0995\n",
            "Epoch 76/80 - Train Loss: 0.1003 | Val Loss: 0.1407\n",
            "Epoch 77/80 - Train Loss: 0.1197 | Val Loss: 0.1081\n",
            "Epoch 78/80 - Train Loss: 0.1144 | Val Loss: 0.1053\n",
            "Epoch 79/80 - Train Loss: 0.1026 | Val Loss: 0.0950\n",
            "Epoch 80/80 - Train Loss: 0.1048 | Val Loss: 0.1244\n",
            "Evaluation Metrics:\n",
            "pixel_accuracy: 0.9778587828291223\n",
            "precision: [0.98631274 0.80990242 0.99718739 0.86959895]\n",
            "recall: [0.99048602 0.87585064 0.39487766 0.66378781]\n",
            "f1_score: [0.98839497 0.84158655 0.56573078 0.75288139]\n",
            "iou: [0.97705621 0.7264993  0.39443835 0.6036967 ]\n",
            "dice_score: [0.98839497 0.84158655 0.56573078 0.75288139]\n",
            "Total params: 34,878,768\n",
            "Model size: 133.05 MB\n"
          ]
        }
      ],
      "source": [
        "# run training\n",
        "!python train.py \\\n",
        "  --model attunet \\\n",
        "  --data-dir data \\\n",
        "  --output-dir /content/Finaldraft/outputs \\\n",
        "  --img-size 640 \\\n",
        "  --batch-size 8 \\\n",
        "  --epochs 80 \\\n",
        "  --lr 1e-4 \\\n",
        "  --patience 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1yhbWvvU0JD"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "shutil.rmtree('/content/Finaldraft/outputs/resunet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDxkl7CbhWNn",
        "outputId": "300433e7-d9c5-457b-e0de-2e2c2349ac5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:111: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "Epoch 1/80 - Train Loss: 0.9941 | Val Loss: 0.9063\n",
            "✔️ Best model saved at epoch 1\n",
            "Epoch 2/80 - Train Loss: 0.7542 | Val Loss: 0.6576\n",
            "✔️ Best model saved at epoch 2\n",
            "Epoch 3/80 - Train Loss: 0.5635 | Val Loss: 0.4814\n",
            "✔️ Best model saved at epoch 3\n",
            "Epoch 4/80 - Train Loss: 0.4710 | Val Loss: 0.3080\n",
            "✔️ Best model saved at epoch 4\n",
            "Epoch 5/80 - Train Loss: 0.4093 | Val Loss: 0.2964\n",
            "✔️ Best model saved at epoch 5\n",
            "Epoch 6/80 - Train Loss: 0.3785 | Val Loss: 0.2508\n",
            "✔️ Best model saved at epoch 6\n",
            "Epoch 7/80 - Train Loss: 0.3441 | Val Loss: 0.2011\n",
            "✔️ Best model saved at epoch 7\n",
            "Epoch 8/80 - Train Loss: 0.3056 | Val Loss: 0.1833\n",
            "✔️ Best model saved at epoch 8\n",
            "Epoch 9/80 - Train Loss: 0.3075 | Val Loss: 0.1728\n",
            "✔️ Best model saved at epoch 9\n",
            "Epoch 10/80 - Train Loss: 0.2629 | Val Loss: 0.1544\n",
            "✔️ Best model saved at epoch 10\n",
            "Epoch 11/80 - Train Loss: 0.2700 | Val Loss: 0.1524\n",
            "✔️ Best model saved at epoch 11\n",
            "Epoch 12/80 - Train Loss: 0.2493 | Val Loss: 0.1555\n",
            "Epoch 13/80 - Train Loss: 0.2270 | Val Loss: 0.1331\n",
            "✔️ Best model saved at epoch 13\n",
            "Epoch 14/80 - Train Loss: 0.1984 | Val Loss: 0.1213\n",
            "✔️ Best model saved at epoch 14\n",
            "Epoch 15/80 - Train Loss: 0.2087 | Val Loss: 0.1294\n",
            "Epoch 16/80 - Train Loss: 0.1876 | Val Loss: 0.1248\n",
            "Epoch 17/80 - Train Loss: 0.1756 | Val Loss: 0.1078\n",
            "✔️ Best model saved at epoch 17\n",
            "Epoch 18/80 - Train Loss: 0.1612 | Val Loss: 0.1053\n",
            "✔️ Best model saved at epoch 18\n",
            "Epoch 19/80 - Train Loss: 0.1526 | Val Loss: 0.1253\n",
            "Epoch 20/80 - Train Loss: 0.1477 | Val Loss: 0.1071\n",
            "Epoch 21/80 - Train Loss: 0.1427 | Val Loss: 0.1054\n",
            "Epoch 22/80 - Train Loss: 0.1472 | Val Loss: 0.1040\n",
            "✔️ Best model saved at epoch 22\n",
            "Epoch 23/80 - Train Loss: 0.1455 | Val Loss: 0.1171\n",
            "Epoch 24/80 - Train Loss: 0.1231 | Val Loss: 0.1003\n",
            "✔️ Best model saved at epoch 24\n",
            "Epoch 25/80 - Train Loss: 0.1327 | Val Loss: 0.1518\n",
            "Epoch 26/80 - Train Loss: 0.1234 | Val Loss: 0.0879\n",
            "✔️ Best model saved at epoch 26\n",
            "Epoch 27/80 - Train Loss: 0.1210 | Val Loss: 0.1002\n",
            "Epoch 28/80 - Train Loss: 0.1108 | Val Loss: 0.0957\n",
            "Epoch 29/80 - Train Loss: 0.1107 | Val Loss: 0.0965\n",
            "Epoch 30/80 - Train Loss: 0.1054 | Val Loss: 0.0935\n",
            "Epoch 31/80 - Train Loss: 0.1028 | Val Loss: 0.0872\n",
            "✔️ Best model saved at epoch 31\n",
            "Epoch 32/80 - Train Loss: 0.0898 | Val Loss: 0.0976\n",
            "Epoch 33/80 - Train Loss: 0.0957 | Val Loss: 0.0876\n",
            "Epoch 34/80 - Train Loss: 0.0995 | Val Loss: 0.0804\n",
            "✔️ Best model saved at epoch 34\n",
            "Epoch 35/80 - Train Loss: 0.0845 | Val Loss: 0.0888\n",
            "Epoch 36/80 - Train Loss: 0.0846 | Val Loss: 0.0816\n",
            "Epoch 37/80 - Train Loss: 0.0847 | Val Loss: 0.0899\n",
            "Epoch 38/80 - Train Loss: 0.0851 | Val Loss: 0.0965\n",
            "Epoch 39/80 - Train Loss: 0.0862 | Val Loss: 0.0805\n",
            "Epoch 40/80 - Train Loss: 0.0813 | Val Loss: 0.0800\n",
            "✔️ Best model saved at epoch 40\n",
            "Epoch 41/80 - Train Loss: 0.0752 | Val Loss: 0.0760\n",
            "✔️ Best model saved at epoch 41\n",
            "Epoch 42/80 - Train Loss: 0.0901 | Val Loss: 0.0819\n",
            "Epoch 43/80 - Train Loss: 0.0832 | Val Loss: 0.0853\n",
            "Epoch 44/80 - Train Loss: 0.0734 | Val Loss: 0.0869\n",
            "Epoch 45/80 - Train Loss: 0.0770 | Val Loss: 0.0986\n",
            "Epoch 46/80 - Train Loss: 0.0762 | Val Loss: 0.0939\n",
            "Epoch 47/80 - Train Loss: 0.0746 | Val Loss: 0.0819\n",
            "Epoch 48/80 - Train Loss: 0.0690 | Val Loss: 0.0759\n",
            "✔️ Best model saved at epoch 48\n",
            "Epoch 49/80 - Train Loss: 0.0693 | Val Loss: 0.0818\n",
            "Epoch 50/80 - Train Loss: 0.0641 | Val Loss: 0.0822\n",
            "Epoch 51/80 - Train Loss: 0.0640 | Val Loss: 0.0784\n",
            "Epoch 52/80 - Train Loss: 0.0666 | Val Loss: 0.0844\n",
            "Epoch 53/80 - Train Loss: 0.0695 | Val Loss: 0.0774\n",
            "Epoch 54/80 - Train Loss: 0.0664 | Val Loss: 0.0815\n",
            "Epoch 55/80 - Train Loss: 0.0743 | Val Loss: 0.0869\n",
            "Epoch 56/80 - Train Loss: 0.0684 | Val Loss: 0.0987\n",
            "Epoch 57/80 - Train Loss: 0.0650 | Val Loss: 0.0768\n",
            "Epoch 58/80 - Train Loss: 0.0601 | Val Loss: 0.0747\n",
            "✔️ Best model saved at epoch 58\n",
            "Epoch 59/80 - Train Loss: 0.0936 | Val Loss: 0.0751\n",
            "Epoch 60/80 - Train Loss: 0.0665 | Val Loss: 0.0742\n",
            "✔️ Best model saved at epoch 60\n",
            "Epoch 61/80 - Train Loss: 0.0661 | Val Loss: 0.0723\n",
            "✔️ Best model saved at epoch 61\n",
            "Epoch 62/80 - Train Loss: 0.0597 | Val Loss: 0.0704\n",
            "✔️ Best model saved at epoch 62\n",
            "Epoch 63/80 - Train Loss: 0.0584 | Val Loss: 0.0762\n",
            "Epoch 64/80 - Train Loss: 0.0615 | Val Loss: 0.0743\n",
            "Epoch 65/80 - Train Loss: 0.0680 | Val Loss: 0.0742\n",
            "Epoch 66/80 - Train Loss: 0.0678 | Val Loss: 0.0831\n",
            "Epoch 67/80 - Train Loss: 0.0649 | Val Loss: 0.0877\n",
            "Epoch 68/80 - Train Loss: 0.0606 | Val Loss: 0.0895\n",
            "Epoch 69/80 - Train Loss: 0.0708 | Val Loss: 0.0765\n",
            "Epoch 70/80 - Train Loss: 0.0645 | Val Loss: 0.0752\n",
            "Epoch 71/80 - Train Loss: 0.0655 | Val Loss: 0.0846\n",
            "Epoch 72/80 - Train Loss: 0.0631 | Val Loss: 0.0904\n",
            "Epoch 73/80 - Train Loss: 0.0629 | Val Loss: 0.0757\n",
            "Epoch 74/80 - Train Loss: 0.0615 | Val Loss: 0.0694\n",
            "✔️ Best model saved at epoch 74\n",
            "Epoch 75/80 - Train Loss: 0.0576 | Val Loss: 0.0768\n",
            "Epoch 76/80 - Train Loss: 0.0562 | Val Loss: 0.0853\n",
            "Epoch 77/80 - Train Loss: 0.0559 | Val Loss: 0.0844\n",
            "Epoch 78/80 - Train Loss: 0.0613 | Val Loss: 0.0876\n",
            "Epoch 79/80 - Train Loss: 0.0543 | Val Loss: 0.0817\n",
            "Epoch 80/80 - Train Loss: 0.0529 | Val Loss: 0.0756\n",
            "Evaluation Metrics:\n",
            "pixel_accuracy: 0.9846031935671542\n",
            "precision: [0.98938198 0.90089992 0.89502543 0.87870109]\n",
            "recall: [0.99433532 0.879301   0.77002925 0.45591768]\n",
            "f1_score: [0.99185246 0.88996943 0.82783559 0.60034426]\n",
            "iou: [0.98383662 0.80175218 0.70624529 0.42892281]\n",
            "dice_score: [0.99185246 0.88996943 0.82783559 0.60034426]\n",
            "Total params: 22,438,228\n",
            "Model size: 85.60 MB\n"
          ]
        }
      ],
      "source": [
        "# run training\n",
        "!python train.py \\\n",
        "  --model deeplabv3plus_resnet34\\\n",
        "  --data-dir data \\\n",
        "  --output-dir /content/Finaldraft/outputs \\\n",
        "  --img-size 640 \\\n",
        "  --batch-size 8 \\\n",
        "  --epochs 80 \\\n",
        "  --lr 1e-4 \\\n",
        "  --patience 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bHPDE0oXou5",
        "outputId": "6c67f469-e0ae-4f85-deec-ff3f1ed8c0c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:111: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "Epoch 1/80 - Train Loss: 1.1542 | Val Loss: 1.0045\n",
            "✔️ Best model saved at epoch 1\n",
            "Epoch 2/80 - Train Loss: 0.8885 | Val Loss: 0.6010\n",
            "✔️ Best model saved at epoch 2\n",
            "Epoch 3/80 - Train Loss: 0.6833 | Val Loss: 0.4551\n",
            "✔️ Best model saved at epoch 3\n",
            "Epoch 4/80 - Train Loss: 0.5506 | Val Loss: 0.3561\n",
            "✔️ Best model saved at epoch 4\n",
            "Epoch 5/80 - Train Loss: 0.4654 | Val Loss: 0.3147\n",
            "✔️ Best model saved at epoch 5\n",
            "Epoch 6/80 - Train Loss: 0.4102 | Val Loss: 0.2642\n",
            "✔️ Best model saved at epoch 6\n",
            "Epoch 7/80 - Train Loss: 0.3975 | Val Loss: 0.2453\n",
            "✔️ Best model saved at epoch 7\n",
            "Epoch 8/80 - Train Loss: 0.3757 | Val Loss: 0.2283\n",
            "✔️ Best model saved at epoch 8\n",
            "Epoch 9/80 - Train Loss: 0.3522 | Val Loss: 0.2052\n",
            "✔️ Best model saved at epoch 9\n",
            "Epoch 10/80 - Train Loss: 0.3032 | Val Loss: 0.1901\n",
            "✔️ Best model saved at epoch 10\n",
            "Epoch 11/80 - Train Loss: 0.2958 | Val Loss: 0.1811\n",
            "✔️ Best model saved at epoch 11\n",
            "Epoch 12/80 - Train Loss: 0.2837 | Val Loss: 0.1740\n",
            "✔️ Best model saved at epoch 12\n",
            "Epoch 13/80 - Train Loss: 0.2609 | Val Loss: 0.1621\n",
            "✔️ Best model saved at epoch 13\n",
            "Epoch 14/80 - Train Loss: 0.2560 | Val Loss: 0.1477\n",
            "✔️ Best model saved at epoch 14\n",
            "Epoch 15/80 - Train Loss: 0.2369 | Val Loss: 0.1481\n",
            "Epoch 16/80 - Train Loss: 0.2327 | Val Loss: 0.1299\n",
            "✔️ Best model saved at epoch 16\n",
            "Epoch 17/80 - Train Loss: 0.2084 | Val Loss: 0.1230\n",
            "✔️ Best model saved at epoch 17\n",
            "Epoch 18/80 - Train Loss: 0.1976 | Val Loss: 0.1254\n",
            "Epoch 19/80 - Train Loss: 0.1888 | Val Loss: 0.1171\n",
            "✔️ Best model saved at epoch 19\n",
            "Epoch 20/80 - Train Loss: 0.1873 | Val Loss: 0.1129\n",
            "✔️ Best model saved at epoch 20\n",
            "Epoch 21/80 - Train Loss: 0.1609 | Val Loss: 0.1118\n",
            "✔️ Best model saved at epoch 21\n",
            "Epoch 22/80 - Train Loss: 0.1724 | Val Loss: 0.1121\n",
            "Epoch 23/80 - Train Loss: 0.1464 | Val Loss: 0.1116\n",
            "✔️ Best model saved at epoch 23\n",
            "Epoch 24/80 - Train Loss: 0.1443 | Val Loss: 0.1016\n",
            "✔️ Best model saved at epoch 24\n",
            "Epoch 25/80 - Train Loss: 0.1447 | Val Loss: 0.1083\n",
            "Epoch 26/80 - Train Loss: 0.1429 | Val Loss: 0.1025\n",
            "Epoch 27/80 - Train Loss: 0.1470 | Val Loss: 0.1081\n",
            "Epoch 28/80 - Train Loss: 0.1373 | Val Loss: 0.1144\n",
            "Epoch 29/80 - Train Loss: 0.1310 | Val Loss: 0.0997\n",
            "✔️ Best model saved at epoch 29\n",
            "Epoch 30/80 - Train Loss: 0.1204 | Val Loss: 0.0980\n",
            "✔️ Best model saved at epoch 30\n",
            "Epoch 31/80 - Train Loss: 0.1173 | Val Loss: 0.1027\n",
            "Epoch 32/80 - Train Loss: 0.1082 | Val Loss: 0.0895\n",
            "✔️ Best model saved at epoch 32\n",
            "Epoch 33/80 - Train Loss: 0.1200 | Val Loss: 0.0936\n",
            "Epoch 34/80 - Train Loss: 0.1083 | Val Loss: 0.0955\n",
            "Epoch 35/80 - Train Loss: 0.0919 | Val Loss: 0.0885\n",
            "✔️ Best model saved at epoch 35\n",
            "Epoch 36/80 - Train Loss: 0.1042 | Val Loss: 0.0882\n",
            "✔️ Best model saved at epoch 36\n",
            "Epoch 37/80 - Train Loss: 0.0991 | Val Loss: 0.0961\n",
            "Epoch 38/80 - Train Loss: 0.0947 | Val Loss: 0.0980\n",
            "Epoch 39/80 - Train Loss: 0.0926 | Val Loss: 0.0941\n",
            "Epoch 40/80 - Train Loss: 0.0910 | Val Loss: 0.0966\n",
            "Epoch 41/80 - Train Loss: 0.0878 | Val Loss: 0.0812\n",
            "✔️ Best model saved at epoch 41\n",
            "Epoch 42/80 - Train Loss: 0.0972 | Val Loss: 0.0935\n",
            "Epoch 43/80 - Train Loss: 0.0946 | Val Loss: 0.0922\n",
            "Epoch 44/80 - Train Loss: 0.0971 | Val Loss: 0.0870\n",
            "Epoch 45/80 - Train Loss: 0.0914 | Val Loss: 0.0880\n",
            "Epoch 46/80 - Train Loss: 0.0902 | Val Loss: 0.1004\n",
            "Epoch 47/80 - Train Loss: 0.0841 | Val Loss: 0.0928\n",
            "Epoch 48/80 - Train Loss: 0.0869 | Val Loss: 0.0834\n",
            "Epoch 49/80 - Train Loss: 0.0764 | Val Loss: 0.0903\n",
            "Epoch 50/80 - Train Loss: 0.0836 | Val Loss: 0.0918\n",
            "Epoch 51/80 - Train Loss: 0.0781 | Val Loss: 0.0809\n",
            "✔️ Best model saved at epoch 51\n",
            "Epoch 52/80 - Train Loss: 0.0714 | Val Loss: 0.0975\n",
            "Epoch 53/80 - Train Loss: 0.0719 | Val Loss: 0.0837\n",
            "Epoch 54/80 - Train Loss: 0.0817 | Val Loss: 0.0942\n",
            "Epoch 55/80 - Train Loss: 0.0786 | Val Loss: 0.0902\n",
            "Epoch 56/80 - Train Loss: 0.0748 | Val Loss: 0.0944\n",
            "Epoch 57/80 - Train Loss: 0.0684 | Val Loss: 0.0846\n",
            "Epoch 58/80 - Train Loss: 0.0769 | Val Loss: 0.0973\n",
            "Epoch 59/80 - Train Loss: 0.0828 | Val Loss: 0.0811\n",
            "Epoch 60/80 - Train Loss: 0.0830 | Val Loss: 0.0877\n",
            "Epoch 61/80 - Train Loss: 0.0734 | Val Loss: 0.0794\n",
            "✔️ Best model saved at epoch 61\n",
            "Epoch 62/80 - Train Loss: 0.0677 | Val Loss: 0.0763\n",
            "✔️ Best model saved at epoch 62\n",
            "Epoch 63/80 - Train Loss: 0.0682 | Val Loss: 0.0802\n",
            "Epoch 64/80 - Train Loss: 0.0758 | Val Loss: 0.0875\n",
            "Epoch 65/80 - Train Loss: 0.0697 | Val Loss: 0.0814\n",
            "Epoch 66/80 - Train Loss: 0.0729 | Val Loss: 0.0795\n",
            "Epoch 67/80 - Train Loss: 0.0711 | Val Loss: 0.0884\n",
            "Epoch 68/80 - Train Loss: 0.0670 | Val Loss: 0.0740\n",
            "✔️ Best model saved at epoch 68\n",
            "Epoch 69/80 - Train Loss: 0.0685 | Val Loss: 0.0826\n",
            "Epoch 70/80 - Train Loss: 0.0675 | Val Loss: 0.0740\n",
            "✔️ Best model saved at epoch 70\n",
            "Epoch 71/80 - Train Loss: 0.0658 | Val Loss: 0.0772\n",
            "Epoch 72/80 - Train Loss: 0.0665 | Val Loss: 0.0870\n",
            "Epoch 73/80 - Train Loss: 0.0657 | Val Loss: 0.0729\n",
            "✔️ Best model saved at epoch 73\n",
            "Epoch 74/80 - Train Loss: 0.0666 | Val Loss: 0.0901\n",
            "Epoch 75/80 - Train Loss: 0.0613 | Val Loss: 0.0801\n",
            "Epoch 76/80 - Train Loss: 0.0658 | Val Loss: 0.0851\n",
            "Epoch 77/80 - Train Loss: 0.0656 | Val Loss: 0.0664\n",
            "✔️ Best model saved at epoch 77\n",
            "Epoch 78/80 - Train Loss: 0.0621 | Val Loss: 0.0768\n",
            "Epoch 79/80 - Train Loss: 0.0577 | Val Loss: 0.0751\n",
            "Epoch 80/80 - Train Loss: 0.0600 | Val Loss: 0.0705\n",
            "Evaluation Metrics:\n",
            "pixel_accuracy: 0.9852392058676862\n",
            "precision: [0.98700502 0.95855427 0.9374233  0.89334378]\n",
            "recall: [0.99747181 0.81052784 0.70705931 0.7259198 ]\n",
            "f1_score: [0.99221081 0.87834806 0.80610626 0.80097637]\n",
            "iou: [0.98454203 0.78308433 0.67519097 0.66802385]\n",
            "dice_score: [0.99221081 0.87834806 0.80610626 0.80097637]\n",
            "Total params: 4,136,820\n",
            "Model size: 15.78 MB\n"
          ]
        }
      ],
      "source": [
        "# run training\n",
        "!python train.py \\\n",
        "  --model deeplabv3plus_mit_b0\\\n",
        "  --data-dir data \\\n",
        "  --output-dir /content/Finaldraft/outputs \\\n",
        "  --img-size 640 \\\n",
        "  --batch-size 8 \\\n",
        "  --epochs 80 \\\n",
        "  --lr 1e-4 \\\n",
        "  --patience 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGVqN8j2pQ3_",
        "outputId": "71a4e13f-e9f0-46a7-ac11-2a873625b560"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:111: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "Epoch 1/80 - Train Loss: 1.0457 | Val Loss: 0.7380\n",
            "✔️ Best model saved at epoch 1\n",
            "Epoch 2/80 - Train Loss: 0.8922 | Val Loss: 0.7202\n",
            "✔️ Best model saved at epoch 2\n",
            "Epoch 3/80 - Train Loss: 0.8431 | Val Loss: 0.7407\n",
            "Epoch 4/80 - Train Loss: 0.8106 | Val Loss: 0.6767\n",
            "✔️ Best model saved at epoch 4\n",
            "Epoch 5/80 - Train Loss: 0.7646 | Val Loss: 0.6274\n",
            "✔️ Best model saved at epoch 5\n",
            "Epoch 6/80 - Train Loss: 0.7690 | Val Loss: 0.6811\n",
            "Epoch 7/80 - Train Loss: 0.7504 | Val Loss: 0.5749\n",
            "✔️ Best model saved at epoch 7\n",
            "Epoch 8/80 - Train Loss: 0.7247 | Val Loss: 0.5632\n",
            "✔️ Best model saved at epoch 8\n",
            "Epoch 9/80 - Train Loss: 0.6972 | Val Loss: 0.5158\n",
            "✔️ Best model saved at epoch 9\n",
            "Epoch 10/80 - Train Loss: 0.6759 | Val Loss: 0.5108\n",
            "✔️ Best model saved at epoch 10\n",
            "Epoch 11/80 - Train Loss: 0.6496 | Val Loss: 0.5170\n",
            "Epoch 12/80 - Train Loss: 0.6456 | Val Loss: 0.5033\n",
            "✔️ Best model saved at epoch 12\n",
            "Epoch 13/80 - Train Loss: 0.6318 | Val Loss: 0.4687\n",
            "✔️ Best model saved at epoch 13\n",
            "Epoch 14/80 - Train Loss: 0.6264 | Val Loss: 0.4799\n",
            "Epoch 15/80 - Train Loss: 0.6041 | Val Loss: 0.4723\n",
            "Epoch 16/80 - Train Loss: 0.5834 | Val Loss: 0.4736\n",
            "Epoch 17/80 - Train Loss: 0.5789 | Val Loss: 0.4066\n",
            "✔️ Best model saved at epoch 17\n",
            "Epoch 18/80 - Train Loss: 0.5707 | Val Loss: 0.4381\n",
            "Epoch 19/80 - Train Loss: 0.5574 | Val Loss: 0.4022\n",
            "✔️ Best model saved at epoch 19\n",
            "Epoch 20/80 - Train Loss: 0.5381 | Val Loss: 0.3752\n",
            "✔️ Best model saved at epoch 20\n",
            "Epoch 21/80 - Train Loss: 0.5413 | Val Loss: 0.3906\n",
            "Epoch 22/80 - Train Loss: 0.5253 | Val Loss: 0.3662\n",
            "✔️ Best model saved at epoch 22\n",
            "Epoch 23/80 - Train Loss: 0.5303 | Val Loss: 0.4065\n",
            "Epoch 24/80 - Train Loss: 0.5074 | Val Loss: 0.3594\n",
            "✔️ Best model saved at epoch 24\n",
            "Epoch 25/80 - Train Loss: 0.5033 | Val Loss: 0.3426\n",
            "✔️ Best model saved at epoch 25\n",
            "Epoch 26/80 - Train Loss: 0.4890 | Val Loss: 0.3362\n",
            "✔️ Best model saved at epoch 26\n",
            "Epoch 27/80 - Train Loss: 0.4903 | Val Loss: 0.3585\n",
            "Epoch 28/80 - Train Loss: 0.4786 | Val Loss: 0.3206\n",
            "✔️ Best model saved at epoch 28\n",
            "Epoch 29/80 - Train Loss: 0.4641 | Val Loss: 0.3630\n",
            "Epoch 30/80 - Train Loss: 0.4777 | Val Loss: 0.3127\n",
            "✔️ Best model saved at epoch 30\n",
            "Epoch 31/80 - Train Loss: 0.4614 | Val Loss: 0.2999\n",
            "✔️ Best model saved at epoch 31\n",
            "Epoch 32/80 - Train Loss: 0.4758 | Val Loss: 0.3067\n",
            "Epoch 33/80 - Train Loss: 0.4694 | Val Loss: 0.2959\n",
            "✔️ Best model saved at epoch 33\n",
            "Epoch 34/80 - Train Loss: 0.4631 | Val Loss: 0.2871\n",
            "✔️ Best model saved at epoch 34\n",
            "Epoch 35/80 - Train Loss: 0.4550 | Val Loss: 0.2902\n",
            "Epoch 36/80 - Train Loss: 0.4271 | Val Loss: 0.3320\n",
            "Epoch 37/80 - Train Loss: 0.4358 | Val Loss: 0.2913\n",
            "Epoch 38/80 - Train Loss: 0.4411 | Val Loss: 0.2723\n",
            "✔️ Best model saved at epoch 38\n",
            "Epoch 39/80 - Train Loss: 0.4209 | Val Loss: 0.2723\n",
            "Epoch 40/80 - Train Loss: 0.4146 | Val Loss: 0.2739\n",
            "Epoch 41/80 - Train Loss: 0.4244 | Val Loss: 0.2669\n",
            "✔️ Best model saved at epoch 41\n",
            "Epoch 42/80 - Train Loss: 0.4194 | Val Loss: 0.2740\n",
            "Epoch 43/80 - Train Loss: 0.3972 | Val Loss: 0.2687\n",
            "Epoch 44/80 - Train Loss: 0.4005 | Val Loss: 0.2613\n",
            "✔️ Best model saved at epoch 44\n",
            "Epoch 45/80 - Train Loss: 0.4102 | Val Loss: 0.2493\n",
            "✔️ Best model saved at epoch 45\n",
            "Epoch 46/80 - Train Loss: 0.3811 | Val Loss: 0.2807\n",
            "Epoch 47/80 - Train Loss: 0.4059 | Val Loss: 0.2897\n",
            "Epoch 48/80 - Train Loss: 0.3690 | Val Loss: 0.2407\n",
            "✔️ Best model saved at epoch 48\n",
            "Epoch 49/80 - Train Loss: 0.3698 | Val Loss: 0.2512\n",
            "Epoch 50/80 - Train Loss: 0.3731 | Val Loss: 0.2475\n",
            "Epoch 51/80 - Train Loss: 0.3751 | Val Loss: 0.2345\n",
            "✔️ Best model saved at epoch 51\n",
            "Epoch 52/80 - Train Loss: 0.3876 | Val Loss: 0.2407\n",
            "Epoch 53/80 - Train Loss: 0.3710 | Val Loss: 0.2516\n",
            "Epoch 54/80 - Train Loss: 0.3555 | Val Loss: 0.2348\n",
            "Epoch 55/80 - Train Loss: 0.3606 | Val Loss: 0.2116\n",
            "✔️ Best model saved at epoch 55\n",
            "Epoch 56/80 - Train Loss: 0.3296 | Val Loss: 0.2210\n",
            "Epoch 57/80 - Train Loss: 0.3425 | Val Loss: 0.2124\n",
            "Epoch 58/80 - Train Loss: 0.3288 | Val Loss: 0.2474\n",
            "Epoch 59/80 - Train Loss: 0.3310 | Val Loss: 0.2443\n",
            "Epoch 60/80 - Train Loss: 0.3286 | Val Loss: 0.2396\n",
            "Epoch 61/80 - Train Loss: 0.3386 | Val Loss: 0.2035\n",
            "✔️ Best model saved at epoch 61\n",
            "Epoch 62/80 - Train Loss: 0.3079 | Val Loss: 0.1919\n",
            "✔️ Best model saved at epoch 62\n",
            "Epoch 63/80 - Train Loss: 0.2968 | Val Loss: 0.1989\n",
            "Epoch 64/80 - Train Loss: 0.2983 | Val Loss: 0.2224\n",
            "Epoch 65/80 - Train Loss: 0.3108 | Val Loss: 0.1993\n",
            "Epoch 66/80 - Train Loss: 0.3032 | Val Loss: 0.1754\n",
            "✔️ Best model saved at epoch 66\n",
            "Epoch 67/80 - Train Loss: 0.3050 | Val Loss: 0.1991\n",
            "Epoch 68/80 - Train Loss: 0.2959 | Val Loss: 0.1841\n",
            "Epoch 69/80 - Train Loss: 0.2840 | Val Loss: 0.1870\n",
            "Epoch 70/80 - Train Loss: 0.2835 | Val Loss: 0.2349\n",
            "Epoch 71/80 - Train Loss: 0.2683 | Val Loss: 0.1670\n",
            "✔️ Best model saved at epoch 71\n",
            "Epoch 72/80 - Train Loss: 0.2926 | Val Loss: 0.1994\n",
            "Epoch 73/80 - Train Loss: 0.2712 | Val Loss: 0.2028\n",
            "Epoch 74/80 - Train Loss: 0.2635 | Val Loss: 0.1770\n",
            "Epoch 75/80 - Train Loss: 0.2500 | Val Loss: 0.1783\n",
            "Epoch 76/80 - Train Loss: 0.2520 | Val Loss: 0.1690\n",
            "Epoch 77/80 - Train Loss: 0.2605 | Val Loss: 0.1738\n",
            "Epoch 78/80 - Train Loss: 0.2505 | Val Loss: 0.1665\n",
            "✔️ Best model saved at epoch 78\n",
            "Epoch 79/80 - Train Loss: 0.2409 | Val Loss: 0.1588\n",
            "✔️ Best model saved at epoch 79\n",
            "Epoch 80/80 - Train Loss: 0.2288 | Val Loss: 0.1662\n",
            "Evaluation Metrics:\n",
            "pixel_accuracy: 0.9630413169049202\n",
            "precision: [0.98083646 0.64237126 0.90477525 0.84931605]\n",
            "recall: [0.980281   0.76822503 0.5113431  0.26361128]\n",
            "f1_score: [0.98055865 0.69968379 0.65340666 0.40234305]\n",
            "iou: [0.96185882 0.53808742 0.48522939 0.25183319]\n",
            "dice_score: [0.98055865 0.69968379 0.65340666 0.40234305]\n",
            "Total params: 15,112,876\n",
            "Model size: 57.65 MB\n"
          ]
        }
      ],
      "source": [
        "# run training\n",
        "!python train.py \\\n",
        "  --model unet_mobilenet \\\n",
        "  --data-dir data \\\n",
        "  --output-dir /content/Finaldraft/outputs \\\n",
        "  --img-size 640 \\\n",
        "  --batch-size 8 \\\n",
        "  --epochs 80 \\\n",
        "  --lr 1e-4 \\\n",
        "  --patience 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxTaOCBagorJ",
        "outputId": "3205f591-12a1-49ee-cf22-645ca3be4f64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:111: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "Epoch 1/80 - Train Loss: 0.7743 | Val Loss: 0.5656\n",
            "✔️ Best model saved at epoch 1\n",
            "Epoch 2/80 - Train Loss: 0.5452 | Val Loss: 0.3760\n",
            "✔️ Best model saved at epoch 2\n",
            "Epoch 3/80 - Train Loss: 0.5029 | Val Loss: 0.3205\n",
            "✔️ Best model saved at epoch 3\n",
            "Epoch 4/80 - Train Loss: 0.4866 | Val Loss: 0.3208\n",
            "Epoch 5/80 - Train Loss: 0.4852 | Val Loss: 0.3418\n",
            "Epoch 6/80 - Train Loss: 0.4707 | Val Loss: 0.3100\n",
            "✔️ Best model saved at epoch 6\n",
            "Epoch 7/80 - Train Loss: 0.4642 | Val Loss: 0.3340\n",
            "Epoch 8/80 - Train Loss: 0.4556 | Val Loss: 0.3044\n",
            "✔️ Best model saved at epoch 8\n",
            "Epoch 9/80 - Train Loss: 0.4567 | Val Loss: 0.2948\n",
            "✔️ Best model saved at epoch 9\n",
            "Epoch 10/80 - Train Loss: 0.4281 | Val Loss: 0.3038\n",
            "Epoch 11/80 - Train Loss: 0.4216 | Val Loss: 0.2979\n",
            "Epoch 12/80 - Train Loss: 0.4155 | Val Loss: 0.2682\n",
            "✔️ Best model saved at epoch 12\n",
            "Epoch 13/80 - Train Loss: 0.3965 | Val Loss: 0.3055\n",
            "Epoch 14/80 - Train Loss: 0.3911 | Val Loss: 0.2980\n",
            "Epoch 15/80 - Train Loss: 0.4023 | Val Loss: 0.3173\n",
            "Epoch 16/80 - Train Loss: 0.4129 | Val Loss: 0.2714\n",
            "Epoch 17/80 - Train Loss: 0.3778 | Val Loss: 0.2837\n",
            "Epoch 18/80 - Train Loss: 0.3996 | Val Loss: 0.4802\n",
            "Epoch 19/80 - Train Loss: 0.3928 | Val Loss: 0.2404\n",
            "✔️ Best model saved at epoch 19\n",
            "Epoch 20/80 - Train Loss: 0.3551 | Val Loss: 0.2443\n",
            "Epoch 21/80 - Train Loss: 0.3643 | Val Loss: 0.2351\n",
            "✔️ Best model saved at epoch 21\n",
            "Epoch 22/80 - Train Loss: 0.3631 | Val Loss: 0.2496\n",
            "Epoch 23/80 - Train Loss: 0.3425 | Val Loss: 0.2184\n",
            "✔️ Best model saved at epoch 23\n",
            "Epoch 24/80 - Train Loss: 0.3480 | Val Loss: 0.2372\n",
            "Epoch 25/80 - Train Loss: 0.3407 | Val Loss: 0.2740\n",
            "Epoch 26/80 - Train Loss: 0.3422 | Val Loss: 0.2671\n",
            "Epoch 27/80 - Train Loss: 0.3347 | Val Loss: 0.2678\n",
            "Epoch 28/80 - Train Loss: 0.3014 | Val Loss: 0.2020\n",
            "✔️ Best model saved at epoch 28\n",
            "Epoch 29/80 - Train Loss: 0.3120 | Val Loss: 0.2499\n",
            "Epoch 30/80 - Train Loss: 0.2836 | Val Loss: 0.2992\n",
            "Epoch 31/80 - Train Loss: 0.3040 | Val Loss: 0.1989\n",
            "✔️ Best model saved at epoch 31\n",
            "Epoch 32/80 - Train Loss: 0.2797 | Val Loss: 0.1964\n",
            "✔️ Best model saved at epoch 32\n",
            "Epoch 33/80 - Train Loss: 0.2908 | Val Loss: 0.1952\n",
            "✔️ Best model saved at epoch 33\n",
            "Epoch 34/80 - Train Loss: 0.3099 | Val Loss: 0.2174\n",
            "Epoch 35/80 - Train Loss: 0.2854 | Val Loss: 0.1873\n",
            "✔️ Best model saved at epoch 35\n",
            "Epoch 36/80 - Train Loss: 0.2940 | Val Loss: 0.2565\n",
            "Epoch 37/80 - Train Loss: 0.2864 | Val Loss: 0.2274\n",
            "Epoch 38/80 - Train Loss: 0.2881 | Val Loss: 0.1863\n",
            "✔️ Best model saved at epoch 38\n",
            "Epoch 39/80 - Train Loss: 0.2652 | Val Loss: 0.1815\n",
            "✔️ Best model saved at epoch 39\n",
            "Epoch 40/80 - Train Loss: 0.2724 | Val Loss: 0.2309\n",
            "Epoch 41/80 - Train Loss: 0.2727 | Val Loss: 0.1882\n",
            "Epoch 42/80 - Train Loss: 0.2632 | Val Loss: 0.2066\n",
            "Epoch 43/80 - Train Loss: 0.2446 | Val Loss: 0.1915\n",
            "Epoch 44/80 - Train Loss: 0.2563 | Val Loss: 0.2455\n",
            "Epoch 45/80 - Train Loss: 0.2274 | Val Loss: 0.1544\n",
            "✔️ Best model saved at epoch 45\n",
            "Epoch 46/80 - Train Loss: 0.2336 | Val Loss: 0.2315\n",
            "Epoch 47/80 - Train Loss: 0.2390 | Val Loss: 0.1623\n",
            "Epoch 48/80 - Train Loss: 0.2526 | Val Loss: 0.1743\n",
            "Epoch 49/80 - Train Loss: 0.2331 | Val Loss: 0.1614\n",
            "Epoch 50/80 - Train Loss: 0.2117 | Val Loss: 0.1891\n",
            "Epoch 51/80 - Train Loss: 0.2255 | Val Loss: 0.1643\n",
            "Epoch 52/80 - Train Loss: 0.2129 | Val Loss: 0.1833\n",
            "Epoch 53/80 - Train Loss: 0.2289 | Val Loss: 0.1706\n",
            "Epoch 54/80 - Train Loss: 0.2112 | Val Loss: 0.1732\n",
            "Epoch 55/80 - Train Loss: 0.2183 | Val Loss: 0.1554\n",
            "Epoch 56/80 - Train Loss: 0.2186 | Val Loss: 0.1706\n",
            "Epoch 57/80 - Train Loss: 0.2071 | Val Loss: 0.1409\n",
            "✔️ Best model saved at epoch 57\n",
            "Epoch 58/80 - Train Loss: 0.1981 | Val Loss: 0.1635\n",
            "Epoch 59/80 - Train Loss: 0.1931 | Val Loss: 0.1410\n",
            "Epoch 60/80 - Train Loss: 0.2008 | Val Loss: 0.1452\n",
            "Epoch 61/80 - Train Loss: 0.1965 | Val Loss: 0.1778\n",
            "Epoch 62/80 - Train Loss: 0.2035 | Val Loss: 0.1862\n",
            "Epoch 63/80 - Train Loss: 0.2121 | Val Loss: 0.1602\n",
            "Epoch 64/80 - Train Loss: 0.1991 | Val Loss: 0.1476\n",
            "Epoch 65/80 - Train Loss: 0.1875 | Val Loss: 0.1457\n",
            "Epoch 66/80 - Train Loss: 0.1947 | Val Loss: 0.1600\n",
            "Epoch 67/80 - Train Loss: 0.1939 | Val Loss: 0.1411\n",
            "Epoch 68/80 - Train Loss: 0.1974 | Val Loss: 0.1600\n",
            "Epoch 69/80 - Train Loss: 0.1792 | Val Loss: 0.1346\n",
            "✔️ Best model saved at epoch 69\n",
            "Epoch 70/80 - Train Loss: 0.1836 | Val Loss: 0.1365\n",
            "Epoch 71/80 - Train Loss: 0.1778 | Val Loss: 0.1737\n",
            "Epoch 72/80 - Train Loss: 0.1940 | Val Loss: 0.1450\n",
            "Epoch 73/80 - Train Loss: 0.1847 | Val Loss: 0.1395\n",
            "Epoch 74/80 - Train Loss: 0.1822 | Val Loss: 0.1350\n",
            "Epoch 75/80 - Train Loss: 0.1657 | Val Loss: 0.1589\n",
            "Epoch 76/80 - Train Loss: 0.1840 | Val Loss: 0.1393\n",
            "Epoch 77/80 - Train Loss: 0.1902 | Val Loss: 0.1380\n",
            "Epoch 78/80 - Train Loss: 0.1840 | Val Loss: 0.1347\n",
            "Epoch 79/80 - Train Loss: 0.1815 | Val Loss: 0.1294\n",
            "✔️ Best model saved at epoch 79\n",
            "Epoch 80/80 - Train Loss: 0.1725 | Val Loss: 0.1636\n",
            "Evaluation Metrics:\n",
            "pixel_accuracy: 0.9617891352227393\n",
            "precision: [0.98202761 0.62336567 0.93692671 0.88376273]\n",
            "recall: [0.97745029 0.81644677 0.50258642 0.14831905]\n",
            "f1_score: [0.9797336  0.70695998 0.65423041 0.25400865]\n",
            "iou: [0.96027234 0.54674254 0.48613851 0.14548105]\n",
            "dice_score: [0.9797336  0.70695998 0.65423041 0.25400865]\n",
            "Total params: 13,043,204\n",
            "Model size: 49.76 MB\n"
          ]
        }
      ],
      "source": [
        "# run training\n",
        "!python train.py \\\n",
        "  --model resunet \\\n",
        "  --data-dir data \\\n",
        "  --output-dir /content/Finaldraft/outputs \\\n",
        "  --img-size 640 \\\n",
        "  --batch-size 8 \\\n",
        "  --epochs 80 \\\n",
        "  --lr 1e-4 \\\n",
        "  --patience 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxbudqkogzlC",
        "outputId": "f2939b73-b117-4e60-dd73-a733d51588fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:111: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "Epoch 1/80 - Train Loss: 1.1327 | Val Loss: 0.9174\n",
            "✔️ Best model saved at epoch 1\n",
            "Epoch 2/80 - Train Loss: 1.0099 | Val Loss: 0.8373\n",
            "✔️ Best model saved at epoch 2\n",
            "Epoch 3/80 - Train Loss: 0.9511 | Val Loss: 0.8242\n",
            "✔️ Best model saved at epoch 3\n",
            "Epoch 4/80 - Train Loss: 0.9266 | Val Loss: 0.7697\n",
            "✔️ Best model saved at epoch 4\n",
            "Epoch 5/80 - Train Loss: 0.9080 | Val Loss: 0.7456\n",
            "✔️ Best model saved at epoch 5\n",
            "Epoch 6/80 - Train Loss: 0.8712 | Val Loss: 0.7439\n",
            "✔️ Best model saved at epoch 6\n",
            "Epoch 7/80 - Train Loss: 0.8722 | Val Loss: 0.7150\n",
            "✔️ Best model saved at epoch 7\n",
            "Epoch 8/80 - Train Loss: 0.8427 | Val Loss: 0.6874\n",
            "✔️ Best model saved at epoch 8\n",
            "Epoch 9/80 - Train Loss: 0.8359 | Val Loss: 1.0940\n",
            "Epoch 10/80 - Train Loss: 0.8327 | Val Loss: 0.7207\n",
            "Epoch 11/80 - Train Loss: 0.8019 | Val Loss: 0.6600\n",
            "✔️ Best model saved at epoch 11\n",
            "Epoch 12/80 - Train Loss: 0.7786 | Val Loss: 0.6309\n",
            "✔️ Best model saved at epoch 12\n",
            "Epoch 13/80 - Train Loss: 0.7719 | Val Loss: 0.6391\n",
            "Epoch 14/80 - Train Loss: 0.7424 | Val Loss: 0.6003\n",
            "✔️ Best model saved at epoch 14\n",
            "Epoch 15/80 - Train Loss: 0.7189 | Val Loss: 0.5978\n",
            "✔️ Best model saved at epoch 15\n",
            "Epoch 16/80 - Train Loss: 0.7070 | Val Loss: 0.5645\n",
            "✔️ Best model saved at epoch 16\n",
            "Epoch 17/80 - Train Loss: 0.7055 | Val Loss: 0.5796\n",
            "Epoch 18/80 - Train Loss: 0.6857 | Val Loss: 0.5307\n",
            "✔️ Best model saved at epoch 18\n",
            "Epoch 19/80 - Train Loss: 0.6583 | Val Loss: 0.5295\n",
            "✔️ Best model saved at epoch 19\n",
            "Epoch 20/80 - Train Loss: 0.6631 | Val Loss: 0.4968\n",
            "✔️ Best model saved at epoch 20\n",
            "Epoch 21/80 - Train Loss: 0.6410 | Val Loss: 0.4975\n",
            "Epoch 22/80 - Train Loss: 0.6121 | Val Loss: 0.5287\n",
            "Epoch 23/80 - Train Loss: 0.6084 | Val Loss: 0.4818\n",
            "✔️ Best model saved at epoch 23\n",
            "Epoch 24/80 - Train Loss: 0.6161 | Val Loss: 0.4647\n",
            "✔️ Best model saved at epoch 24\n",
            "Epoch 25/80 - Train Loss: 0.5726 | Val Loss: 0.4459\n",
            "✔️ Best model saved at epoch 25\n",
            "Epoch 26/80 - Train Loss: 0.5722 | Val Loss: 0.4303\n",
            "✔️ Best model saved at epoch 26\n",
            "Epoch 27/80 - Train Loss: 0.5637 | Val Loss: 0.4089\n",
            "✔️ Best model saved at epoch 27\n",
            "Epoch 28/80 - Train Loss: 0.5412 | Val Loss: 0.4070\n",
            "✔️ Best model saved at epoch 28\n",
            "Epoch 29/80 - Train Loss: 0.5395 | Val Loss: 0.3971\n",
            "✔️ Best model saved at epoch 29\n",
            "Epoch 30/80 - Train Loss: 0.5205 | Val Loss: 0.4052\n",
            "Epoch 31/80 - Train Loss: 0.5280 | Val Loss: 0.3680\n",
            "✔️ Best model saved at epoch 31\n",
            "Epoch 32/80 - Train Loss: 0.4961 | Val Loss: 0.3652\n",
            "✔️ Best model saved at epoch 32\n",
            "Epoch 33/80 - Train Loss: 0.4858 | Val Loss: 0.3636\n",
            "✔️ Best model saved at epoch 33\n",
            "Epoch 34/80 - Train Loss: 0.4807 | Val Loss: 0.3426\n",
            "✔️ Best model saved at epoch 34\n",
            "Epoch 35/80 - Train Loss: 0.4862 | Val Loss: 0.3341\n",
            "✔️ Best model saved at epoch 35\n",
            "Epoch 36/80 - Train Loss: 0.4616 | Val Loss: 0.3174\n",
            "✔️ Best model saved at epoch 36\n",
            "Epoch 37/80 - Train Loss: 0.4530 | Val Loss: 0.3322\n",
            "Epoch 38/80 - Train Loss: 0.4414 | Val Loss: 0.3209\n",
            "Epoch 39/80 - Train Loss: 0.4443 | Val Loss: 0.3033\n",
            "✔️ Best model saved at epoch 39\n",
            "Epoch 40/80 - Train Loss: 0.4290 | Val Loss: 0.2835\n",
            "✔️ Best model saved at epoch 40\n",
            "Epoch 41/80 - Train Loss: 0.4056 | Val Loss: 0.2940\n",
            "Epoch 42/80 - Train Loss: 0.4076 | Val Loss: 0.2849\n",
            "Epoch 43/80 - Train Loss: 0.3849 | Val Loss: 0.2890\n",
            "Epoch 44/80 - Train Loss: 0.3897 | Val Loss: 0.2779\n",
            "✔️ Best model saved at epoch 44\n",
            "Epoch 45/80 - Train Loss: 0.3789 | Val Loss: 0.2591\n",
            "✔️ Best model saved at epoch 45\n",
            "Epoch 46/80 - Train Loss: 0.3701 | Val Loss: 0.2557\n",
            "✔️ Best model saved at epoch 46\n",
            "Epoch 47/80 - Train Loss: 0.3606 | Val Loss: 0.2669\n",
            "Epoch 48/80 - Train Loss: 0.3607 | Val Loss: 0.2464\n",
            "✔️ Best model saved at epoch 48\n",
            "Epoch 49/80 - Train Loss: 0.3637 | Val Loss: 0.2409\n",
            "✔️ Best model saved at epoch 49\n",
            "Epoch 50/80 - Train Loss: 0.3484 | Val Loss: 0.2436\n",
            "Epoch 51/80 - Train Loss: 0.3346 | Val Loss: 0.2365\n",
            "✔️ Best model saved at epoch 51\n",
            "Epoch 52/80 - Train Loss: 0.3413 | Val Loss: 0.2248\n",
            "✔️ Best model saved at epoch 52\n",
            "Epoch 53/80 - Train Loss: 0.3289 | Val Loss: 0.3185\n",
            "Epoch 54/80 - Train Loss: 0.3317 | Val Loss: 0.2518\n",
            "Epoch 55/80 - Train Loss: 0.2953 | Val Loss: 0.2323\n",
            "Epoch 56/80 - Train Loss: 0.3155 | Val Loss: 0.2191\n",
            "✔️ Best model saved at epoch 56\n",
            "Epoch 57/80 - Train Loss: 0.3111 | Val Loss: 0.2093\n",
            "✔️ Best model saved at epoch 57\n",
            "Epoch 58/80 - Train Loss: 0.3188 | Val Loss: 0.2178\n",
            "Epoch 59/80 - Train Loss: 0.3076 | Val Loss: 0.2143\n",
            "Epoch 60/80 - Train Loss: 0.2946 | Val Loss: 0.1963\n",
            "✔️ Best model saved at epoch 60\n",
            "Epoch 61/80 - Train Loss: 0.2905 | Val Loss: 0.2073\n",
            "Epoch 62/80 - Train Loss: 0.2974 | Val Loss: 0.1892\n",
            "✔️ Best model saved at epoch 62\n",
            "Epoch 63/80 - Train Loss: 0.2811 | Val Loss: 0.1866\n",
            "✔️ Best model saved at epoch 63\n",
            "Epoch 64/80 - Train Loss: 0.2832 | Val Loss: 0.1978\n",
            "Epoch 65/80 - Train Loss: 0.2827 | Val Loss: 0.1867\n",
            "Epoch 66/80 - Train Loss: 0.2643 | Val Loss: 0.1795\n",
            "✔️ Best model saved at epoch 66\n",
            "Epoch 67/80 - Train Loss: 0.2670 | Val Loss: 0.1784\n",
            "✔️ Best model saved at epoch 67\n",
            "Epoch 68/80 - Train Loss: 0.2731 | Val Loss: 0.1710\n",
            "✔️ Best model saved at epoch 68\n",
            "Epoch 69/80 - Train Loss: 0.2531 | Val Loss: 0.1801\n",
            "Epoch 70/80 - Train Loss: 0.2721 | Val Loss: 0.1616\n",
            "✔️ Best model saved at epoch 70\n",
            "Epoch 71/80 - Train Loss: 0.2548 | Val Loss: 0.1890\n",
            "Epoch 72/80 - Train Loss: 0.2607 | Val Loss: 0.1692\n",
            "Epoch 73/80 - Train Loss: 0.2433 | Val Loss: 0.1546\n",
            "✔️ Best model saved at epoch 73\n",
            "Epoch 74/80 - Train Loss: 0.2390 | Val Loss: 0.1598\n",
            "Epoch 75/80 - Train Loss: 0.2359 | Val Loss: 0.1499\n",
            "✔️ Best model saved at epoch 75\n",
            "Epoch 76/80 - Train Loss: 0.2270 | Val Loss: 0.1467\n",
            "✔️ Best model saved at epoch 76\n",
            "Epoch 77/80 - Train Loss: 0.2224 | Val Loss: 0.1517\n",
            "Epoch 78/80 - Train Loss: 0.2338 | Val Loss: 0.1529\n",
            "Epoch 79/80 - Train Loss: 0.2152 | Val Loss: 0.1517\n",
            "Epoch 80/80 - Train Loss: 0.2165 | Val Loss: 0.1393\n",
            "✔️ Best model saved at epoch 80\n",
            "Evaluation Metrics:\n",
            "pixel_accuracy: 0.9810119888630319\n",
            "precision: [0.98647443 0.89036942 0.8422624  0.78336681]\n",
            "recall: [0.99347464 0.8472782  0.74568972 0.2047976 ]\n",
            "f1_score: [0.98996215 0.8682895  0.79103948 0.32470638]\n",
            "iou: [0.98012383 0.76723642 0.65431375 0.19382058]\n",
            "dice_score: [0.98996215 0.8682895  0.79103948 0.32470638]\n",
            "Total params: 9,163,428\n",
            "Model size: 34.96 MB\n"
          ]
        }
      ],
      "source": [
        "# run training\n",
        "!python train.py \\\n",
        "  --model unetpp \\\n",
        "  --data-dir data \\\n",
        "  --output-dir /content/Finaldraft/outputs \\\n",
        "  --img-size 640 \\\n",
        "  --batch-size 8 \\\n",
        "  --epochs 80 \\\n",
        "  --lr 1e-4 \\\n",
        "  --patience 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "MF_mdL6avm_R",
        "outputId": "f63d3c7b-463a-4596-8b14-20166e3a296c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/project_root_seg.zip'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import shutil\n",
        "shutil.make_archive('/content/project_root_seg', 'zip', '/content/project_root_seg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "h2CGdlr70Uk8",
        "outputId": "6166193d-f445-4ecd-81ce-9e09d8b6c1d5"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_d8f1fe5e-ce5e-4d2e-8e4a-2a1f87819940\", \"project_root_seg.zip\", 496349112)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download('/content/project_root_seg.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nqUwWl10c-d",
        "outputId": "0099f6af-2142-4151-9c94-c452ee0d4502"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: content/Finaldraft/ (stored 0%)\n",
            "  adding: content/Finaldraft/data/ (stored 0%)\n",
            "  adding: content/Finaldraft/data/val/ (stored 0%)\n",
            "  adding: content/Finaldraft/data/val/images/ (stored 0%)\n",
            "  adding: content/Finaldraft/data/val/images/29_0_640.png (deflated 2%)\n",
            "  adding: content/Finaldraft/data/val/images/25_640_640.png (deflated 1%)\n",
            "  adding: content/Finaldraft/data/val/images/25_0_640.png (deflated 1%)\n",
            "  adding: content/Finaldraft/data/val/images/29_0_1280.png (deflated 3%)\n",
            "  adding: content/Finaldraft/data/val/images/24_1280_0.png (deflated 6%)\n",
            "  adding: content/Finaldraft/data/val/images/28_0_1280.png (deflated 6%)\n",
            "  adding: content/Finaldraft/data/val/images/22_0_1280.png (deflated 4%)\n",
            "  adding: content/Finaldraft/data/val/images/3_0_640.png (deflated 9%)\n",
            "  adding: content/Finaldraft/data/val/images/22_0_0.png (deflated 11%)\n",
            "  adding: content/Finaldraft/data/val/images/31_0_1280.png (deflated 8%)\n",
            "  adding: content/Finaldraft/data/val/images/31_0_2560.png (deflated 17%)\n",
            "  adding: content/Finaldraft/data/val/images/25_640_1280.png (deflated 2%)\n",
            "  adding: content/Finaldraft/data/val/images/31_0_0.png (deflated 14%)\n",
            "  adding: content/Finaldraft/data/val/images/29_640_640.png (deflated 2%)\n",
            "  adding: content/Finaldraft/data/val/images/34_0_0.png (deflated 15%)\n",
            "  adding: content/Finaldraft/data/val/images/24_640_640.png (deflated 1%)\n",
            "  adding: content/Finaldraft/data/val/images/31_0_1920.png (deflated 7%)\n",
            "  adding: content/Finaldraft/data/val/images/29_640_1920.png (deflated 9%)\n",
            "  adding: content/Finaldraft/data/val/images/24_640_0.png (deflated 5%)\n",
            "  adding: content/Finaldraft/data/val/images/3_640_640.png (deflated 3%)\n",
            "  adding: content/Finaldraft/data/val/images/29_640_0.png (deflated 12%)\n",
            "  adding: content/Finaldraft/data/val/images/25_640_0.png (deflated 3%)\n",
            "  adding: content/Finaldraft/data/val/images/24_0_0.png (deflated 8%)\n",
            "  adding: content/Finaldraft/data/val/images/25_1280_0.png (deflated 4%)\n",
            "  adding: content/Finaldraft/data/val/images/25_1280_640.png (deflated 2%)\n",
            "  adding: content/Finaldraft/data/val/images/24_0_1920.png (deflated 7%)\n",
            "  adding: content/Finaldraft/data/val/images/28_0_1920.png (deflated 15%)\n",
            "  adding: content/Finaldraft/data/val/images/34_0_1280.png (deflated 9%)\n",
            "  adding: content/Finaldraft/data/val/images/24_640_1920.png (deflated 5%)\n",
            "  adding: content/Finaldraft/data/val/images/29_640_1280.png (deflated 2%)\n",
            "  adding: content/Finaldraft/data/val/images/28_0_640.png (deflated 5%)\n",
            "  adding: content/Finaldraft/data/val/images/3_640_0.png (deflated 8%)\n",
            "  adding: content/Finaldraft/data/val/images/24_0_1280.png (deflated 4%)\n",
            "  adding: content/Finaldraft/data/val/images/24_1280_1280.png (deflated 2%)\n",
            "  adding: content/Finaldraft/data/val/images/25_0_1280.png (deflated 4%)\n",
            "  adding: content/Finaldraft/data/val/images/24_640_1280.png (deflated 3%)\n",
            "  adding: content/Finaldraft/data/val/images/25_1280_1280.png (deflated 2%)\n",
            "  adding: content/Finaldraft/data/val/images/25_0_1920.png (deflated 4%)\n",
            "  adding: content/Finaldraft/data/val/images/25_640_1920.png (deflated 4%)\n",
            "  adding: content/Finaldraft/data/val/images/31_0_640.png (deflated 5%)\n",
            "  adding: content/Finaldraft/data/val/images/3_0_0.png (deflated 16%)\n",
            "  adding: content/Finaldraft/data/val/images/25_0_0.png (deflated 4%)\n",
            "  adding: content/Finaldraft/data/val/images/24_0_640.png (deflated 4%)\n",
            "  adding: content/Finaldraft/data/val/images/22_0_640.png (deflated 3%)\n",
            "  adding: content/Finaldraft/data/val/images/25_1280_1920.png (deflated 4%)\n",
            "  adding: content/Finaldraft/data/val/images/24_1280_1920.png (deflated 5%)\n",
            "  adding: content/Finaldraft/data/val/images/24_1280_640.png (deflated 3%)\n",
            "  adding: content/Finaldraft/data/val/masks/ (stored 0%)\n",
            "  adding: content/Finaldraft/data/val/masks/29_0_640.png (deflated 86%)\n",
            "  adding: content/Finaldraft/data/val/masks/25_640_640.png (deflated 59%)\n",
            "  adding: content/Finaldraft/data/val/masks/25_0_640.png (deflated 87%)\n",
            "  adding: content/Finaldraft/data/val/masks/29_0_1280.png (deflated 92%)\n",
            "  adding: content/Finaldraft/data/val/masks/24_1280_0.png (deflated 63%)\n",
            "  adding: content/Finaldraft/data/val/masks/28_0_1280.png (deflated 79%)\n",
            "  adding: content/Finaldraft/data/val/masks/22_0_1280.png (deflated 47%)\n",
            "  adding: content/Finaldraft/data/val/masks/3_0_640.png (deflated 39%)\n",
            "  adding: content/Finaldraft/data/val/masks/22_0_0.png (deflated 86%)\n",
            "  adding: content/Finaldraft/data/val/masks/31_0_1280.png (deflated 67%)\n",
            "  adding: content/Finaldraft/data/val/masks/31_0_2560.png (deflated 92%)\n",
            "  adding: content/Finaldraft/data/val/masks/25_640_1280.png (deflated 56%)\n",
            "  adding: content/Finaldraft/data/val/masks/31_0_0.png (deflated 93%)\n",
            "  adding: content/Finaldraft/data/val/masks/29_640_640.png (deflated 76%)\n",
            "  adding: content/Finaldraft/data/val/masks/34_0_0.png (deflated 76%)\n",
            "  adding: content/Finaldraft/data/val/masks/24_640_640.png (deflated 38%)\n",
            "  adding: content/Finaldraft/data/val/masks/31_0_1920.png (deflated 75%)\n",
            "  adding: content/Finaldraft/data/val/masks/29_640_1920.png (deflated 82%)\n",
            "  adding: content/Finaldraft/data/val/masks/24_640_0.png (deflated 42%)\n",
            "  adding: content/Finaldraft/data/val/masks/3_640_640.png (deflated 40%)\n",
            "  adding: content/Finaldraft/data/val/masks/29_640_0.png (deflated 83%)\n",
            "  adding: content/Finaldraft/data/val/masks/25_640_0.png (deflated 64%)\n",
            "  adding: content/Finaldraft/data/val/masks/24_0_0.png (deflated 75%)\n",
            "  adding: content/Finaldraft/data/val/masks/25_1280_0.png (deflated 48%)\n",
            "  adding: content/Finaldraft/data/val/masks/25_1280_640.png (deflated 68%)\n",
            "  adding: content/Finaldraft/data/val/masks/24_0_1920.png (deflated 84%)\n",
            "  adding: content/Finaldraft/data/val/masks/28_0_1920.png (deflated 69%)\n",
            "  adding: content/Finaldraft/data/val/masks/34_0_1280.png (deflated 65%)\n",
            "  adding: content/Finaldraft/data/val/masks/24_640_1920.png (deflated 82%)\n",
            "  adding: content/Finaldraft/data/val/masks/29_640_1280.png (deflated 75%)\n",
            "  adding: content/Finaldraft/data/val/masks/28_0_640.png (deflated 78%)\n",
            "  adding: content/Finaldraft/data/val/masks/3_640_0.png (deflated 91%)\n",
            "  adding: content/Finaldraft/data/val/masks/24_0_1280.png (deflated 66%)\n",
            "  adding: content/Finaldraft/data/val/masks/24_1280_1280.png (deflated 35%)\n",
            "  adding: content/Finaldraft/data/val/masks/25_0_1280.png (deflated 62%)\n",
            "  adding: content/Finaldraft/data/val/masks/24_640_1280.png (deflated 67%)\n",
            "  adding: content/Finaldraft/data/val/masks/25_1280_1280.png (deflated 43%)\n",
            "  adding: content/Finaldraft/data/val/masks/25_0_1920.png (deflated 63%)\n",
            "  adding: content/Finaldraft/data/val/masks/25_640_1920.png (deflated 70%)\n",
            "  adding: content/Finaldraft/data/val/masks/31_0_640.png (deflated 70%)\n",
            "  adding: content/Finaldraft/data/val/masks/3_0_0.png (deflated 90%)\n",
            "  adding: content/Finaldraft/data/val/masks/25_0_0.png (deflated 80%)\n",
            "  adding: content/Finaldraft/data/val/masks/24_0_640.png (deflated 70%)\n",
            "  adding: content/Finaldraft/data/val/masks/22_0_640.png (deflated 52%)\n",
            "  adding: content/Finaldraft/data/val/masks/25_1280_1920.png (deflated 50%)\n",
            "  adding: content/Finaldraft/data/val/masks/24_1280_1920.png (deflated 58%)\n",
            "  adding: content/Finaldraft/data/val/masks/24_1280_640.png (deflated 53%)\n",
            "  adding: content/Finaldraft/data/train/ (stored 0%)\n",
            "  adding: content/Finaldraft/data/train/images/ (stored 0%)\n",
            "  adding: content/Finaldraft/data/train/images/39_0_1920.png (deflated 5%)\n",
            "  adding: content/Finaldraft/data/train/images/11_0_640.png (deflated 8%)\n",
            "  adding: content/Finaldraft/data/train/images/26_640_0.png (deflated 11%)\n",
            "  adding: content/Finaldraft/data/train/images/2_640_1280.png (deflated 2%)\n",
            "  adding: content/Finaldraft/data/train/images/15_0_1280.png (deflated 5%)\n",
            "  adding: content/Finaldraft/data/train/images/38_0_1920.png (deflated 5%)\n",
            "  adding: content/Finaldraft/data/train/images/15_0_2560.png (deflated 7%)\n",
            "  adding: content/Finaldraft/data/train/images/1_0_640.png (deflated 2%)\n",
            "  adding: content/Finaldraft/data/train/images/21_640_640.png (deflated 3%)\n",
            "  adding: content/Finaldraft/data/train/images/2_1280_0.png (deflated 4%)\n",
            "  adding: content/Finaldraft/data/train/images/26_0_1920.png (deflated 6%)\n",
            "  adding: content/Finaldraft/data/train/images/39_640_640.png (deflated 1%)\n",
            "  adding: content/Finaldraft/data/train/images/32_640_640.png (deflated 3%)\n",
            "  adding: content/Finaldraft/data/train/images/17_640_1920.png (deflated 3%)\n",
            "  adding: content/Finaldraft/data/train/images/27_640_1280.png (deflated 5%)\n",
            "  adding: content/Finaldraft/data/train/images/8_0_640.png (deflated 5%)\n",
            "  adding: content/Finaldraft/data/train/images/16_0_640.png (deflated 9%)\n",
            "  adding: content/Finaldraft/data/train/images/17_1920_640.png (deflated 8%)\n",
            "  adding: content/Finaldraft/data/train/images/19_0_640.png (deflated 3%)\n",
            "  adding: content/Finaldraft/data/train/images/16_640_640.png (deflated 4%)\n",
            "  adding: content/Finaldraft/data/train/images/9_0_0.png (deflated 5%)\n",
            "  adding: content/Finaldraft/data/train/images/38_1280_640.png (deflated 1%)\n",
            "  adding: content/Finaldraft/data/train/images/26_640_1920.png (deflated 3%)\n",
            "  adding: content/Finaldraft/data/train/images/16_0_1280.png (deflated 5%)\n",
            "  adding: content/Finaldraft/data/train/images/21_640_1280.png (deflated 3%)\n",
            "  adding: content/Finaldraft/data/train/images/19_640_0.png (deflated 8%)\n",
            "  adding: content/Finaldraft/data/train/images/19_0_0.png (deflated 9%)\n",
            "  adding: content/Finaldraft/data/train/images/2_0_1920.png (deflated 4%)\n",
            "  adding: content/Finaldraft/data/train/images/37_640_0.png (deflated 15%)\n",
            "  adding: content/Finaldraft/data/train/images/40_1280_2560.png (deflated 5%)\n",
            "  adding: content/Finaldraft/data/train/images/27_0_1280.png (deflated 3%)\n",
            "  adding: content/Finaldraft/data/train/images/36_1280_640.png (deflated 5%)\n",
            "  adding: content/Finaldraft/data/train/images/32_0_1920.png (deflated 4%)\n",
            "  adding: content/Finaldraft/data/train/images/23_0_0.png (deflated 9%)\n",
            "  adding: content/Finaldraft/data/train/images/36_0_0.png (deflated 12%)\n",
            "  adding: content/Finaldraft/data/train/images/37_640_640.png (deflated 2%)\n",
            "  adding: content/Finaldraft/data/train/images/30_0_1280.png (deflated 5%)\n",
            "  adding: content/Finaldraft/data/train/images/17_640_1280.png (deflated 2%)\n",
            "  adding: content/Finaldraft/data/train/images/12_0_0.png (deflated 6%)\n",
            "  adding: content/Finaldraft/data/train/images/38_640_1280.png (deflated 2%)\n",
            "  adding: content/Finaldraft/data/train/images/21_0_1280.png (deflated 7%)\n",
            "  adding: content/Finaldraft/data/train/images/19_640_640.png (deflated 5%)\n",
            "  adding: content/Finaldraft/data/train/images/36_0_640.png (deflated 3%)\n",
            "  adding: content/Finaldraft/data/train/images/38_640_640.png (deflated 1%)\n",
            "  adding: content/Finaldraft/data/train/images/32_0_640.png (deflated 5%)\n",
            "  adding: content/Finaldraft/data/train/images/9_0_1280.png (deflated 3%)\n",
            "  adding: content/Finaldraft/data/train/images/30_640_0.png (deflated 5%)\n",
            "  adding: content/Finaldraft/data/train/images/16_640_1920.png (deflated 2%)\n",
            "  adding: content/Finaldraft/data/train/images/27_1280_1280.png (deflated 5%)\n",
            "  adding: content/Finaldraft/data/train/images/2_1920_1920.png (deflated 7%)\n",
            "  adding: content/Finaldraft/data/train/images/30_640_1920.png (deflated 8%)\n",
            "  adding: content/Finaldraft/data/train/images/39_0_1280.png (deflated 8%)\n",
            "  adding: content/Finaldraft/data/train/images/38_1280_1920.png (deflated 4%)\n",
            "  adding: content/Finaldraft/data/train/images/16_0_1920.png (deflated 3%)\n",
            "  adding: content/Finaldraft/data/train/images/10_640_640.png (deflated 2%)\n",
            "  adding: content/Finaldraft/data/train/images/15_640_640.png (deflated 2%)\n",
            "  adding: content/Finaldraft/data/train/images/40_0_2560.png (deflated 10%)\n",
            "  adding: content/Finaldraft/data/train/images/40_1280_1920.png (deflated 2%)\n",
            "  adding: content/Finaldraft/data/train/images/39_640_1920.png (deflated 8%)\n",
            "  adding: content/Finaldraft/data/train/images/36_640_1280.png (deflated 3%)\n",
            "  adding: content/Finaldraft/data/train/images/2_640_1920.png (deflated 2%)\n",
            "  adding: content/Finaldraft/data/train/images/23_0_640.png (deflated 8%)\n",
            "  adding: content/Finaldraft/data/train/images/15_640_1920.png (deflated 4%)\n",
            "  adding: content/Finaldraft/data/train/images/53_0_640.png (deflated 9%)\n",
            "  adding: content/Finaldraft/data/train/images/37_1280_0.png (deflated 11%)\n",
            "  adding: content/Finaldraft/data/train/images/26_1280_1280.png (deflated 2%)\n",
            "  adding: content/Finaldraft/data/train/images/30_0_640.png (deflated 4%)\n",
            "  adding: content/Finaldraft/data/train/images/36_640_1920.png (deflated 7%)\n",
            "  adding: content/Finaldraft/data/train/images/32_0_0.png (deflated 10%)\n",
            "  adding: content/Finaldraft/data/train/images/15_640_0.png (deflated 7%)\n",
            "  adding: content/Finaldraft/data/train/images/26_0_0.png (deflated 21%)\n",
            "  adding: content/Finaldraft/data/train/images/17_1280_640.png (deflated 6%)\n",
            "  adding: content/Finaldraft/data/train/images/32_1280_0.png (deflated 7%)\n",
            "  adding: content/Finaldraft/data/train/images/30_0_0.png (deflated 7%)\n",
            "  adding: content/Finaldraft/data/train/images/32_1280_640.png (deflated 3%)\n",
            "  adding: content/Finaldraft/data/train/images/52_0_0.png (deflated 9%)\n",
            "  adding: content/Finaldraft/data/train/images/39_1280_640.png (deflated 1%)\n",
            "  adding: content/Finaldraft/data/train/images/15_0_1920.png (deflated 5%)\n",
            "  adding: content/Finaldraft/data/train/images/37_640_1280.png (deflated 3%)\n",
            "  adding: content/Finaldraft/data/train/images/40_0_1280.png (deflated 5%)\n",
            "  adding: content/Finaldraft/data/train/images/26_640_1280.png (deflated 1%)\n",
            "  adding: content/Finaldraft/data/train/images/37_0_1920.png (deflated 5%)\n",
            "  adding: content/Finaldraft/data/train/images/38_1280_1280.png (deflated 2%)\n",
            "  adding: content/Finaldraft/data/train/images/17_1280_1920.png (deflated 3%)\n",
            "  adding: content/Finaldraft/data/train/images/15_640_2560.png (deflated 4%)\n",
            "  adding: content/Finaldraft/data/train/images/27_640_640.png (deflated 2%)\n",
            "  adding: content/Finaldraft/data/train/images/10_0_1280.png (deflated 4%)\n",
            "  adding: content/Finaldraft/data/train/images/37_1280_1280.png (deflated 3%)\n",
            "  adding: content/Finaldraft/data/train/images/40_640_2560.png (deflated 5%)\n",
            "  adding: content/Finaldraft/data/train/images/8_0_0.png (deflated 6%)\n",
            "  adding: content/Finaldraft/data/train/images/37_640_1920.png (deflated 7%)\n",
            "  adding: content/Finaldraft/data/train/images/40_1280_1280.png (deflated 1%)\n",
            "  adding: content/Finaldraft/data/train/images/27_1280_1920.png (deflated 9%)\n",
            "  adding: content/Finaldraft/data/train/images/16_1280_1920.png (deflated 3%)\n",
            "  adding: content/Finaldraft/data/train/images/38_0_1280.png (deflated 3%)\n",
            "  adding: content/Finaldraft/data/train/images/19_0_1280.png (deflated 7%)\n",
            "  adding: content/Finaldraft/data/train/images/11_0_0.png (deflated 4%)\n",
            "  adding: content/Finaldraft/data/train/images/27_0_1920.png (deflated 7%)\n",
            "  adding: content/Finaldraft/data/train/images/9_0_640.png (deflated 3%)\n",
            "  adding: content/Finaldraft/data/train/images/21_0_640.png (deflated 5%)\n",
            "  adding: content/Finaldraft/data/train/images/17_1920_1920.png (deflated 3%)\n",
            "  adding: content/Finaldraft/data/train/images/27_0_640.png (deflated 3%)\n",
            "  adding: content/Finaldraft/data/train/images/1_0_0.png (deflated 4%)\n",
            "  adding: content/Finaldraft/data/train/images/30_0_1920.png (deflated 8%)\n",
            "  adding: content/Finaldraft/data/train/images/32_1280_1920.png (deflated 7%)\n",
            "  adding: content/Finaldraft/data/train/images/17_1920_1280.png (deflated 2%)\n",
            "  adding: content/Finaldraft/data/train/images/50_0_0.png (deflated 11%)\n",
            "  adding: content/Finaldraft/data/train/images/23_0_1280.png (deflated 15%)\n",
            "  adding: content/Finaldraft/data/train/images/19_640_1920.png (deflated 7%)\n",
            "  adding: content/Finaldraft/data/train/images/26_0_640.png (deflated 10%)\n",
            "  adding: content/Finaldraft/data/train/images/17_1280_2560.png (deflated 3%)\n",
            "  adding: content/Finaldraft/data/train/images/39_640_0.png (deflated 4%)\n",
            "  adding: content/Finaldraft/data/train/images/19_640_1280.png (deflated 4%)\n",
            "  adding: content/Finaldraft/data/train/images/27_1280_640.png (deflated 3%)\n",
            "  adding: content/Finaldraft/data/train/images/40_1280_0.png (deflated 11%)\n",
            "  adding: content/Finaldraft/data/train/images/37_0_640.png (deflated 5%)\n",
            "  adding: content/Finaldraft/data/train/images/39_1280_0.png (deflated 5%)\n",
            "  adding: content/Finaldraft/data/train/images/32_640_1920.png (deflated 7%)\n",
            "  adding: content/Finaldraft/data/train/images/40_640_640.png (deflated 1%)\n",
            "  adding: content/Finaldraft/data/train/images/10_0_0.png (deflated 9%)\n",
            "  adding: content/Finaldraft/data/train/images/30_640_1280.png (deflated 3%)\n",
            "  adding: content/Finaldraft/data/train/images/15_0_640.png (deflated 4%)\n",
            "  adding: content/Finaldraft/data/train/images/52_0_640.png (deflated 5%)\n",
            "  adding: content/Finaldraft/data/train/images/26_640_640.png (deflated 1%)\n",
            "  adding: content/Finaldraft/data/train/images/16_1280_1280.png (deflated 2%)\n",
            "  adding: content/Finaldraft/data/train/images/36_1280_1920.png (deflated 13%)\n",
            "  adding: content/Finaldraft/data/train/images/16_1280_640.png (deflated 5%)\n",
            "  adding: content/Finaldraft/data/train/images/23_640_1280.png (deflated 13%)\n",
            "  adding: content/Finaldraft/data/train/images/53_640_640.png (deflated 6%)\n",
            "  adding: content/Finaldraft/data/train/images/2_1280_1280.png (deflated 3%)\n",
            "  adding: content/Finaldraft/data/train/images/16_640_2560.png (deflated 5%)\n",
            "  adding: content/Finaldraft/data/train/images/17_1920_2560.png (deflated 3%)\n",
            "  adding: content/Finaldraft/data/train/images/39_640_1280.png (deflated 3%)\n",
            "  adding: content/Finaldraft/data/train/images/32_640_0.png (deflated 9%)\n",
            "  adding: content/Finaldraft/data/train/images/36_1280_0.png (deflated 14%)\n",
            "  adding: content/Finaldraft/data/train/images/16_1280_2560.png (deflated 4%)\n",
            "  adding: content/Finaldraft/data/train/images/10_640_1920.png (deflated 5%)\n",
            "  adding: content/Finaldraft/data/train/images/16_0_2560.png (deflated 3%)\n",
            "  adding: content/Finaldraft/data/train/images/23_640_640.png (deflated 7%)\n",
            "  adding: content/Finaldraft/data/train/images/2_1920_1280.png (deflated 7%)\n",
            "  adding: content/Finaldraft/data/train/images/10_0_1920.png (deflated 4%)\n",
            "  adding: content/Finaldraft/data/train/images/2_1280_640.png (deflated 3%)\n",
            "  adding: content/Finaldraft/data/train/images/39_0_0.png (deflated 9%)\n",
            "  adding: content/Finaldraft/data/train/images/50_0_640.png (deflated 6%)\n",
            "  adding: content/Finaldraft/data/train/images/37_1280_640.png (deflated 1%)\n",
            "  adding: content/Finaldraft/data/train/images/40_640_0.png (deflated 11%)\n",
            "  adding: content/Finaldraft/data/train/images/35_0_640.png (deflated 7%)\n",
            "  adding: content/Finaldraft/data/train/images/36_0_1280.png (deflated 4%)\n",
            "  adding: content/Finaldraft/data/train/images/2_1920_640.png (deflated 7%)\n",
            "  adding: content/Finaldraft/data/train/images/2_0_1280.png (deflated 4%)\n",
            "  adding: content/Finaldraft/data/train/images/30_640_640.png (deflated 2%)\n",
            "  adding: content/Finaldraft/data/train/images/40_0_640.png (deflated 8%)\n",
            "  adding: content/Finaldraft/data/train/images/32_640_1280.png (deflated 4%)\n",
            "  adding: content/Finaldraft/data/train/images/40_640_1920.png (deflated 2%)\n",
            "  adding: content/Finaldraft/data/train/images/17_640_640.png (deflated 9%)\n",
            "  adding: content/Finaldraft/data/train/images/17_640_2560.png (deflated 3%)\n",
            "  adding: content/Finaldraft/data/train/images/10_0_640.png (deflated 5%)\n",
            "  adding: content/Finaldraft/data/train/images/17_1280_1280.png (deflated 1%)\n",
            "  adding: content/Finaldraft/data/train/images/2_1920_0.png (deflated 11%)\n",
            "  adding: content/Finaldraft/data/train/images/15_640_1280.png (deflated 5%)\n",
            "  adding: content/Finaldraft/data/train/images/40_0_1920.png (deflated 5%)\n",
            "  adding: content/Finaldraft/data/train/images/23_640_0.png (deflated 11%)\n",
            "  adding: content/Finaldraft/data/train/images/36_640_0.png (deflated 8%)\n",
            "  adding: content/Finaldraft/data/train/images/37_1280_1920.png (deflated 7%)\n",
            "  adding: content/Finaldraft/data/train/images/12_0_640.png (deflated 5%)\n",
            "  adding: content/Finaldraft/data/train/images/16_640_1280.png (deflated 1%)\n",
            "  adding: content/Finaldraft/data/train/images/37_0_1280.png (deflated 3%)\n",
            "  adding: content/Finaldraft/data/train/images/10_640_1280.png (deflated 3%)\n",
            "  adding: content/Finaldraft/data/train/images/40_1280_640.png (deflated 1%)\n",
            "  adding: content/Finaldraft/data/train/images/2_1280_1920.png (deflated 2%)\n",
            "  adding: content/Finaldraft/data/train/images/26_1280_0.png (deflated 13%)\n",
            "  adding: content/Finaldraft/data/train/images/39_1280_1280.png (deflated 3%)\n",
            "  adding: content/Finaldraft/data/train/images/36_640_640.png (deflated 2%)\n",
            "  adding: content/Finaldraft/data/train/images/26_1280_1920.png (deflated 4%)\n",
            "  adding: content/Finaldraft/data/train/images/40_640_1280.png (deflated 1%)\n",
            "  adding: content/Finaldraft/data/train/images/26_1280_640.png (deflated 1%)\n",
            "  adding: content/Finaldraft/data/train/images/10_640_0.png (deflated 5%)\n",
            "  adding: content/Finaldraft/data/train/images/38_640_1920.png (deflated 5%)\n",
            "  adding: content/Finaldraft/data/train/images/53_0_1280.png (deflated 18%)\n",
            "  adding: content/Finaldraft/data/train/images/39_1280_1920.png (deflated 7%)\n",
            "  adding: content/Finaldraft/data/train/masks/ (stored 0%)\n",
            "  adding: content/Finaldraft/data/train/masks/39_0_1920.png (deflated 78%)\n",
            "  adding: content/Finaldraft/data/train/masks/11_0_640.png (deflated 51%)\n",
            "  adding: content/Finaldraft/data/train/masks/26_640_0.png (deflated 86%)\n",
            "  adding: content/Finaldraft/data/train/masks/2_640_1280.png (deflated 72%)\n",
            "  adding: content/Finaldraft/data/train/masks/15_0_1280.png (deflated 84%)\n",
            "  adding: content/Finaldraft/data/train/masks/38_0_1920.png (deflated 78%)\n",
            "  adding: content/Finaldraft/data/train/masks/15_0_2560.png (deflated 91%)\n",
            "  adding: content/Finaldraft/data/train/masks/1_0_640.png (deflated 44%)\n",
            "  adding: content/Finaldraft/data/train/masks/21_640_640.png (deflated 55%)\n",
            "  adding: content/Finaldraft/data/train/masks/2_1280_0.png (deflated 68%)\n",
            "  adding: content/Finaldraft/data/train/masks/26_0_1920.png (deflated 80%)\n",
            "  adding: content/Finaldraft/data/train/masks/39_640_640.png (deflated 89%)\n",
            "  adding: content/Finaldraft/data/train/masks/32_640_640.png (deflated 45%)\n",
            "  adding: content/Finaldraft/data/train/masks/17_640_1920.png (deflated 48%)\n",
            "  adding: content/Finaldraft/data/train/masks/27_640_1280.png (deflated 46%)\n",
            "  adding: content/Finaldraft/data/train/masks/8_0_640.png (deflated 62%)\n",
            "  adding: content/Finaldraft/data/train/masks/16_0_640.png (deflated 87%)\n",
            "  adding: content/Finaldraft/data/train/masks/17_1920_640.png (deflated 57%)\n",
            "  adding: content/Finaldraft/data/train/masks/19_0_640.png (deflated 54%)\n",
            "  adding: content/Finaldraft/data/train/masks/16_640_640.png (deflated 69%)\n",
            "  adding: content/Finaldraft/data/train/masks/9_0_0.png (deflated 38%)\n",
            "  adding: content/Finaldraft/data/train/masks/38_1280_640.png (deflated 93%)\n",
            "  adding: content/Finaldraft/data/train/masks/26_640_1920.png (deflated 92%)\n",
            "  adding: content/Finaldraft/data/train/masks/16_0_1280.png (deflated 71%)\n",
            "  adding: content/Finaldraft/data/train/masks/21_640_1280.png (deflated 44%)\n",
            "  adding: content/Finaldraft/data/train/masks/19_640_0.png (deflated 67%)\n",
            "  adding: content/Finaldraft/data/train/masks/19_0_0.png (deflated 71%)\n",
            "  adding: content/Finaldraft/data/train/masks/2_0_1920.png (deflated 65%)\n",
            "  adding: content/Finaldraft/data/train/masks/37_640_0.png (deflated 89%)\n",
            "  adding: content/Finaldraft/data/train/masks/40_1280_2560.png (deflated 91%)\n",
            "  adding: content/Finaldraft/data/train/masks/27_0_1280.png (deflated 55%)\n",
            "  adding: content/Finaldraft/data/train/masks/36_1280_640.png (deflated 71%)\n",
            "  adding: content/Finaldraft/data/train/masks/32_0_1920.png (deflated 90%)\n",
            "  adding: content/Finaldraft/data/train/masks/23_0_0.png (deflated 92%)\n",
            "  adding: content/Finaldraft/data/train/masks/36_0_0.png (deflated 67%)\n",
            "  adding: content/Finaldraft/data/train/masks/37_640_640.png (deflated 64%)\n",
            "  adding: content/Finaldraft/data/train/masks/30_0_1280.png (deflated 48%)\n",
            "  adding: content/Finaldraft/data/train/masks/17_640_1280.png (deflated 41%)\n",
            "  adding: content/Finaldraft/data/train/masks/12_0_0.png (deflated 88%)\n",
            "  adding: content/Finaldraft/data/train/masks/38_640_1280.png (deflated 81%)\n",
            "  adding: content/Finaldraft/data/train/masks/21_0_1280.png (deflated 53%)\n",
            "  adding: content/Finaldraft/data/train/masks/19_640_640.png (deflated 55%)\n",
            "  adding: content/Finaldraft/data/train/masks/36_0_640.png (deflated 61%)\n",
            "  adding: content/Finaldraft/data/train/masks/38_640_640.png (deflated 92%)\n",
            "  adding: content/Finaldraft/data/train/masks/32_0_640.png (deflated 43%)\n",
            "  adding: content/Finaldraft/data/train/masks/9_0_1280.png (deflated 69%)\n",
            "  adding: content/Finaldraft/data/train/masks/30_640_0.png (deflated 65%)\n",
            "  adding: content/Finaldraft/data/train/masks/16_640_1920.png (deflated 63%)\n",
            "  adding: content/Finaldraft/data/train/masks/27_1280_1280.png (deflated 81%)\n",
            "  adding: content/Finaldraft/data/train/masks/2_1920_1920.png (deflated 47%)\n",
            "  adding: content/Finaldraft/data/train/masks/30_640_1920.png (deflated 67%)\n",
            "  adding: content/Finaldraft/data/train/masks/39_0_1280.png (deflated 92%)\n",
            "  adding: content/Finaldraft/data/train/masks/38_1280_1920.png (deflated 51%)\n",
            "  adding: content/Finaldraft/data/train/masks/16_0_1920.png (deflated 78%)\n",
            "  adding: content/Finaldraft/data/train/masks/10_640_640.png (deflated 55%)\n",
            "  adding: content/Finaldraft/data/train/masks/15_640_640.png (deflated 45%)\n",
            "  adding: content/Finaldraft/data/train/masks/40_0_2560.png (deflated 90%)\n",
            "  adding: content/Finaldraft/data/train/masks/40_1280_1920.png (deflated 89%)\n",
            "  adding: content/Finaldraft/data/train/masks/39_640_1920.png (deflated 62%)\n",
            "  adding: content/Finaldraft/data/train/masks/36_640_1280.png (deflated 59%)\n",
            "  adding: content/Finaldraft/data/train/masks/2_640_1920.png (deflated 64%)\n",
            "  adding: content/Finaldraft/data/train/masks/23_0_640.png (deflated 73%)\n",
            "  adding: content/Finaldraft/data/train/masks/15_640_1920.png (deflated 72%)\n",
            "  adding: content/Finaldraft/data/train/masks/53_0_640.png (deflated 57%)\n",
            "  adding: content/Finaldraft/data/train/masks/37_1280_0.png (deflated 66%)\n",
            "  adding: content/Finaldraft/data/train/masks/26_1280_1280.png (deflated 81%)\n",
            "  adding: content/Finaldraft/data/train/masks/30_0_640.png (deflated 66%)\n",
            "  adding: content/Finaldraft/data/train/masks/36_640_1920.png (deflated 61%)\n",
            "  adding: content/Finaldraft/data/train/masks/32_0_0.png (deflated 92%)\n",
            "  adding: content/Finaldraft/data/train/masks/15_640_0.png (deflated 88%)\n",
            "  adding: content/Finaldraft/data/train/masks/26_0_0.png (deflated 89%)\n",
            "  adding: content/Finaldraft/data/train/masks/17_1280_640.png (deflated 54%)\n",
            "  adding: content/Finaldraft/data/train/masks/32_1280_0.png (deflated 77%)\n",
            "  adding: content/Finaldraft/data/train/masks/30_0_0.png (deflated 94%)\n",
            "  adding: content/Finaldraft/data/train/masks/32_1280_640.png (deflated 62%)\n",
            "  adding: content/Finaldraft/data/train/masks/52_0_0.png (deflated 67%)\n",
            "  adding: content/Finaldraft/data/train/masks/39_1280_640.png (deflated 89%)\n",
            "  adding: content/Finaldraft/data/train/masks/15_0_1920.png (deflated 87%)\n",
            "  adding: content/Finaldraft/data/train/masks/37_640_1280.png (deflated 60%)\n",
            "  adding: content/Finaldraft/data/train/masks/40_0_1280.png (deflated 84%)\n",
            "  adding: content/Finaldraft/data/train/masks/26_640_1280.png (deflated 83%)\n",
            "  adding: content/Finaldraft/data/train/masks/37_0_1920.png (deflated 72%)\n",
            "  adding: content/Finaldraft/data/train/masks/38_1280_1280.png (deflated 76%)\n",
            "  adding: content/Finaldraft/data/train/masks/17_1280_1920.png (deflated 39%)\n",
            "  adding: content/Finaldraft/data/train/masks/15_640_2560.png (deflated 61%)\n",
            "  adding: content/Finaldraft/data/train/masks/27_640_640.png (deflated 53%)\n",
            "  adding: content/Finaldraft/data/train/masks/10_0_1280.png (deflated 77%)\n",
            "  adding: content/Finaldraft/data/train/masks/37_1280_1280.png (deflated 50%)\n",
            "  adding: content/Finaldraft/data/train/masks/40_640_2560.png (deflated 90%)\n",
            "  adding: content/Finaldraft/data/train/masks/8_0_0.png (deflated 84%)\n",
            "  adding: content/Finaldraft/data/train/masks/37_640_1920.png (deflated 91%)\n",
            "  adding: content/Finaldraft/data/train/masks/40_1280_1280.png (deflated 89%)\n",
            "  adding: content/Finaldraft/data/train/masks/27_1280_1920.png (deflated 59%)\n",
            "  adding: content/Finaldraft/data/train/masks/16_1280_1920.png (deflated 65%)\n",
            "  adding: content/Finaldraft/data/train/masks/38_0_1280.png (deflated 75%)\n",
            "  adding: content/Finaldraft/data/train/masks/19_0_1280.png (deflated 44%)\n",
            "  adding: content/Finaldraft/data/train/masks/11_0_0.png (deflated 40%)\n",
            "  adding: content/Finaldraft/data/train/masks/27_0_1920.png (deflated 66%)\n",
            "  adding: content/Finaldraft/data/train/masks/9_0_640.png (deflated 72%)\n",
            "  adding: content/Finaldraft/data/train/masks/21_0_640.png (deflated 45%)\n",
            "  adding: content/Finaldraft/data/train/masks/17_1920_1920.png (deflated 32%)\n",
            "  adding: content/Finaldraft/data/train/masks/27_0_640.png (deflated 57%)\n",
            "  adding: content/Finaldraft/data/train/masks/1_0_0.png (deflated 43%)\n",
            "  adding: content/Finaldraft/data/train/masks/30_0_1920.png (deflated 92%)\n",
            "  adding: content/Finaldraft/data/train/masks/32_1280_1920.png (deflated 48%)\n",
            "  adding: content/Finaldraft/data/train/masks/17_1920_1280.png (deflated 60%)\n",
            "  adding: content/Finaldraft/data/train/masks/50_0_0.png (deflated 78%)\n",
            "  adding: content/Finaldraft/data/train/masks/23_0_1280.png (deflated 79%)\n",
            "  adding: content/Finaldraft/data/train/masks/19_640_1920.png (deflated 65%)\n",
            "  adding: content/Finaldraft/data/train/masks/26_0_640.png (deflated 81%)\n",
            "  adding: content/Finaldraft/data/train/masks/17_1280_2560.png (deflated 87%)\n",
            "  adding: content/Finaldraft/data/train/masks/39_640_0.png (deflated 86%)\n",
            "  adding: content/Finaldraft/data/train/masks/19_640_1280.png (deflated 46%)\n",
            "  adding: content/Finaldraft/data/train/masks/27_1280_640.png (deflated 37%)\n",
            "  adding: content/Finaldraft/data/train/masks/40_1280_0.png (deflated 93%)\n",
            "  adding: content/Finaldraft/data/train/masks/37_0_640.png (deflated 66%)\n",
            "  adding: content/Finaldraft/data/train/masks/39_1280_0.png (deflated 92%)\n",
            "  adding: content/Finaldraft/data/train/masks/32_640_1920.png (deflated 85%)\n",
            "  adding: content/Finaldraft/data/train/masks/40_640_640.png (deflated 86%)\n",
            "  adding: content/Finaldraft/data/train/masks/10_0_0.png (deflated 65%)\n",
            "  adding: content/Finaldraft/data/train/masks/30_640_1280.png (deflated 50%)\n",
            "  adding: content/Finaldraft/data/train/masks/15_0_640.png (deflated 38%)\n",
            "  adding: content/Finaldraft/data/train/masks/52_0_640.png (deflated 72%)\n",
            "  adding: content/Finaldraft/data/train/masks/26_640_640.png (deflated 61%)\n",
            "  adding: content/Finaldraft/data/train/masks/16_1280_1280.png (deflated 53%)\n",
            "  adding: content/Finaldraft/data/train/masks/36_1280_1920.png (deflated 59%)\n",
            "  adding: content/Finaldraft/data/train/masks/16_1280_640.png (deflated 82%)\n",
            "  adding: content/Finaldraft/data/train/masks/23_640_1280.png (deflated 74%)\n",
            "  adding: content/Finaldraft/data/train/masks/53_640_640.png (deflated 42%)\n",
            "  adding: content/Finaldraft/data/train/masks/2_1280_1280.png (deflated 58%)\n",
            "  adding: content/Finaldraft/data/train/masks/16_640_2560.png (deflated 66%)\n",
            "  adding: content/Finaldraft/data/train/masks/17_1920_2560.png (deflated 51%)\n",
            "  adding: content/Finaldraft/data/train/masks/39_640_1280.png (deflated 75%)\n",
            "  adding: content/Finaldraft/data/train/masks/32_640_0.png (deflated 77%)\n",
            "  adding: content/Finaldraft/data/train/masks/36_1280_0.png (deflated 85%)\n",
            "  adding: content/Finaldraft/data/train/masks/16_1280_2560.png (deflated 51%)\n",
            "  adding: content/Finaldraft/data/train/masks/10_640_1920.png (deflated 56%)\n",
            "  adding: content/Finaldraft/data/train/masks/16_0_2560.png (deflated 58%)\n",
            "  adding: content/Finaldraft/data/train/masks/23_640_640.png (deflated 68%)\n",
            "  adding: content/Finaldraft/data/train/masks/2_1920_1280.png (deflated 60%)\n",
            "  adding: content/Finaldraft/data/train/masks/10_0_1920.png (deflated 92%)\n",
            "  adding: content/Finaldraft/data/train/masks/2_1280_640.png (deflated 46%)\n",
            "  adding: content/Finaldraft/data/train/masks/39_0_0.png (deflated 94%)\n",
            "  adding: content/Finaldraft/data/train/masks/50_0_640.png (deflated 64%)\n",
            "  adding: content/Finaldraft/data/train/masks/37_1280_640.png (deflated 44%)\n",
            "  adding: content/Finaldraft/data/train/masks/40_640_0.png (deflated 93%)\n",
            "  adding: content/Finaldraft/data/train/masks/35_0_640.png (deflated 63%)\n",
            "  adding: content/Finaldraft/data/train/masks/36_0_1280.png (deflated 77%)\n",
            "  adding: content/Finaldraft/data/train/masks/2_1920_640.png (deflated 54%)\n",
            "  adding: content/Finaldraft/data/train/masks/2_0_1280.png (deflated 65%)\n",
            "  adding: content/Finaldraft/data/train/masks/30_640_640.png (deflated 31%)\n",
            "  adding: content/Finaldraft/data/train/masks/40_0_640.png (deflated 89%)\n",
            "  adding: content/Finaldraft/data/train/masks/32_640_1280.png (deflated 76%)\n",
            "  adding: content/Finaldraft/data/train/masks/40_640_1920.png (deflated 87%)\n",
            "  adding: content/Finaldraft/data/train/masks/17_640_640.png (deflated 68%)\n",
            "  adding: content/Finaldraft/data/train/masks/17_640_2560.png (deflated 38%)\n",
            "  adding: content/Finaldraft/data/train/masks/10_0_640.png (deflated 67%)\n",
            "  adding: content/Finaldraft/data/train/masks/17_1280_1280.png (deflated 55%)\n",
            "  adding: content/Finaldraft/data/train/masks/2_1920_0.png (deflated 41%)\n",
            "  adding: content/Finaldraft/data/train/masks/15_640_1280.png (deflated 72%)\n",
            "  adding: content/Finaldraft/data/train/masks/40_0_1920.png (deflated 86%)\n",
            "  adding: content/Finaldraft/data/train/masks/23_640_0.png (deflated 73%)\n",
            "  adding: content/Finaldraft/data/train/masks/36_640_0.png (deflated 60%)\n",
            "  adding: content/Finaldraft/data/train/masks/37_1280_1920.png (deflated 45%)\n",
            "  adding: content/Finaldraft/data/train/masks/12_0_640.png (deflated 85%)\n",
            "  adding: content/Finaldraft/data/train/masks/16_640_1280.png (deflated 61%)\n",
            "  adding: content/Finaldraft/data/train/masks/37_0_1280.png (deflated 43%)\n",
            "  adding: content/Finaldraft/data/train/masks/10_640_1280.png (deflated 48%)\n",
            "  adding: content/Finaldraft/data/train/masks/40_1280_640.png (deflated 87%)\n",
            "  adding: content/Finaldraft/data/train/masks/2_1280_1920.png (deflated 56%)\n",
            "  adding: content/Finaldraft/data/train/masks/26_1280_0.png (deflated 64%)\n",
            "  adding: content/Finaldraft/data/train/masks/39_1280_1280.png (deflated 90%)\n",
            "  adding: content/Finaldraft/data/train/masks/36_640_640.png (deflated 56%)\n",
            "  adding: content/Finaldraft/data/train/masks/26_1280_1920.png (deflated 93%)\n",
            "  adding: content/Finaldraft/data/train/masks/40_640_1280.png (deflated 83%)\n",
            "  adding: content/Finaldraft/data/train/masks/26_1280_640.png (deflated 72%)\n",
            "  adding: content/Finaldraft/data/train/masks/10_640_0.png (deflated 68%)\n",
            "  adding: content/Finaldraft/data/train/masks/38_640_1920.png (deflated 71%)\n",
            "  adding: content/Finaldraft/data/train/masks/53_0_1280.png (deflated 83%)\n",
            "  adding: content/Finaldraft/data/train/masks/39_1280_1920.png (deflated 89%)\n",
            "  adding: content/Finaldraft/eval.py (deflated 60%)\n",
            "  adding: content/Finaldraft/__pycache__/ (stored 0%)\n",
            "  adding: content/Finaldraft/__pycache__/visualize.cpython-311.pyc (deflated 60%)\n",
            "  adding: content/Finaldraft/__pycache__/network.cpython-311.pyc (deflated 46%)\n",
            "  adding: content/Finaldraft/__pycache__/augmentation.cpython-311.pyc (deflated 49%)\n",
            "  adding: content/Finaldraft/__pycache__/eval.cpython-311.pyc (deflated 47%)\n",
            "  adding: content/Finaldraft/network.py (deflated 68%)\n",
            "  adding: content/Finaldraft/augmentation.py (deflated 60%)\n",
            "  adding: content/Finaldraft/requirements.txt (deflated 24%)\n",
            "  adding: content/Finaldraft/visualize.py (deflated 69%)\n",
            "  adding: content/Finaldraft/README.md (deflated 58%)\n",
            "  adding: content/Finaldraft/models/ (stored 0%)\n",
            "  adding: content/Finaldraft/models/Unet.py (deflated 63%)\n",
            "  adding: content/Finaldraft/models/unet_vgg16.py (deflated 72%)\n",
            "  adding: content/Finaldraft/models/attunet.py (deflated 73%)\n",
            "  adding: content/Finaldraft/models/__pycache__/ (stored 0%)\n",
            "  adding: content/Finaldraft/models/__pycache__/unetpp.cpython-311.pyc (deflated 70%)\n",
            "  adding: content/Finaldraft/models/__pycache__/unet_mobilenet.cpython-311.pyc (deflated 64%)\n",
            "  adding: content/Finaldraft/models/__pycache__/Unet.cpython-311.pyc (deflated 49%)\n",
            "  adding: content/Finaldraft/models/__pycache__/unet3plus.cpython-311.pyc (deflated 66%)\n",
            "  adding: content/Finaldraft/models/__pycache__/__init__.cpython-311.pyc (deflated 22%)\n",
            "  adding: content/Finaldraft/models/__pycache__/unet_vgg16.cpython-311.pyc (deflated 61%)\n",
            "  adding: content/Finaldraft/models/__pycache__/attunet.cpython-311.pyc (deflated 64%)\n",
            "  adding: content/Finaldraft/models/__pycache__/ResUnet.cpython-311.pyc (deflated 61%)\n",
            "  adding: content/Finaldraft/models/ResUnet.py (deflated 72%)\n",
            "  adding: content/Finaldraft/models/unetpp.py (deflated 79%)\n",
            "  adding: content/Finaldraft/models/__init__.py (stored 0%)\n",
            "  adding: content/Finaldraft/models/unet_mobilenet.py (deflated 72%)\n",
            "  adding: content/Finaldraft/models/unet3plus.py (deflated 79%)\n",
            "  adding: content/Finaldraft/outputs/ (stored 0%)\n",
            "  adding: content/Finaldraft/outputs/resunet/ (stored 0%)\n",
            "  adding: content/Finaldraft/outputs/resunet/resunet_acc.png (deflated 5%)\n",
            "  adding: content/Finaldraft/outputs/resunet/best_resunet.pth (deflated 8%)\n",
            "  adding: content/Finaldraft/outputs/resunet/classwise_iou.png (deflated 3%)\n",
            "  adding: content/Finaldraft/outputs/resunet/classwise_dice.png (deflated 3%)\n",
            "  adding: content/Finaldraft/outputs/resunet/samples/ (stored 0%)\n",
            "  adding: content/Finaldraft/outputs/resunet/samples/sample_2.png (deflated 1%)\n",
            "  adding: content/Finaldraft/outputs/resunet/samples/sample_1.png (deflated 1%)\n",
            "  adding: content/Finaldraft/outputs/resunet/samples/sample_4.png (deflated 2%)\n",
            "  adding: content/Finaldraft/outputs/resunet/samples/sample_0.png (deflated 3%)\n",
            "  adding: content/Finaldraft/outputs/resunet/samples/sample_3.png (deflated 2%)\n",
            "  adding: content/Finaldraft/outputs/resunet/resunet_loss.png (deflated 6%)\n",
            "  adding: content/Finaldraft/outputs/resunet/classwise_iou.json (deflated 54%)\n",
            "  adding: content/Finaldraft/outputs/resunet/classwise_dice.json (deflated 54%)\n",
            "  adding: content/Finaldraft/outputs/unetpp/ (stored 0%)\n",
            "  adding: content/Finaldraft/outputs/unetpp/unetpp_acc.png (deflated 5%)\n",
            "  adding: content/Finaldraft/outputs/unetpp/classwise_iou.png (deflated 3%)\n",
            "  adding: content/Finaldraft/outputs/unetpp/classwise_dice.png (deflated 3%)\n",
            "  adding: content/Finaldraft/outputs/unetpp/samples/ (stored 0%)\n",
            "  adding: content/Finaldraft/outputs/unetpp/samples/sample_2.png (deflated 1%)\n",
            "  adding: content/Finaldraft/outputs/unetpp/samples/sample_1.png (deflated 2%)\n",
            "  adding: content/Finaldraft/outputs/unetpp/samples/sample_4.png (deflated 2%)\n",
            "  adding: content/Finaldraft/outputs/unetpp/samples/sample_0.png (deflated 3%)\n",
            "  adding: content/Finaldraft/outputs/unetpp/samples/sample_3.png (deflated 2%)\n",
            "  adding: content/Finaldraft/outputs/unetpp/classwise_iou.json (deflated 54%)\n",
            "  adding: content/Finaldraft/outputs/unetpp/unetpp_loss.png (deflated 5%)\n",
            "  adding: content/Finaldraft/outputs/unetpp/best_unetpp.pth (deflated 8%)\n",
            "  adding: content/Finaldraft/outputs/unetpp/classwise_dice.json (deflated 54%)\n",
            "  adding: content/Finaldraft/outputs/unet/ (stored 0%)\n",
            "  adding: content/Finaldraft/outputs/unet/unet_acc.png (deflated 6%)\n",
            "  adding: content/Finaldraft/outputs/unet/unet_loss.png (deflated 6%)\n",
            "  adding: content/Finaldraft/outputs/unet/classwise_iou.png (deflated 3%)\n",
            "  adding: content/Finaldraft/outputs/unet/classwise_dice.png (deflated 3%)\n",
            "  adding: content/Finaldraft/outputs/unet/samples/ (stored 0%)\n",
            "  adding: content/Finaldraft/outputs/unet/samples/sample_2.png (deflated 1%)\n",
            "  adding: content/Finaldraft/outputs/unet/samples/sample_1.png (deflated 2%)\n",
            "  adding: content/Finaldraft/outputs/unet/samples/sample_4.png (deflated 2%)\n",
            "  adding: content/Finaldraft/outputs/unet/samples/sample_0.png (deflated 3%)\n",
            "  adding: content/Finaldraft/outputs/unet/samples/sample_3.png (deflated 2%)\n",
            "  adding: content/Finaldraft/outputs/unet/classwise_iou.json (deflated 55%)\n",
            "  adding: content/Finaldraft/outputs/unet/best_unet.pth (deflated 8%)\n",
            "  adding: content/Finaldraft/outputs/unet/classwise_dice.json (deflated 55%)\n",
            "  adding: content/Finaldraft/outputs/deeplabv3plus_mit_b0/ (stored 0%)\n",
            "  adding: content/Finaldraft/outputs/deeplabv3plus_mit_b0/best_deeplabv3plus_mit_b0.pth (deflated 8%)\n",
            "  adding: content/Finaldraft/outputs/deeplabv3plus_mit_b0/deeplabv3plus_mit_b0_acc.png (deflated 8%)\n",
            "  adding: content/Finaldraft/outputs/deeplabv3plus_mit_b0/deeplabv3plus_mit_b0_loss.png (deflated 8%)\n",
            "  adding: content/Finaldraft/outputs/deeplabv3plus_mit_b0/classwise_iou.png (deflated 3%)\n",
            "  adding: content/Finaldraft/outputs/deeplabv3plus_mit_b0/classwise_dice.png (deflated 3%)\n",
            "  adding: content/Finaldraft/outputs/deeplabv3plus_mit_b0/samples/ (stored 0%)\n",
            "  adding: content/Finaldraft/outputs/deeplabv3plus_mit_b0/samples/sample_2.png (deflated 1%)\n",
            "  adding: content/Finaldraft/outputs/deeplabv3plus_mit_b0/samples/sample_1.png (deflated 2%)\n",
            "  adding: content/Finaldraft/outputs/deeplabv3plus_mit_b0/samples/sample_4.png (deflated 2%)\n",
            "  adding: content/Finaldraft/outputs/deeplabv3plus_mit_b0/samples/sample_0.png (deflated 3%)\n",
            "  adding: content/Finaldraft/outputs/deeplabv3plus_mit_b0/samples/sample_3.png (deflated 2%)\n",
            "  adding: content/Finaldraft/outputs/deeplabv3plus_mit_b0/classwise_iou.json (deflated 54%)\n",
            "  adding: content/Finaldraft/outputs/deeplabv3plus_mit_b0/classwise_dice.json (deflated 55%)\n",
            "  adding: content/Finaldraft/outputs/unet_mobilenet/ (stored 0%)\n",
            "  adding: content/Finaldraft/outputs/unet_mobilenet/best_unet_mobilenet.pth (deflated 8%)\n",
            "  adding: content/Finaldraft/outputs/unet_mobilenet/classwise_iou.png (deflated 4%)\n",
            "  adding: content/Finaldraft/outputs/unet_mobilenet/classwise_dice.png (deflated 4%)\n",
            "  adding: content/Finaldraft/outputs/unet_mobilenet/samples/ (stored 0%)\n",
            "  adding: content/Finaldraft/outputs/unet_mobilenet/samples/sample_2.png (deflated 1%)\n",
            "  adding: content/Finaldraft/outputs/unet_mobilenet/samples/sample_1.png (deflated 2%)\n",
            "  adding: content/Finaldraft/outputs/unet_mobilenet/samples/sample_4.png (deflated 2%)\n",
            "  adding: content/Finaldraft/outputs/unet_mobilenet/samples/sample_0.png (deflated 4%)\n",
            "  adding: content/Finaldraft/outputs/unet_mobilenet/samples/sample_3.png (deflated 2%)\n",
            "  adding: content/Finaldraft/outputs/unet_mobilenet/classwise_iou.json (deflated 56%)\n",
            "  adding: content/Finaldraft/outputs/unet_mobilenet/unet_mobilenet_acc.png (deflated 5%)\n",
            "  adding: content/Finaldraft/outputs/unet_mobilenet/classwise_dice.json (deflated 56%)\n",
            "  adding: content/Finaldraft/outputs/unet_mobilenet/unet_mobilenet_loss.png (deflated 5%)\n",
            "  adding: content/Finaldraft/outputs/unet3plus/ (stored 0%)\n",
            "  adding: content/Finaldraft/outputs/unet3plus/unet3plus_loss.png (deflated 7%)\n",
            "  adding: content/Finaldraft/outputs/unet3plus/best_unet3plus.pth (deflated 8%)\n",
            "  adding: content/Finaldraft/outputs/unet3plus/unet3plus_acc.png (deflated 6%)\n",
            "  adding: content/Finaldraft/outputs/unet3plus/classwise_iou.png (deflated 4%)\n",
            "  adding: content/Finaldraft/outputs/unet3plus/classwise_dice.png (deflated 5%)\n",
            "  adding: content/Finaldraft/outputs/unet3plus/samples/ (stored 0%)\n",
            "  adding: content/Finaldraft/outputs/unet3plus/samples/sample_2.png (deflated 1%)\n",
            "  adding: content/Finaldraft/outputs/unet3plus/samples/sample_1.png (deflated 2%)\n",
            "  adding: content/Finaldraft/outputs/unet3plus/samples/sample_4.png (deflated 2%)\n",
            "  adding: content/Finaldraft/outputs/unet3plus/samples/sample_0.png (deflated 3%)\n",
            "  adding: content/Finaldraft/outputs/unet3plus/samples/sample_3.png (deflated 2%)\n",
            "  adding: content/Finaldraft/outputs/unet3plus/classwise_iou.json (deflated 57%)\n",
            "  adding: content/Finaldraft/outputs/unet3plus/classwise_dice.json (deflated 58%)\n",
            "  adding: content/Finaldraft/outputs/unet_vgg16/ (stored 0%)\n",
            "  adding: content/Finaldraft/outputs/unet_vgg16/classwise_iou.png (deflated 3%)\n",
            "  adding: content/Finaldraft/outputs/unet_vgg16/best_unet_vgg16.pth (deflated 7%)\n",
            "  adding: content/Finaldraft/outputs/unet_vgg16/classwise_dice.png (deflated 4%)\n",
            "  adding: content/Finaldraft/outputs/unet_vgg16/samples/ (stored 0%)\n",
            "  adding: content/Finaldraft/outputs/unet_vgg16/samples/sample_2.png (deflated 1%)\n",
            "  adding: content/Finaldraft/outputs/unet_vgg16/samples/sample_1.png (deflated 2%)\n",
            "  adding: content/Finaldraft/outputs/unet_vgg16/samples/sample_4.png (deflated 2%)\n",
            "  adding: content/Finaldraft/outputs/unet_vgg16/samples/sample_0.png (deflated 3%)\n",
            "  adding: content/Finaldraft/outputs/unet_vgg16/samples/sample_3.png (deflated 2%)\n",
            "  adding: content/Finaldraft/outputs/unet_vgg16/unet_vgg16_loss.png (deflated 5%)\n",
            "  adding: content/Finaldraft/outputs/unet_vgg16/unet_vgg16_acc.png (deflated 5%)\n",
            "  adding: content/Finaldraft/outputs/unet_vgg16/classwise_iou.json (deflated 56%)\n",
            "  adding: content/Finaldraft/outputs/unet_vgg16/classwise_dice.json (deflated 56%)\n",
            "  adding: content/Finaldraft/outputs/attunet/ (stored 0%)\n",
            "  adding: content/Finaldraft/outputs/attunet/classwise_iou.png (deflated 3%)\n",
            "  adding: content/Finaldraft/outputs/attunet/classwise_dice.png (deflated 3%)\n",
            "  adding: content/Finaldraft/outputs/attunet/samples/ (stored 0%)\n",
            "  adding: content/Finaldraft/outputs/attunet/samples/sample_2.png (deflated 1%)\n",
            "  adding: content/Finaldraft/outputs/attunet/samples/sample_1.png (deflated 2%)\n",
            "  adding: content/Finaldraft/outputs/attunet/samples/sample_4.png (deflated 2%)\n",
            "  adding: content/Finaldraft/outputs/attunet/samples/sample_0.png (deflated 3%)\n",
            "  adding: content/Finaldraft/outputs/attunet/samples/sample_3.png (deflated 2%)\n",
            "  adding: content/Finaldraft/outputs/attunet/classwise_iou.json (deflated 54%)\n",
            "  adding: content/Finaldraft/outputs/attunet/best_attunet.pth (deflated 8%)\n",
            "  adding: content/Finaldraft/outputs/attunet/attunet_acc.png (deflated 6%)\n",
            "  adding: content/Finaldraft/outputs/attunet/classwise_dice.json (deflated 55%)\n",
            "  adding: content/Finaldraft/outputs/attunet/attunet_loss.png (deflated 6%)\n",
            "  adding: content/Finaldraft/outputs/deeplabv3plus_resnet34/ (stored 0%)\n",
            "  adding: content/Finaldraft/outputs/deeplabv3plus_resnet34/deeplabv3plus_resnet34_loss.png (deflated 8%)\n",
            "  adding: content/Finaldraft/outputs/deeplabv3plus_resnet34/deeplabv3plus_resnet34_acc.png (deflated 8%)\n",
            "  adding: content/Finaldraft/outputs/deeplabv3plus_resnet34/classwise_iou.png (deflated 3%)\n",
            "  adding: content/Finaldraft/outputs/deeplabv3plus_resnet34/classwise_dice.png (deflated 3%)\n",
            "  adding: content/Finaldraft/outputs/deeplabv3plus_resnet34/samples/ (stored 0%)\n",
            "  adding: content/Finaldraft/outputs/deeplabv3plus_resnet34/samples/sample_2.png (deflated 1%)\n",
            "  adding: content/Finaldraft/outputs/deeplabv3plus_resnet34/samples/sample_1.png (deflated 2%)\n",
            "  adding: content/Finaldraft/outputs/deeplabv3plus_resnet34/samples/sample_4.png (deflated 2%)\n",
            "  adding: content/Finaldraft/outputs/deeplabv3plus_resnet34/samples/sample_0.png (deflated 3%)\n",
            "  adding: content/Finaldraft/outputs/deeplabv3plus_resnet34/samples/sample_3.png (deflated 2%)\n",
            "  adding: content/Finaldraft/outputs/deeplabv3plus_resnet34/classwise_iou.json (deflated 54%)\n",
            "  adding: content/Finaldraft/outputs/deeplabv3plus_resnet34/best_deeplabv3plus_resnet34.pth (deflated 7%)\n",
            "  adding: content/Finaldraft/outputs/deeplabv3plus_resnet34/classwise_dice.json (deflated 55%)\n",
            "  adding: content/Finaldraft/train.py (deflated 68%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r /content/Finaldraft.zip /content/Finaldraft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "leqUjzQoawiL",
        "outputId": "48119901-31f9-49d1-dd58-cc3845bfb59c"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_a261eb93-9b96-4973-a904-c77900c5bbcc\", \"Finaldraft.zip\", 885142068)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download('/content/Finaldraft.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7MtDaYNa0HE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

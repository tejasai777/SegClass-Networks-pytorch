{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOgZyCGoMPY0",
        "outputId": "ab2eb496-0355-44bd-8eff-a217d22df2ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTovWOHGNOK5",
        "outputId": "f8cb634f-b0b6-44b5-abb3-e878afb6adff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!unzip -q /content/drive/MyDrive/projects/Finaldraft-PCBVISION.zip -d /content/\n",
        "%cd /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eThVFRDfNYJj",
        "outputId": "50f7b2ca-7c32-465c-f383-d7d7abafba35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m126.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m96.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m113.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# !pip install -q torch torchvision albumentations scikit-learn opencv-python\n",
        "# !pip install -q segmentation-models-pytorch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJqaTUJfQg_W",
        "outputId": "4291af15-2e85-40bf-9bdb-2edafe525b55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/Finaldraft-PCBVISION\n"
          ]
        }
      ],
      "source": [
        "%cd /content/Finaldraft-PCBVISION/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WAPVxQTdxZJ",
        "outputId": "1af7bbfa-177a-4f01-f6b4-8940fe734fe7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/Finaldraft-PCBVISION\n",
            "augmentation.py  models      outputs-fics  requirements.txt\n",
            "data\t\t network.py  __pycache__   train.py\n",
            "eval.py\t\t outputs     README.md\t   visualize.py\n"
          ]
        }
      ],
      "source": [
        "%cd /content/Finaldraft-PCBVISION\n",
        "!mkdir -p outputs\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tnf9Ynt0NxUu",
        "outputId": "3713c503-6ec0-43d8-f52c-1dba7d3325b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:111: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "Epoch 1/80 - Train Loss: 0.9575 | Val Loss: 0.8736\n",
            "✔️ Best model saved at epoch 1\n",
            "Epoch 2/80 - Train Loss: 0.8229 | Val Loss: 0.6989\n",
            "✔️ Best model saved at epoch 2\n",
            "Epoch 3/80 - Train Loss: 0.7563 | Val Loss: 0.6949\n",
            "✔️ Best model saved at epoch 3\n",
            "Epoch 4/80 - Train Loss: 0.7313 | Val Loss: 0.5843\n",
            "✔️ Best model saved at epoch 4\n",
            "Epoch 5/80 - Train Loss: 0.6902 | Val Loss: 0.5429\n",
            "✔️ Best model saved at epoch 5\n",
            "Epoch 6/80 - Train Loss: 0.6642 | Val Loss: 0.5403\n",
            "✔️ Best model saved at epoch 6\n",
            "Epoch 7/80 - Train Loss: 0.6379 | Val Loss: 0.4993\n",
            "✔️ Best model saved at epoch 7\n",
            "Epoch 8/80 - Train Loss: 0.6178 | Val Loss: 0.5175\n",
            "Epoch 9/80 - Train Loss: 0.5750 | Val Loss: 0.4459\n",
            "✔️ Best model saved at epoch 9\n",
            "Epoch 10/80 - Train Loss: 0.5616 | Val Loss: 0.4390\n",
            "✔️ Best model saved at epoch 10\n",
            "Epoch 11/80 - Train Loss: 0.5380 | Val Loss: 0.4139\n",
            "✔️ Best model saved at epoch 11\n",
            "Epoch 12/80 - Train Loss: 0.5269 | Val Loss: 0.4354\n",
            "Epoch 13/80 - Train Loss: 0.5128 | Val Loss: 0.3657\n",
            "✔️ Best model saved at epoch 13\n",
            "Epoch 14/80 - Train Loss: 0.4870 | Val Loss: 0.3596\n",
            "✔️ Best model saved at epoch 14\n",
            "Epoch 15/80 - Train Loss: 0.4574 | Val Loss: 0.3518\n",
            "✔️ Best model saved at epoch 15\n",
            "Epoch 16/80 - Train Loss: 0.4606 | Val Loss: 0.3241\n",
            "✔️ Best model saved at epoch 16\n",
            "Epoch 17/80 - Train Loss: 0.4621 | Val Loss: 0.3275\n",
            "Epoch 18/80 - Train Loss: 0.4513 | Val Loss: 0.3151\n",
            "✔️ Best model saved at epoch 18\n",
            "Epoch 19/80 - Train Loss: 0.4263 | Val Loss: 0.2885\n",
            "✔️ Best model saved at epoch 19\n",
            "Epoch 20/80 - Train Loss: 0.4237 | Val Loss: 0.3070\n",
            "Epoch 21/80 - Train Loss: 0.4114 | Val Loss: 0.3475\n",
            "Epoch 22/80 - Train Loss: 0.3877 | Val Loss: 0.2756\n",
            "✔️ Best model saved at epoch 22\n",
            "Epoch 23/80 - Train Loss: 0.3703 | Val Loss: 0.2433\n",
            "✔️ Best model saved at epoch 23\n",
            "Epoch 24/80 - Train Loss: 0.3572 | Val Loss: 0.2410\n",
            "✔️ Best model saved at epoch 24\n",
            "Epoch 25/80 - Train Loss: 0.3792 | Val Loss: 0.3722\n",
            "Epoch 26/80 - Train Loss: 0.3611 | Val Loss: 0.2548\n",
            "Epoch 27/80 - Train Loss: 0.3563 | Val Loss: 0.3756\n",
            "Epoch 28/80 - Train Loss: 0.3626 | Val Loss: 0.2322\n",
            "✔️ Best model saved at epoch 28\n",
            "Epoch 29/80 - Train Loss: 0.3334 | Val Loss: 0.2905\n",
            "Epoch 30/80 - Train Loss: 0.3357 | Val Loss: 0.2217\n",
            "✔️ Best model saved at epoch 30\n",
            "Epoch 31/80 - Train Loss: 0.3238 | Val Loss: 0.2367\n",
            "Epoch 32/80 - Train Loss: 0.3237 | Val Loss: 0.3191\n",
            "Epoch 33/80 - Train Loss: 0.3329 | Val Loss: 0.2411\n",
            "Epoch 34/80 - Train Loss: 0.3001 | Val Loss: 0.2773\n",
            "Epoch 35/80 - Train Loss: 0.3028 | Val Loss: 0.2149\n",
            "✔️ Best model saved at epoch 35\n",
            "Epoch 36/80 - Train Loss: 0.2960 | Val Loss: 0.2083\n",
            "✔️ Best model saved at epoch 36\n",
            "Epoch 37/80 - Train Loss: 0.2879 | Val Loss: 0.2154\n",
            "Epoch 38/80 - Train Loss: 0.2705 | Val Loss: 0.2005\n",
            "✔️ Best model saved at epoch 38\n",
            "Epoch 39/80 - Train Loss: 0.2594 | Val Loss: 0.1855\n",
            "✔️ Best model saved at epoch 39\n",
            "Epoch 40/80 - Train Loss: 0.2685 | Val Loss: 0.2255\n",
            "Epoch 41/80 - Train Loss: 0.2587 | Val Loss: 0.2047\n",
            "Epoch 42/80 - Train Loss: 0.2587 | Val Loss: 0.1855\n",
            "✔️ Best model saved at epoch 42\n",
            "Epoch 43/80 - Train Loss: 0.2470 | Val Loss: 0.2287\n",
            "Epoch 44/80 - Train Loss: 0.2597 | Val Loss: 0.1937\n",
            "Epoch 45/80 - Train Loss: 0.2573 | Val Loss: 0.1830\n",
            "✔️ Best model saved at epoch 45\n",
            "Epoch 46/80 - Train Loss: 0.2268 | Val Loss: 0.2007\n",
            "Epoch 47/80 - Train Loss: 0.2335 | Val Loss: 0.1924\n",
            "Epoch 48/80 - Train Loss: 0.2265 | Val Loss: 0.1691\n",
            "✔️ Best model saved at epoch 48\n",
            "Epoch 49/80 - Train Loss: 0.2175 | Val Loss: 0.1864\n",
            "Epoch 50/80 - Train Loss: 0.2042 | Val Loss: 0.1637\n",
            "✔️ Best model saved at epoch 50\n",
            "Epoch 51/80 - Train Loss: 0.1928 | Val Loss: 0.1657\n",
            "Epoch 52/80 - Train Loss: 0.2223 | Val Loss: 0.1728\n",
            "Epoch 53/80 - Train Loss: 0.2173 | Val Loss: 0.2208\n",
            "Epoch 54/80 - Train Loss: 0.1893 | Val Loss: 0.1937\n",
            "Epoch 55/80 - Train Loss: 0.1761 | Val Loss: 0.1844\n",
            "Epoch 56/80 - Train Loss: 0.2135 | Val Loss: 0.1884\n",
            "Epoch 57/80 - Train Loss: 0.2017 | Val Loss: 0.1599\n",
            "✔️ Best model saved at epoch 57\n",
            "Epoch 58/80 - Train Loss: 0.1879 | Val Loss: 0.1713\n",
            "Epoch 59/80 - Train Loss: 0.1847 | Val Loss: 0.1798\n",
            "Epoch 60/80 - Train Loss: 0.1648 | Val Loss: 0.1529\n",
            "✔️ Best model saved at epoch 60\n",
            "Epoch 61/80 - Train Loss: 0.1657 | Val Loss: 0.1456\n",
            "✔️ Best model saved at epoch 61\n",
            "Epoch 62/80 - Train Loss: 0.1755 | Val Loss: 0.1522\n",
            "Epoch 63/80 - Train Loss: 0.1639 | Val Loss: 0.1442\n",
            "✔️ Best model saved at epoch 63\n",
            "Epoch 64/80 - Train Loss: 0.1469 | Val Loss: 0.1784\n",
            "Epoch 65/80 - Train Loss: 0.1534 | Val Loss: 0.1702\n",
            "Epoch 66/80 - Train Loss: 0.1412 | Val Loss: 0.2084\n",
            "Epoch 67/80 - Train Loss: 0.1455 | Val Loss: 0.2170\n",
            "Epoch 68/80 - Train Loss: 0.1634 | Val Loss: 0.2389\n",
            "Epoch 69/80 - Train Loss: 0.1647 | Val Loss: 0.1866\n",
            "Epoch 70/80 - Train Loss: 0.1734 | Val Loss: 0.1487\n",
            "Epoch 71/80 - Train Loss: 0.1522 | Val Loss: 0.1875\n",
            "Epoch 72/80 - Train Loss: 0.1523 | Val Loss: 0.1755\n",
            "Epoch 73/80 - Train Loss: 0.1519 | Val Loss: 0.1945\n",
            "Epoch 74/80 - Train Loss: 0.1607 | Val Loss: 0.1478\n",
            "Epoch 75/80 - Train Loss: 0.1324 | Val Loss: 0.1903\n",
            "Epoch 76/80 - Train Loss: 0.1371 | Val Loss: 0.1470\n",
            "Epoch 77/80 - Train Loss: 0.1452 | Val Loss: 0.1899\n",
            "Epoch 78/80 - Train Loss: 0.1611 | Val Loss: 0.2365\n",
            "Epoch 79/80 - Train Loss: 0.1363 | Val Loss: 0.1677\n",
            "Epoch 80/80 - Train Loss: 0.1188 | Val Loss: 0.1602\n",
            "Evaluation Metrics:\n",
            "pixel_accuracy: 0.9779728536402925\n",
            "precision: [0.99174303 0.76460663 0.86200121 0.72268305]\n",
            "recall: [0.98485837 0.93257143 0.76660875 0.47307911]\n",
            "f1_score: [0.98828871 0.84027753 0.81151127 0.57182986]\n",
            "iou: [0.97684856 0.72455054 0.6828094  0.40039338]\n",
            "dice_score: [0.98828871 0.84027753 0.81151127 0.57182986]\n",
            "Total params: 31,037,828\n",
            "Model size: 118.40 MB\n"
          ]
        }
      ],
      "source": [
        "# from inside /content/project_root\n",
        "!python train.py \\\n",
        "  --model unet \\\n",
        "  --data-dir data \\\n",
        "  --output-dir /content/Finaldraft/outputs \\\n",
        "  --img-size 640 \\\n",
        "  --batch-size 8 \\\n",
        "  --epochs 80 \\\n",
        "  --lr 1e-4 \\\n",
        "  --patience 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOc_aDOPgc2T",
        "outputId": "1dad41b4-fab3-4d4f-d65c-fc47ca37989a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:111: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "Epoch 1/80 - Train Loss: 0.9909 | Val Loss: 0.8551\n",
            "✔️ Best model saved at epoch 1\n",
            "Epoch 2/80 - Train Loss: 0.9038 | Val Loss: 0.7491\n",
            "✔️ Best model saved at epoch 2\n",
            "Epoch 3/80 - Train Loss: 0.8434 | Val Loss: 0.7198\n",
            "✔️ Best model saved at epoch 3\n",
            "Epoch 4/80 - Train Loss: 0.7768 | Val Loss: 0.6290\n",
            "✔️ Best model saved at epoch 4\n",
            "Epoch 5/80 - Train Loss: 0.7779 | Val Loss: 0.7430\n",
            "Epoch 6/80 - Train Loss: 0.7115 | Val Loss: 0.5755\n",
            "✔️ Best model saved at epoch 6\n",
            "Epoch 7/80 - Train Loss: 0.6846 | Val Loss: 0.5637\n",
            "✔️ Best model saved at epoch 7\n",
            "Epoch 8/80 - Train Loss: 0.6872 | Val Loss: 0.5787\n",
            "Epoch 9/80 - Train Loss: 0.6653 | Val Loss: 0.5601\n",
            "✔️ Best model saved at epoch 9\n",
            "Epoch 10/80 - Train Loss: 0.6516 | Val Loss: 0.4963\n",
            "✔️ Best model saved at epoch 10\n",
            "Epoch 11/80 - Train Loss: 0.6274 | Val Loss: 0.5014\n",
            "Epoch 12/80 - Train Loss: 0.5957 | Val Loss: 0.4721\n",
            "✔️ Best model saved at epoch 12\n",
            "Epoch 13/80 - Train Loss: 0.6059 | Val Loss: 0.4328\n",
            "✔️ Best model saved at epoch 13\n",
            "Epoch 14/80 - Train Loss: 0.5885 | Val Loss: 0.4414\n",
            "Epoch 15/80 - Train Loss: 0.5496 | Val Loss: 0.4157\n",
            "✔️ Best model saved at epoch 15\n",
            "Epoch 16/80 - Train Loss: 0.5277 | Val Loss: 0.4094\n",
            "✔️ Best model saved at epoch 16\n",
            "Epoch 17/80 - Train Loss: 0.5214 | Val Loss: 0.3898\n",
            "✔️ Best model saved at epoch 17\n",
            "Epoch 18/80 - Train Loss: 0.5133 | Val Loss: 0.4032\n",
            "Epoch 19/80 - Train Loss: 0.5102 | Val Loss: 0.3737\n",
            "✔️ Best model saved at epoch 19\n",
            "Epoch 20/80 - Train Loss: 0.5078 | Val Loss: 0.3647\n",
            "✔️ Best model saved at epoch 20\n",
            "Epoch 21/80 - Train Loss: 0.5228 | Val Loss: 0.3787\n",
            "Epoch 22/80 - Train Loss: 0.4961 | Val Loss: 0.3524\n",
            "✔️ Best model saved at epoch 22\n",
            "Epoch 23/80 - Train Loss: 0.4697 | Val Loss: 0.3442\n",
            "✔️ Best model saved at epoch 23\n",
            "Epoch 24/80 - Train Loss: 0.4569 | Val Loss: 0.3449\n",
            "Epoch 25/80 - Train Loss: 0.4603 | Val Loss: 0.3390\n",
            "✔️ Best model saved at epoch 25\n",
            "Epoch 26/80 - Train Loss: 0.4231 | Val Loss: 0.3078\n",
            "✔️ Best model saved at epoch 26\n",
            "Epoch 27/80 - Train Loss: 0.4358 | Val Loss: 0.3316\n",
            "Epoch 28/80 - Train Loss: 0.4490 | Val Loss: 0.3314\n",
            "Epoch 29/80 - Train Loss: 0.4313 | Val Loss: 0.2782\n",
            "✔️ Best model saved at epoch 29\n",
            "Epoch 30/80 - Train Loss: 0.4149 | Val Loss: 0.2916\n",
            "Epoch 31/80 - Train Loss: 0.4065 | Val Loss: 0.3034\n",
            "Epoch 32/80 - Train Loss: 0.4289 | Val Loss: 0.2831\n",
            "Epoch 33/80 - Train Loss: 0.4086 | Val Loss: 0.2715\n",
            "✔️ Best model saved at epoch 33\n",
            "Epoch 34/80 - Train Loss: 0.3840 | Val Loss: 0.2549\n",
            "✔️ Best model saved at epoch 34\n",
            "Epoch 35/80 - Train Loss: 0.3905 | Val Loss: 0.2729\n",
            "Epoch 36/80 - Train Loss: 0.3903 | Val Loss: 0.2562\n",
            "Epoch 37/80 - Train Loss: 0.3611 | Val Loss: 0.2595\n",
            "Epoch 38/80 - Train Loss: 0.3674 | Val Loss: 0.2388\n",
            "✔️ Best model saved at epoch 38\n",
            "Epoch 39/80 - Train Loss: 0.3667 | Val Loss: 0.2457\n",
            "Epoch 40/80 - Train Loss: 0.3440 | Val Loss: 0.2267\n",
            "✔️ Best model saved at epoch 40\n",
            "Epoch 41/80 - Train Loss: 0.3396 | Val Loss: 0.2656\n",
            "Epoch 42/80 - Train Loss: 0.3615 | Val Loss: 0.2282\n",
            "Epoch 43/80 - Train Loss: 0.3589 | Val Loss: 0.2175\n",
            "✔️ Best model saved at epoch 43\n",
            "Epoch 44/80 - Train Loss: 0.3447 | Val Loss: 0.2129\n",
            "✔️ Best model saved at epoch 44\n",
            "Epoch 45/80 - Train Loss: 0.3366 | Val Loss: 0.2374\n",
            "Epoch 46/80 - Train Loss: 0.3285 | Val Loss: 0.2467\n",
            "Epoch 47/80 - Train Loss: 0.3074 | Val Loss: 0.2155\n",
            "Epoch 48/80 - Train Loss: 0.3434 | Val Loss: 0.2407\n",
            "Epoch 49/80 - Train Loss: 0.3108 | Val Loss: 0.2127\n",
            "✔️ Best model saved at epoch 49\n",
            "Epoch 50/80 - Train Loss: 0.3360 | Val Loss: 0.2182\n",
            "Epoch 51/80 - Train Loss: 0.2965 | Val Loss: 0.2292\n",
            "Epoch 52/80 - Train Loss: 0.2807 | Val Loss: 0.2139\n",
            "Epoch 53/80 - Train Loss: 0.3258 | Val Loss: 0.2145\n",
            "Epoch 54/80 - Train Loss: 0.2920 | Val Loss: 0.1978\n",
            "✔️ Best model saved at epoch 54\n",
            "Epoch 55/80 - Train Loss: 0.2842 | Val Loss: 0.2031\n",
            "Epoch 56/80 - Train Loss: 0.2725 | Val Loss: 0.1921\n",
            "✔️ Best model saved at epoch 56\n",
            "Epoch 57/80 - Train Loss: 0.2726 | Val Loss: 0.1821\n",
            "✔️ Best model saved at epoch 57\n",
            "Epoch 58/80 - Train Loss: 0.2782 | Val Loss: 0.2113\n",
            "Epoch 59/80 - Train Loss: 0.2817 | Val Loss: 0.1831\n",
            "Epoch 60/80 - Train Loss: 0.2606 | Val Loss: 0.1803\n",
            "✔️ Best model saved at epoch 60\n",
            "Epoch 61/80 - Train Loss: 0.2644 | Val Loss: 0.2582\n",
            "Epoch 62/80 - Train Loss: 0.2504 | Val Loss: 0.1702\n",
            "✔️ Best model saved at epoch 62\n",
            "Epoch 63/80 - Train Loss: 0.2378 | Val Loss: 0.1875\n",
            "Epoch 64/80 - Train Loss: 0.2347 | Val Loss: 0.1841\n",
            "Epoch 65/80 - Train Loss: 0.2464 | Val Loss: 0.1847\n",
            "Epoch 66/80 - Train Loss: 0.2323 | Val Loss: 0.1762\n",
            "Epoch 67/80 - Train Loss: 0.2346 | Val Loss: 0.2009\n",
            "Epoch 68/80 - Train Loss: 0.2328 | Val Loss: 0.2073\n",
            "Epoch 69/80 - Train Loss: 0.2441 | Val Loss: 0.1965\n",
            "Epoch 70/80 - Train Loss: 0.2366 | Val Loss: 0.1705\n",
            "Epoch 71/80 - Train Loss: 0.2358 | Val Loss: 0.1537\n",
            "✔️ Best model saved at epoch 71\n",
            "Epoch 72/80 - Train Loss: 0.2221 | Val Loss: 0.1796\n",
            "Epoch 73/80 - Train Loss: 0.2201 | Val Loss: 0.1782\n",
            "Epoch 74/80 - Train Loss: 0.2024 | Val Loss: 0.1618\n",
            "Epoch 75/80 - Train Loss: 0.1951 | Val Loss: 0.2061\n",
            "Epoch 76/80 - Train Loss: 0.2134 | Val Loss: 0.2100\n",
            "Epoch 77/80 - Train Loss: 0.2161 | Val Loss: 0.1743\n",
            "Epoch 78/80 - Train Loss: 0.2143 | Val Loss: 0.1836\n",
            "Epoch 79/80 - Train Loss: 0.2286 | Val Loss: 0.2196\n",
            "Epoch 80/80 - Train Loss: 0.2059 | Val Loss: 0.2068\n",
            "Evaluation Metrics:\n",
            "pixel_accuracy: 0.9547768970246011\n",
            "precision: [0.99149425 0.53385879 0.82604641 0.75606126]\n",
            "recall: [0.96050248 0.95929306 0.76736116 0.17594941]\n",
            "f1_score: [0.97575233 0.68596778 0.79562309 0.28546568]\n",
            "iou: [0.95265274 0.5220327  0.66060973 0.1664975 ]\n",
            "dice_score: [0.97575233 0.68596778 0.79562309 0.28546568]\n",
            "Total params: 41,896,932\n",
            "Model size: 159.82 MB\n"
          ]
        }
      ],
      "source": [
        "# from inside /content/project_root\n",
        "!python train.py \\\n",
        "  --model unet_vgg16 \\\n",
        "  --data-dir data \\\n",
        "  --output-dir /content/Finaldraft/outputs \\\n",
        "  --img-size 640 \\\n",
        "  --batch-size 8 \\\n",
        "  --epochs 80 \\\n",
        "  --lr 1e-4 \\\n",
        "  --patience 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vt_DT6gIQZsb",
        "outputId": "f61bb98b-5cd2-494d-d709-0c8e5855e763"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:111: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "Epoch 1/80 - Train Loss: 0.9273 | Val Loss: 0.7886\n",
            "✔️ Best model saved at epoch 1\n",
            "Epoch 2/80 - Train Loss: 0.7991 | Val Loss: 0.9365\n",
            "Epoch 3/80 - Train Loss: 0.7665 | Val Loss: 0.6242\n",
            "✔️ Best model saved at epoch 3\n",
            "Epoch 4/80 - Train Loss: 0.7058 | Val Loss: 0.6168\n",
            "✔️ Best model saved at epoch 4\n",
            "Epoch 5/80 - Train Loss: 0.6923 | Val Loss: 0.6327\n",
            "Epoch 6/80 - Train Loss: 0.6567 | Val Loss: 0.5646\n",
            "✔️ Best model saved at epoch 6\n",
            "Epoch 7/80 - Train Loss: 0.6297 | Val Loss: 0.4751\n",
            "✔️ Best model saved at epoch 7\n",
            "Epoch 8/80 - Train Loss: 0.6265 | Val Loss: 0.6432\n",
            "Epoch 9/80 - Train Loss: 0.5783 | Val Loss: 0.4388\n",
            "✔️ Best model saved at epoch 9\n",
            "Epoch 10/80 - Train Loss: 0.5549 | Val Loss: 0.4234\n",
            "✔️ Best model saved at epoch 10\n",
            "Epoch 11/80 - Train Loss: 0.5502 | Val Loss: 0.4389\n",
            "Epoch 12/80 - Train Loss: 0.5347 | Val Loss: 0.4169\n",
            "✔️ Best model saved at epoch 12\n",
            "Epoch 13/80 - Train Loss: 0.5162 | Val Loss: 0.3920\n",
            "✔️ Best model saved at epoch 13\n",
            "Epoch 14/80 - Train Loss: 0.5046 | Val Loss: 0.4288\n",
            "Epoch 15/80 - Train Loss: 0.5051 | Val Loss: 0.3444\n",
            "✔️ Best model saved at epoch 15\n",
            "Epoch 16/80 - Train Loss: 0.4676 | Val Loss: 0.3295\n",
            "✔️ Best model saved at epoch 16\n",
            "Epoch 17/80 - Train Loss: 0.4507 | Val Loss: 0.3805\n",
            "Epoch 18/80 - Train Loss: 0.4532 | Val Loss: 0.3434\n",
            "Epoch 19/80 - Train Loss: 0.4374 | Val Loss: 0.2994\n",
            "✔️ Best model saved at epoch 19\n",
            "Epoch 20/80 - Train Loss: 0.4193 | Val Loss: 0.3071\n",
            "Epoch 21/80 - Train Loss: 0.4178 | Val Loss: 0.3630\n",
            "Epoch 22/80 - Train Loss: 0.4335 | Val Loss: 0.3733\n",
            "Epoch 23/80 - Train Loss: 0.4014 | Val Loss: 0.3020\n",
            "Epoch 24/80 - Train Loss: 0.3928 | Val Loss: 0.2536\n",
            "✔️ Best model saved at epoch 24\n",
            "Epoch 25/80 - Train Loss: 0.3950 | Val Loss: 0.3269\n",
            "Epoch 26/80 - Train Loss: 0.4088 | Val Loss: 0.2811\n",
            "Epoch 27/80 - Train Loss: 0.3597 | Val Loss: 0.2501\n",
            "✔️ Best model saved at epoch 27\n",
            "Epoch 28/80 - Train Loss: 0.3444 | Val Loss: 0.2452\n",
            "✔️ Best model saved at epoch 28\n",
            "Epoch 29/80 - Train Loss: 0.3493 | Val Loss: 0.3951\n",
            "Epoch 30/80 - Train Loss: 0.3261 | Val Loss: 0.2357\n",
            "✔️ Best model saved at epoch 30\n",
            "Epoch 31/80 - Train Loss: 0.3209 | Val Loss: 0.2625\n",
            "Epoch 32/80 - Train Loss: 0.3124 | Val Loss: 0.2486\n",
            "Epoch 33/80 - Train Loss: 0.3223 | Val Loss: 0.2371\n",
            "Epoch 34/80 - Train Loss: 0.3316 | Val Loss: 0.2677\n",
            "Epoch 35/80 - Train Loss: 0.3297 | Val Loss: 0.2775\n",
            "Epoch 36/80 - Train Loss: 0.3235 | Val Loss: 0.2070\n",
            "✔️ Best model saved at epoch 36\n",
            "Epoch 37/80 - Train Loss: 0.3231 | Val Loss: 0.2702\n",
            "Epoch 38/80 - Train Loss: 0.3220 | Val Loss: 0.2060\n",
            "✔️ Best model saved at epoch 38\n",
            "Epoch 39/80 - Train Loss: 0.3081 | Val Loss: 0.2065\n",
            "Epoch 40/80 - Train Loss: 0.2962 | Val Loss: 0.2361\n",
            "Epoch 41/80 - Train Loss: 0.2902 | Val Loss: 0.1912\n",
            "✔️ Best model saved at epoch 41\n",
            "Epoch 42/80 - Train Loss: 0.2681 | Val Loss: 0.1828\n",
            "✔️ Best model saved at epoch 42\n",
            "Epoch 43/80 - Train Loss: 0.2728 | Val Loss: 0.1997\n",
            "Epoch 44/80 - Train Loss: 0.2391 | Val Loss: 0.2325\n",
            "Epoch 45/80 - Train Loss: 0.2697 | Val Loss: 0.1751\n",
            "✔️ Best model saved at epoch 45\n",
            "Epoch 46/80 - Train Loss: 0.2456 | Val Loss: 0.1814\n",
            "Epoch 47/80 - Train Loss: 0.2499 | Val Loss: 0.1752\n",
            "Epoch 48/80 - Train Loss: 0.2344 | Val Loss: 0.2172\n",
            "Epoch 49/80 - Train Loss: 0.2446 | Val Loss: 0.2576\n",
            "Epoch 50/80 - Train Loss: 0.2480 | Val Loss: 0.2087\n",
            "Epoch 51/80 - Train Loss: 0.2239 | Val Loss: 0.1904\n",
            "Epoch 52/80 - Train Loss: 0.2095 | Val Loss: 0.1707\n",
            "✔️ Best model saved at epoch 52\n",
            "Epoch 53/80 - Train Loss: 0.2251 | Val Loss: 0.1765\n",
            "Epoch 54/80 - Train Loss: 0.2126 | Val Loss: 0.1789\n",
            "Epoch 55/80 - Train Loss: 0.2198 | Val Loss: 0.1872\n",
            "Epoch 56/80 - Train Loss: 0.2212 | Val Loss: 0.1783\n",
            "Epoch 57/80 - Train Loss: 0.1948 | Val Loss: 0.1732\n",
            "Epoch 58/80 - Train Loss: 0.1780 | Val Loss: 0.1746\n",
            "Epoch 59/80 - Train Loss: 0.1793 | Val Loss: 0.1674\n",
            "✔️ Best model saved at epoch 59\n",
            "Epoch 60/80 - Train Loss: 0.1899 | Val Loss: 0.2077\n",
            "Epoch 61/80 - Train Loss: 0.1871 | Val Loss: 0.1821\n",
            "Epoch 62/80 - Train Loss: 0.2109 | Val Loss: 0.1565\n",
            "✔️ Best model saved at epoch 62\n",
            "Epoch 63/80 - Train Loss: 0.1738 | Val Loss: 0.1728\n",
            "Epoch 64/80 - Train Loss: 0.1803 | Val Loss: 0.2058\n",
            "Epoch 65/80 - Train Loss: 0.1656 | Val Loss: 0.1830\n",
            "Epoch 66/80 - Train Loss: 0.1764 | Val Loss: 0.1775\n",
            "Epoch 67/80 - Train Loss: 0.1830 | Val Loss: 0.1840\n",
            "Epoch 68/80 - Train Loss: 0.1641 | Val Loss: 0.1735\n",
            "Epoch 69/80 - Train Loss: 0.1579 | Val Loss: 0.1884\n",
            "Epoch 70/80 - Train Loss: 0.1638 | Val Loss: 0.2620\n",
            "Epoch 71/80 - Train Loss: 0.1689 | Val Loss: 0.2159\n",
            "Epoch 72/80 - Train Loss: 0.1683 | Val Loss: 0.1823\n",
            "Epoch 73/80 - Train Loss: 0.1778 | Val Loss: 0.1784\n",
            "Epoch 74/80 - Train Loss: 0.1877 | Val Loss: 0.2234\n",
            "Epoch 75/80 - Train Loss: 0.1853 | Val Loss: 0.1788\n",
            "Epoch 76/80 - Train Loss: 0.1575 | Val Loss: 0.1424\n",
            "✔️ Best model saved at epoch 76\n",
            "Epoch 77/80 - Train Loss: 0.1534 | Val Loss: 0.1701\n",
            "Epoch 78/80 - Train Loss: 0.1438 | Val Loss: 0.2048\n",
            "Epoch 79/80 - Train Loss: 0.1505 | Val Loss: 0.1690\n",
            "Epoch 80/80 - Train Loss: 0.1325 | Val Loss: 0.2131\n",
            "Evaluation Metrics:\n",
            "pixel_accuracy: 0.9775689827127659\n",
            "precision: [0.98960254 0.77111639 0.89974999 0.97033629]\n",
            "recall: [0.98686049 0.94115015 0.69297633 0.06834408]\n",
            "f1_score: [0.98822961 0.84769081 0.78294109 0.12769422]\n",
            "iou: [0.97673308 0.73564528 0.64330584 0.06820158]\n",
            "dice_score: [0.98822961 0.84769081 0.78294109 0.12769422]\n",
            "Total params: 34,878,768\n",
            "Model size: 133.05 MB\n"
          ]
        }
      ],
      "source": [
        "# from inside /content/project_root\n",
        "!python train.py \\\n",
        "  --model attunet \\\n",
        "  --data-dir data \\\n",
        "  --output-dir /content/Finaldraft/outputs \\\n",
        "  --img-size 640 \\\n",
        "  --batch-size 8 \\\n",
        "  --epochs 80 \\\n",
        "  --lr 1e-4 \\\n",
        "  --patience 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDxkl7CbhWNn",
        "outputId": "c2c114d0-2544-4f92-bd6e-2cc7d36c4aa7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:111: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "config.json: 100% 156/156 [00:00<00:00, 1.12MB/s]\n",
            "model.safetensors: 100% 87.3M/87.3M [00:00<00:00, 186MB/s]\n",
            "Epoch 1/80 - Train Loss: 0.9456 | Val Loss: 0.7723\n",
            "✔️ Best model saved at epoch 1\n",
            "Epoch 2/80 - Train Loss: 0.7232 | Val Loss: 0.6639\n",
            "✔️ Best model saved at epoch 2\n",
            "Epoch 3/80 - Train Loss: 0.5902 | Val Loss: 0.3820\n",
            "✔️ Best model saved at epoch 3\n",
            "Epoch 4/80 - Train Loss: 0.4765 | Val Loss: 0.3141\n",
            "✔️ Best model saved at epoch 4\n",
            "Epoch 5/80 - Train Loss: 0.4329 | Val Loss: 0.2728\n",
            "✔️ Best model saved at epoch 5\n",
            "Epoch 6/80 - Train Loss: 0.3860 | Val Loss: 0.2552\n",
            "✔️ Best model saved at epoch 6\n",
            "Epoch 7/80 - Train Loss: 0.3520 | Val Loss: 0.2295\n",
            "✔️ Best model saved at epoch 7\n",
            "Epoch 8/80 - Train Loss: 0.3345 | Val Loss: 0.2112\n",
            "✔️ Best model saved at epoch 8\n",
            "Epoch 9/80 - Train Loss: 0.3178 | Val Loss: 0.2047\n",
            "✔️ Best model saved at epoch 9\n",
            "Epoch 10/80 - Train Loss: 0.2759 | Val Loss: 0.1995\n",
            "✔️ Best model saved at epoch 10\n",
            "Epoch 11/80 - Train Loss: 0.2716 | Val Loss: 0.1779\n",
            "✔️ Best model saved at epoch 11\n",
            "Epoch 12/80 - Train Loss: 0.2542 | Val Loss: 0.1634\n",
            "✔️ Best model saved at epoch 12\n",
            "Epoch 13/80 - Train Loss: 0.2394 | Val Loss: 0.1854\n",
            "Epoch 14/80 - Train Loss: 0.2136 | Val Loss: 0.1589\n",
            "✔️ Best model saved at epoch 14\n",
            "Epoch 15/80 - Train Loss: 0.2208 | Val Loss: 0.1559\n",
            "✔️ Best model saved at epoch 15\n",
            "Epoch 16/80 - Train Loss: 0.2005 | Val Loss: 0.1624\n",
            "Epoch 17/80 - Train Loss: 0.1859 | Val Loss: 0.1705\n",
            "Epoch 18/80 - Train Loss: 0.1865 | Val Loss: 0.1463\n",
            "✔️ Best model saved at epoch 18\n",
            "Epoch 19/80 - Train Loss: 0.1766 | Val Loss: 0.1439\n",
            "✔️ Best model saved at epoch 19\n",
            "Epoch 20/80 - Train Loss: 0.1524 | Val Loss: 0.1493\n",
            "Epoch 21/80 - Train Loss: 0.1633 | Val Loss: 0.1422\n",
            "✔️ Best model saved at epoch 21\n",
            "Epoch 22/80 - Train Loss: 0.1426 | Val Loss: 0.1179\n",
            "✔️ Best model saved at epoch 22\n",
            "Epoch 23/80 - Train Loss: 0.1359 | Val Loss: 0.1447\n",
            "Epoch 24/80 - Train Loss: 0.1442 | Val Loss: 0.1598\n",
            "Epoch 25/80 - Train Loss: 0.1377 | Val Loss: 0.1356\n",
            "Epoch 26/80 - Train Loss: 0.1329 | Val Loss: 0.1314\n",
            "Epoch 27/80 - Train Loss: 0.1327 | Val Loss: 0.1445\n",
            "Epoch 28/80 - Train Loss: 0.1224 | Val Loss: 0.1721\n",
            "Epoch 29/80 - Train Loss: 0.1220 | Val Loss: 0.1617\n",
            "Epoch 30/80 - Train Loss: 0.1167 | Val Loss: 0.1383\n",
            "Epoch 31/80 - Train Loss: 0.1055 | Val Loss: 0.1632\n",
            "Epoch 32/80 - Train Loss: 0.1039 | Val Loss: 0.1536\n",
            "Epoch 33/80 - Train Loss: 0.1012 | Val Loss: 0.1333\n",
            "Epoch 34/80 - Train Loss: 0.0981 | Val Loss: 0.1719\n",
            "Epoch 35/80 - Train Loss: 0.0999 | Val Loss: 0.1441\n",
            "Epoch 36/80 - Train Loss: 0.0979 | Val Loss: 0.1445\n",
            "Epoch 37/80 - Train Loss: 0.1037 | Val Loss: 0.1376\n",
            "Epoch 38/80 - Train Loss: 0.0992 | Val Loss: 0.1500\n",
            "Epoch 39/80 - Train Loss: 0.1041 | Val Loss: 0.1696\n",
            "Epoch 40/80 - Train Loss: 0.0979 | Val Loss: 0.1563\n",
            "Epoch 41/80 - Train Loss: 0.0942 | Val Loss: 0.1446\n",
            "Epoch 42/80 - Train Loss: 0.0854 | Val Loss: 0.1369\n",
            "⏹️ Early stopping.\n",
            "Evaluation Metrics:\n",
            "pixel_accuracy: 0.9840038543051862\n",
            "precision: [0.99125285 0.84737633 0.92694292 0.93313503]\n",
            "recall: [0.99177935 0.90529579 0.7444423  0.66594416]\n",
            "f1_score: [0.99151603 0.87537904 0.82572887 0.77721707]\n",
            "iou: [0.98317481 0.77837696 0.70318418 0.63561328]\n",
            "dice_score: [0.99151603 0.87537904 0.82572887 0.77721707]\n",
            "Total params: 22,438,228\n",
            "Model size: 85.60 MB\n"
          ]
        }
      ],
      "source": [
        "# from inside /content/project_root\n",
        "!python train.py \\\n",
        "  --model deeplabv3plus_resnet34\\\n",
        "  --data-dir data \\\n",
        "  --output-dir /content/Finaldraft/outputs \\\n",
        "  --img-size 640 \\\n",
        "  --batch-size 8 \\\n",
        "  --epochs 80 \\\n",
        "  --lr 1e-4 \\\n",
        "  --patience 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bHPDE0oXou5",
        "outputId": "2d8349f6-4625-4514-e2ff-e354b8aed7da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:111: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "config.json: 100% 135/135 [00:00<00:00, 769kB/s]\n",
            "model.safetensors: 100% 14.3M/14.3M [00:00<00:00, 33.9MB/s]\n",
            "Epoch 1/80 - Train Loss: 0.9276 | Val Loss: 0.8197\n",
            "✔️ Best model saved at epoch 1\n",
            "Epoch 2/80 - Train Loss: 0.7029 | Val Loss: 0.5671\n",
            "✔️ Best model saved at epoch 2\n",
            "Epoch 3/80 - Train Loss: 0.5938 | Val Loss: 0.3847\n",
            "✔️ Best model saved at epoch 3\n",
            "Epoch 4/80 - Train Loss: 0.5140 | Val Loss: 0.3644\n",
            "✔️ Best model saved at epoch 4\n",
            "Epoch 5/80 - Train Loss: 0.4502 | Val Loss: 0.3120\n",
            "✔️ Best model saved at epoch 5\n",
            "Epoch 6/80 - Train Loss: 0.4279 | Val Loss: 0.2468\n",
            "✔️ Best model saved at epoch 6\n",
            "Epoch 7/80 - Train Loss: 0.3789 | Val Loss: 0.2337\n",
            "✔️ Best model saved at epoch 7\n",
            "Epoch 8/80 - Train Loss: 0.3462 | Val Loss: 0.2070\n",
            "✔️ Best model saved at epoch 8\n",
            "Epoch 9/80 - Train Loss: 0.3451 | Val Loss: 0.2042\n",
            "✔️ Best model saved at epoch 9\n",
            "Epoch 10/80 - Train Loss: 0.3194 | Val Loss: 0.1916\n",
            "✔️ Best model saved at epoch 10\n",
            "Epoch 11/80 - Train Loss: 0.2851 | Val Loss: 0.1714\n",
            "✔️ Best model saved at epoch 11\n",
            "Epoch 12/80 - Train Loss: 0.2623 | Val Loss: 0.1752\n",
            "Epoch 13/80 - Train Loss: 0.2607 | Val Loss: 0.1769\n",
            "Epoch 14/80 - Train Loss: 0.2551 | Val Loss: 0.1616\n",
            "✔️ Best model saved at epoch 14\n",
            "Epoch 15/80 - Train Loss: 0.2312 | Val Loss: 0.1516\n",
            "✔️ Best model saved at epoch 15\n",
            "Epoch 16/80 - Train Loss: 0.2191 | Val Loss: 0.1408\n",
            "✔️ Best model saved at epoch 16\n",
            "Epoch 17/80 - Train Loss: 0.2014 | Val Loss: 0.1496\n",
            "Epoch 18/80 - Train Loss: 0.1944 | Val Loss: 0.1521\n",
            "Epoch 19/80 - Train Loss: 0.1874 | Val Loss: 0.1609\n",
            "Epoch 20/80 - Train Loss: 0.1780 | Val Loss: 0.1747\n",
            "Epoch 21/80 - Train Loss: 0.1700 | Val Loss: 0.1367\n",
            "✔️ Best model saved at epoch 21\n",
            "Epoch 22/80 - Train Loss: 0.1619 | Val Loss: 0.1441\n",
            "Epoch 23/80 - Train Loss: 0.1725 | Val Loss: 0.1547\n",
            "Epoch 24/80 - Train Loss: 0.1757 | Val Loss: 0.1731\n",
            "Epoch 25/80 - Train Loss: 0.1555 | Val Loss: 0.1534\n",
            "Epoch 26/80 - Train Loss: 0.1673 | Val Loss: 0.1494\n",
            "Epoch 27/80 - Train Loss: 0.1735 | Val Loss: 0.1633\n",
            "Epoch 28/80 - Train Loss: 0.1546 | Val Loss: 0.1624\n",
            "Epoch 29/80 - Train Loss: 0.1361 | Val Loss: 0.1589\n",
            "Epoch 30/80 - Train Loss: 0.1413 | Val Loss: 0.1344\n",
            "✔️ Best model saved at epoch 30\n",
            "Epoch 31/80 - Train Loss: 0.1440 | Val Loss: 0.1440\n",
            "Epoch 32/80 - Train Loss: 0.1453 | Val Loss: 0.1566\n",
            "Epoch 33/80 - Train Loss: 0.1306 | Val Loss: 0.1459\n",
            "Epoch 34/80 - Train Loss: 0.1216 | Val Loss: 0.1608\n",
            "Epoch 35/80 - Train Loss: 0.1249 | Val Loss: 0.1423\n",
            "Epoch 36/80 - Train Loss: 0.1157 | Val Loss: 0.1400\n",
            "Epoch 37/80 - Train Loss: 0.1306 | Val Loss: 0.1341\n",
            "✔️ Best model saved at epoch 37\n",
            "Epoch 38/80 - Train Loss: 0.1085 | Val Loss: 0.1254\n",
            "✔️ Best model saved at epoch 38\n",
            "Epoch 39/80 - Train Loss: 0.1145 | Val Loss: 0.1398\n",
            "Epoch 40/80 - Train Loss: 0.1195 | Val Loss: 0.1494\n",
            "Epoch 41/80 - Train Loss: 0.1039 | Val Loss: 0.1392\n",
            "Epoch 42/80 - Train Loss: 0.1091 | Val Loss: 0.1563\n",
            "Epoch 43/80 - Train Loss: 0.1119 | Val Loss: 0.1622\n",
            "Epoch 44/80 - Train Loss: 0.1137 | Val Loss: 0.1432\n",
            "Epoch 45/80 - Train Loss: 0.1005 | Val Loss: 0.1560\n",
            "Epoch 46/80 - Train Loss: 0.1112 | Val Loss: 0.1880\n",
            "Epoch 47/80 - Train Loss: 0.1047 | Val Loss: 0.1551\n",
            "Epoch 48/80 - Train Loss: 0.1115 | Val Loss: 0.1863\n",
            "Epoch 49/80 - Train Loss: 0.1036 | Val Loss: 0.1332\n",
            "Epoch 50/80 - Train Loss: 0.1047 | Val Loss: 0.1611\n",
            "Epoch 51/80 - Train Loss: 0.1121 | Val Loss: 0.1702\n",
            "Epoch 52/80 - Train Loss: 0.1081 | Val Loss: 0.1394\n",
            "Epoch 53/80 - Train Loss: 0.1025 | Val Loss: 0.1424\n",
            "Epoch 54/80 - Train Loss: 0.0993 | Val Loss: 0.1536\n",
            "Epoch 55/80 - Train Loss: 0.1076 | Val Loss: 0.1900\n",
            "Epoch 56/80 - Train Loss: 0.0976 | Val Loss: 0.1416\n",
            "Epoch 57/80 - Train Loss: 0.0956 | Val Loss: 0.1431\n",
            "Epoch 58/80 - Train Loss: 0.0838 | Val Loss: 0.1507\n",
            "⏹️ Early stopping.\n",
            "Evaluation Metrics:\n",
            "pixel_accuracy: 0.9836717191655585\n",
            "precision: [0.98943295 0.88848919 0.85373015 0.89449722]\n",
            "recall: [0.99328438 0.8715668  0.79588846 0.48074366]\n",
            "f1_score: [0.99135492 0.87994663 0.82379523 0.6253797 ]\n",
            "iou: [0.98285804 0.78562921 0.70038421 0.45494724]\n",
            "dice_score: [0.99135492 0.87994663 0.82379523 0.6253797 ]\n",
            "Total params: 4,136,820\n",
            "Model size: 15.78 MB\n"
          ]
        }
      ],
      "source": [
        "# from inside /content/project_root\n",
        "!python train.py \\\n",
        "  --model deeplabv3plus_mit_b0\\\n",
        "  --data-dir data \\\n",
        "  --output-dir /content/Finaldraft/outputs \\\n",
        "  --img-size 640 \\\n",
        "  --batch-size 8 \\\n",
        "  --epochs 80 \\\n",
        "  --lr 1e-4 \\\n",
        "  --patience 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGVqN8j2pQ3_",
        "outputId": "f63a8da3-f800-472d-a8be-9fe3b3c7a7a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:111: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "Epoch 1/80 - Train Loss: 0.9656 | Val Loss: 0.8348\n",
            "✔️ Best model saved at epoch 1\n",
            "Epoch 2/80 - Train Loss: 0.8515 | Val Loss: 0.6647\n",
            "✔️ Best model saved at epoch 2\n",
            "Epoch 3/80 - Train Loss: 0.7847 | Val Loss: 0.6270\n",
            "✔️ Best model saved at epoch 3\n",
            "Epoch 4/80 - Train Loss: 0.7715 | Val Loss: 0.7633\n",
            "Epoch 5/80 - Train Loss: 0.7598 | Val Loss: 0.6105\n",
            "✔️ Best model saved at epoch 5\n",
            "Epoch 6/80 - Train Loss: 0.7255 | Val Loss: 0.8915\n",
            "Epoch 7/80 - Train Loss: 0.7180 | Val Loss: 0.6193\n",
            "Epoch 8/80 - Train Loss: 0.6964 | Val Loss: 0.6632\n",
            "Epoch 9/80 - Train Loss: 0.6983 | Val Loss: 0.7533\n",
            "Epoch 10/80 - Train Loss: 0.6704 | Val Loss: 0.5708\n",
            "✔️ Best model saved at epoch 10\n",
            "Epoch 11/80 - Train Loss: 0.6608 | Val Loss: 1.1682\n",
            "Epoch 12/80 - Train Loss: 0.6536 | Val Loss: 0.4903\n",
            "✔️ Best model saved at epoch 12\n",
            "Epoch 13/80 - Train Loss: 0.6205 | Val Loss: 0.4821\n",
            "✔️ Best model saved at epoch 13\n",
            "Epoch 14/80 - Train Loss: 0.6309 | Val Loss: 0.5363\n",
            "Epoch 15/80 - Train Loss: 0.6344 | Val Loss: 0.5965\n",
            "Epoch 16/80 - Train Loss: 0.6056 | Val Loss: 0.6213\n",
            "Epoch 17/80 - Train Loss: 0.5814 | Val Loss: 0.5274\n",
            "Epoch 18/80 - Train Loss: 0.5923 | Val Loss: 0.4551\n",
            "✔️ Best model saved at epoch 18\n",
            "Epoch 19/80 - Train Loss: 0.5809 | Val Loss: 0.4551\n",
            "✔️ Best model saved at epoch 19\n",
            "Epoch 20/80 - Train Loss: 0.5783 | Val Loss: 0.4619\n",
            "Epoch 21/80 - Train Loss: 0.5884 | Val Loss: 0.4696\n",
            "Epoch 22/80 - Train Loss: 0.5750 | Val Loss: 0.4203\n",
            "✔️ Best model saved at epoch 22\n",
            "Epoch 23/80 - Train Loss: 0.5533 | Val Loss: 0.3855\n",
            "✔️ Best model saved at epoch 23\n",
            "Epoch 24/80 - Train Loss: 0.5484 | Val Loss: 0.4015\n",
            "Epoch 25/80 - Train Loss: 0.5457 | Val Loss: 0.4483\n",
            "Epoch 26/80 - Train Loss: 0.5451 | Val Loss: 0.3990\n",
            "Epoch 27/80 - Train Loss: 0.5247 | Val Loss: 0.4060\n",
            "Epoch 28/80 - Train Loss: 0.5327 | Val Loss: 0.4837\n",
            "Epoch 29/80 - Train Loss: 0.5187 | Val Loss: 0.3959\n",
            "Epoch 30/80 - Train Loss: 0.5003 | Val Loss: 0.4322\n",
            "Epoch 31/80 - Train Loss: 0.4819 | Val Loss: 0.3626\n",
            "✔️ Best model saved at epoch 31\n",
            "Epoch 32/80 - Train Loss: 0.5047 | Val Loss: 0.3858\n",
            "Epoch 33/80 - Train Loss: 0.4858 | Val Loss: 0.3451\n",
            "✔️ Best model saved at epoch 33\n",
            "Epoch 34/80 - Train Loss: 0.4859 | Val Loss: 0.4648\n",
            "Epoch 35/80 - Train Loss: 0.4741 | Val Loss: 0.3839\n",
            "Epoch 36/80 - Train Loss: 0.4905 | Val Loss: 0.3894\n",
            "Epoch 37/80 - Train Loss: 0.4762 | Val Loss: 0.3326\n",
            "✔️ Best model saved at epoch 37\n",
            "Epoch 38/80 - Train Loss: 0.4725 | Val Loss: 0.3345\n",
            "Epoch 39/80 - Train Loss: 0.4557 | Val Loss: 0.3517\n",
            "Epoch 40/80 - Train Loss: 0.4602 | Val Loss: 0.4607\n",
            "Epoch 41/80 - Train Loss: 0.4481 | Val Loss: 0.3134\n",
            "✔️ Best model saved at epoch 41\n",
            "Epoch 42/80 - Train Loss: 0.4450 | Val Loss: 0.3717\n",
            "Epoch 43/80 - Train Loss: 0.4324 | Val Loss: 0.3336\n",
            "Epoch 44/80 - Train Loss: 0.4145 | Val Loss: 0.3176\n",
            "Epoch 45/80 - Train Loss: 0.4144 | Val Loss: 0.3409\n",
            "Epoch 46/80 - Train Loss: 0.4110 | Val Loss: 0.3697\n",
            "Epoch 47/80 - Train Loss: 0.4329 | Val Loss: 0.3255\n",
            "Epoch 48/80 - Train Loss: 0.4242 | Val Loss: 0.3232\n",
            "Epoch 49/80 - Train Loss: 0.4228 | Val Loss: 0.3087\n",
            "✔️ Best model saved at epoch 49\n",
            "Epoch 50/80 - Train Loss: 0.3878 | Val Loss: 0.3289\n",
            "Epoch 51/80 - Train Loss: 0.3905 | Val Loss: 0.3295\n",
            "Epoch 52/80 - Train Loss: 0.3683 | Val Loss: 0.2955\n",
            "✔️ Best model saved at epoch 52\n",
            "Epoch 53/80 - Train Loss: 0.4028 | Val Loss: 0.2990\n",
            "Epoch 54/80 - Train Loss: 0.3641 | Val Loss: 0.3385\n",
            "Epoch 55/80 - Train Loss: 0.3885 | Val Loss: 0.2934\n",
            "✔️ Best model saved at epoch 55\n",
            "Epoch 56/80 - Train Loss: 0.3883 | Val Loss: 0.2764\n",
            "✔️ Best model saved at epoch 56\n",
            "Epoch 57/80 - Train Loss: 0.3973 | Val Loss: 0.2812\n",
            "Epoch 58/80 - Train Loss: 0.3830 | Val Loss: 0.3047\n",
            "Epoch 59/80 - Train Loss: 0.3586 | Val Loss: 0.2878\n",
            "Epoch 60/80 - Train Loss: 0.3472 | Val Loss: 0.2964\n",
            "Epoch 61/80 - Train Loss: 0.3484 | Val Loss: 0.2783\n",
            "Epoch 62/80 - Train Loss: 0.3659 | Val Loss: 0.3101\n",
            "Epoch 63/80 - Train Loss: 0.3701 | Val Loss: 0.2942\n",
            "Epoch 64/80 - Train Loss: 0.3535 | Val Loss: 0.2825\n",
            "Epoch 65/80 - Train Loss: 0.3491 | Val Loss: 0.2672\n",
            "✔️ Best model saved at epoch 65\n",
            "Epoch 66/80 - Train Loss: 0.3406 | Val Loss: 0.2614\n",
            "✔️ Best model saved at epoch 66\n",
            "Epoch 67/80 - Train Loss: 0.3202 | Val Loss: 0.2589\n",
            "✔️ Best model saved at epoch 67\n",
            "Epoch 68/80 - Train Loss: 0.3172 | Val Loss: 0.2621\n",
            "Epoch 69/80 - Train Loss: 0.3271 | Val Loss: 0.2559\n",
            "✔️ Best model saved at epoch 69\n",
            "Epoch 70/80 - Train Loss: 0.3366 | Val Loss: 0.2623\n",
            "Epoch 71/80 - Train Loss: 0.3132 | Val Loss: 0.2522\n",
            "✔️ Best model saved at epoch 71\n",
            "Epoch 72/80 - Train Loss: 0.3183 | Val Loss: 0.2690\n",
            "Epoch 73/80 - Train Loss: 0.3143 | Val Loss: 0.2634\n",
            "Epoch 74/80 - Train Loss: 0.3153 | Val Loss: 0.2633\n",
            "Epoch 75/80 - Train Loss: 0.3308 | Val Loss: 0.2479\n",
            "✔️ Best model saved at epoch 75\n",
            "Epoch 76/80 - Train Loss: 0.2987 | Val Loss: 0.2502\n",
            "Epoch 77/80 - Train Loss: 0.3211 | Val Loss: 0.2515\n",
            "Epoch 78/80 - Train Loss: 0.3179 | Val Loss: 0.2619\n",
            "Epoch 79/80 - Train Loss: 0.2938 | Val Loss: 0.2670\n",
            "Epoch 80/80 - Train Loss: 0.2934 | Val Loss: 0.2647\n",
            "Evaluation Metrics:\n",
            "pixel_accuracy: 0.9572174721575798\n",
            "precision: [0.98402625 0.58952599 0.63868113 0.7720478 ]\n",
            "recall: [0.97046257 0.78957316 0.68519976 0.41432131]\n",
            "f1_score: [0.97719734 0.67504051 0.66112315 0.53925182]\n",
            "iou: [0.95541143 0.50948012 0.49378937 0.36916139]\n",
            "dice_score: [0.97719734 0.67504051 0.66112315 0.53925182]\n",
            "Total params: 15,112,876\n",
            "Model size: 57.65 MB\n"
          ]
        }
      ],
      "source": [
        "# from inside /content/project_root\n",
        "!python train.py \\\n",
        "  --model unet_mobilenet \\\n",
        "  --data-dir data \\\n",
        "  --output-dir /content/Finaldraft/outputs \\\n",
        "  --img-size 640 \\\n",
        "  --batch-size 8 \\\n",
        "  --epochs 80 \\\n",
        "  --lr 1e-4 \\\n",
        "  --patience 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxTaOCBagorJ",
        "outputId": "877e193c-f022-493c-de70-856b0cb577a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:111: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "Epoch 1/80 - Train Loss: 0.9333 | Val Loss: 0.7016\n",
            "✔️ Best model saved at epoch 1\n",
            "Epoch 2/80 - Train Loss: 0.7674 | Val Loss: 0.6454\n",
            "✔️ Best model saved at epoch 2\n",
            "Epoch 3/80 - Train Loss: 0.7193 | Val Loss: 0.5804\n",
            "✔️ Best model saved at epoch 3\n",
            "Epoch 4/80 - Train Loss: 0.7113 | Val Loss: 0.6363\n",
            "Epoch 5/80 - Train Loss: 0.7039 | Val Loss: 0.5873\n",
            "Epoch 6/80 - Train Loss: 0.6946 | Val Loss: 0.6275\n",
            "Epoch 7/80 - Train Loss: 0.6847 | Val Loss: 0.5149\n",
            "✔️ Best model saved at epoch 7\n",
            "Epoch 8/80 - Train Loss: 0.6622 | Val Loss: 0.5050\n",
            "✔️ Best model saved at epoch 8\n",
            "Epoch 9/80 - Train Loss: 0.6606 | Val Loss: 0.5078\n",
            "Epoch 10/80 - Train Loss: 0.6464 | Val Loss: 0.5856\n",
            "Epoch 11/80 - Train Loss: 0.6432 | Val Loss: 0.5204\n",
            "Epoch 12/80 - Train Loss: 0.6341 | Val Loss: 0.5260\n",
            "Epoch 13/80 - Train Loss: 0.6273 | Val Loss: 0.4975\n",
            "✔️ Best model saved at epoch 13\n",
            "Epoch 14/80 - Train Loss: 0.5842 | Val Loss: 0.5042\n",
            "Epoch 15/80 - Train Loss: 0.5854 | Val Loss: 0.4357\n",
            "✔️ Best model saved at epoch 15\n",
            "Epoch 16/80 - Train Loss: 0.5966 | Val Loss: 0.5146\n",
            "Epoch 17/80 - Train Loss: 0.5901 | Val Loss: 0.4452\n",
            "Epoch 18/80 - Train Loss: 0.5776 | Val Loss: 0.5042\n",
            "Epoch 19/80 - Train Loss: 0.5678 | Val Loss: 0.5044\n",
            "Epoch 20/80 - Train Loss: 0.5842 | Val Loss: 0.4774\n",
            "Epoch 21/80 - Train Loss: 0.5708 | Val Loss: 0.4248\n",
            "✔️ Best model saved at epoch 21\n",
            "Epoch 22/80 - Train Loss: 0.5270 | Val Loss: 0.4469\n",
            "Epoch 23/80 - Train Loss: 0.5436 | Val Loss: 0.4110\n",
            "✔️ Best model saved at epoch 23\n",
            "Epoch 24/80 - Train Loss: 0.5097 | Val Loss: 0.3871\n",
            "✔️ Best model saved at epoch 24\n",
            "Epoch 25/80 - Train Loss: 0.5108 | Val Loss: 0.4050\n",
            "Epoch 26/80 - Train Loss: 0.4945 | Val Loss: 0.4771\n",
            "Epoch 27/80 - Train Loss: 0.4875 | Val Loss: 0.3859\n",
            "✔️ Best model saved at epoch 27\n",
            "Epoch 28/80 - Train Loss: 0.4931 | Val Loss: 0.4203\n",
            "Epoch 29/80 - Train Loss: 0.4745 | Val Loss: 0.4340\n",
            "Epoch 30/80 - Train Loss: 0.4399 | Val Loss: 0.3524\n",
            "✔️ Best model saved at epoch 30\n",
            "Epoch 31/80 - Train Loss: 0.4289 | Val Loss: 0.5761\n",
            "Epoch 32/80 - Train Loss: 0.4738 | Val Loss: 0.3959\n",
            "Epoch 33/80 - Train Loss: 0.4388 | Val Loss: 0.4119\n",
            "Epoch 34/80 - Train Loss: 0.4762 | Val Loss: 0.3922\n",
            "Epoch 35/80 - Train Loss: 0.4295 | Val Loss: 0.3554\n",
            "Epoch 36/80 - Train Loss: 0.4278 | Val Loss: 0.4264\n",
            "Epoch 37/80 - Train Loss: 0.4197 | Val Loss: 0.3442\n",
            "✔️ Best model saved at epoch 37\n",
            "Epoch 38/80 - Train Loss: 0.4055 | Val Loss: 0.3101\n",
            "✔️ Best model saved at epoch 38\n",
            "Epoch 39/80 - Train Loss: 0.4002 | Val Loss: 0.3355\n",
            "Epoch 40/80 - Train Loss: 0.4013 | Val Loss: 0.3753\n",
            "Epoch 41/80 - Train Loss: 0.3973 | Val Loss: 0.3755\n",
            "Epoch 42/80 - Train Loss: 0.3694 | Val Loss: 0.2959\n",
            "✔️ Best model saved at epoch 42\n",
            "Epoch 43/80 - Train Loss: 0.3781 | Val Loss: 0.3694\n",
            "Epoch 44/80 - Train Loss: 0.3919 | Val Loss: 0.3467\n",
            "Epoch 45/80 - Train Loss: 0.3884 | Val Loss: 0.2869\n",
            "✔️ Best model saved at epoch 45\n",
            "Epoch 46/80 - Train Loss: 0.3495 | Val Loss: 0.3015\n",
            "Epoch 47/80 - Train Loss: 0.3641 | Val Loss: 0.3848\n",
            "Epoch 48/80 - Train Loss: 0.3536 | Val Loss: 0.3162\n",
            "Epoch 49/80 - Train Loss: 0.3705 | Val Loss: 0.3449\n",
            "Epoch 50/80 - Train Loss: 0.3446 | Val Loss: 0.2837\n",
            "✔️ Best model saved at epoch 50\n",
            "Epoch 51/80 - Train Loss: 0.3563 | Val Loss: 0.2824\n",
            "✔️ Best model saved at epoch 51\n",
            "Epoch 52/80 - Train Loss: 0.3262 | Val Loss: 0.3097\n",
            "Epoch 53/80 - Train Loss: 0.3120 | Val Loss: 0.3215\n",
            "Epoch 54/80 - Train Loss: 0.3146 | Val Loss: 0.3613\n",
            "Epoch 55/80 - Train Loss: 0.3360 | Val Loss: 0.3372\n",
            "Epoch 56/80 - Train Loss: 0.3282 | Val Loss: 0.3150\n",
            "Epoch 57/80 - Train Loss: 0.2889 | Val Loss: 0.2638\n",
            "✔️ Best model saved at epoch 57\n",
            "Epoch 58/80 - Train Loss: 0.3103 | Val Loss: 0.3318\n",
            "Epoch 59/80 - Train Loss: 0.3244 | Val Loss: 0.2693\n",
            "Epoch 60/80 - Train Loss: 0.3220 | Val Loss: 0.2847\n",
            "Epoch 61/80 - Train Loss: 0.3110 | Val Loss: 0.2967\n",
            "Epoch 62/80 - Train Loss: 0.2997 | Val Loss: 0.2716\n",
            "Epoch 63/80 - Train Loss: 0.2919 | Val Loss: 0.3198\n",
            "Epoch 64/80 - Train Loss: 0.3031 | Val Loss: 0.3104\n",
            "Epoch 65/80 - Train Loss: 0.2872 | Val Loss: 0.2924\n",
            "Epoch 66/80 - Train Loss: 0.3071 | Val Loss: 0.2994\n",
            "Epoch 67/80 - Train Loss: 0.3160 | Val Loss: 0.3745\n",
            "Epoch 68/80 - Train Loss: 0.3122 | Val Loss: 0.3646\n",
            "Epoch 69/80 - Train Loss: 0.3045 | Val Loss: 0.2894\n",
            "Epoch 70/80 - Train Loss: 0.2896 | Val Loss: 0.2663\n",
            "Epoch 71/80 - Train Loss: 0.2693 | Val Loss: 0.2929\n",
            "Epoch 72/80 - Train Loss: 0.2638 | Val Loss: 0.2698\n",
            "Epoch 73/80 - Train Loss: 0.2826 | Val Loss: 0.2966\n",
            "Epoch 74/80 - Train Loss: 0.2763 | Val Loss: 0.3878\n",
            "Epoch 75/80 - Train Loss: 0.2771 | Val Loss: 0.3157\n",
            "Epoch 76/80 - Train Loss: 0.2956 | Val Loss: 0.2914\n",
            "Epoch 77/80 - Train Loss: 0.2557 | Val Loss: 0.2729\n",
            "⏹️ Early stopping.\n",
            "Evaluation Metrics:\n",
            "pixel_accuracy: 0.9425084670046543\n",
            "precision: [0.98920466 0.45515413 0.84418892 0.76986734]\n",
            "recall: [0.95013163 0.90555564 0.67269091 0.34300526]\n",
            "f1_score: [0.96927452 0.60581234 0.74874515 0.47457103]\n",
            "iou: [0.94038088 0.43452712 0.59839541 0.31110661]\n",
            "dice_score: [0.96927452 0.60581234 0.74874515 0.47457103]\n",
            "Total params: 13,043,204\n",
            "Model size: 49.76 MB\n"
          ]
        }
      ],
      "source": [
        "# from inside /content/project_root\n",
        "!python train.py \\\n",
        "  --model resunet \\\n",
        "  --data-dir data \\\n",
        "  --output-dir /content/Finaldraft/outputs \\\n",
        "  --img-size 640 \\\n",
        "  --batch-size 8 \\\n",
        "  --epochs 80 \\\n",
        "  --lr 1e-4 \\\n",
        "  --patience 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxbudqkogzlC",
        "outputId": "b42b494f-8313-4771-e315-33e0adf81099"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:111: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "Epoch 1/80 - Train Loss: 0.9749 | Val Loss: 0.8763\n",
            "✔️ Best model saved at epoch 1\n",
            "Epoch 2/80 - Train Loss: 0.8842 | Val Loss: 0.7263\n",
            "✔️ Best model saved at epoch 2\n",
            "Epoch 3/80 - Train Loss: 0.8617 | Val Loss: 0.7648\n",
            "Epoch 4/80 - Train Loss: 0.8046 | Val Loss: 0.6602\n",
            "✔️ Best model saved at epoch 4\n",
            "Epoch 5/80 - Train Loss: 0.7873 | Val Loss: 0.6510\n",
            "✔️ Best model saved at epoch 5\n",
            "Epoch 6/80 - Train Loss: 0.7684 | Val Loss: 0.7562\n",
            "Epoch 7/80 - Train Loss: 0.7346 | Val Loss: 0.6094\n",
            "✔️ Best model saved at epoch 7\n",
            "Epoch 8/80 - Train Loss: 0.7200 | Val Loss: 0.5474\n",
            "✔️ Best model saved at epoch 8\n",
            "Epoch 9/80 - Train Loss: 0.6922 | Val Loss: 0.5580\n",
            "Epoch 10/80 - Train Loss: 0.6658 | Val Loss: 0.5603\n",
            "Epoch 11/80 - Train Loss: 0.6422 | Val Loss: 0.5219\n",
            "✔️ Best model saved at epoch 11\n",
            "Epoch 12/80 - Train Loss: 0.6418 | Val Loss: 0.5231\n",
            "Epoch 13/80 - Train Loss: 0.6310 | Val Loss: 0.4937\n",
            "✔️ Best model saved at epoch 13\n",
            "Epoch 14/80 - Train Loss: 0.6070 | Val Loss: 0.4580\n",
            "✔️ Best model saved at epoch 14\n",
            "Epoch 15/80 - Train Loss: 0.6031 | Val Loss: 0.4838\n",
            "Epoch 16/80 - Train Loss: 0.5825 | Val Loss: 0.4475\n",
            "✔️ Best model saved at epoch 16\n",
            "Epoch 17/80 - Train Loss: 0.5811 | Val Loss: 0.4579\n",
            "Epoch 18/80 - Train Loss: 0.5522 | Val Loss: 0.4285\n",
            "✔️ Best model saved at epoch 18\n",
            "Epoch 19/80 - Train Loss: 0.5457 | Val Loss: 0.4673\n",
            "Epoch 20/80 - Train Loss: 0.5411 | Val Loss: 0.4852\n",
            "Epoch 21/80 - Train Loss: 0.5392 | Val Loss: 0.3984\n",
            "✔️ Best model saved at epoch 21\n",
            "Epoch 22/80 - Train Loss: 0.5121 | Val Loss: 0.3971\n",
            "✔️ Best model saved at epoch 22\n",
            "Epoch 23/80 - Train Loss: 0.5041 | Val Loss: 0.4185\n",
            "Epoch 24/80 - Train Loss: 0.5185 | Val Loss: 0.3765\n",
            "✔️ Best model saved at epoch 24\n",
            "Epoch 25/80 - Train Loss: 0.4928 | Val Loss: 0.3734\n",
            "✔️ Best model saved at epoch 25\n",
            "Epoch 26/80 - Train Loss: 0.5042 | Val Loss: 0.4585\n",
            "Epoch 27/80 - Train Loss: 0.4939 | Val Loss: 0.3884\n",
            "Epoch 28/80 - Train Loss: 0.4563 | Val Loss: 0.3377\n",
            "✔️ Best model saved at epoch 28\n",
            "Epoch 29/80 - Train Loss: 0.4629 | Val Loss: 0.3419\n",
            "Epoch 30/80 - Train Loss: 0.4345 | Val Loss: 0.3207\n",
            "✔️ Best model saved at epoch 30\n",
            "Epoch 31/80 - Train Loss: 0.4616 | Val Loss: 0.3528\n",
            "Epoch 32/80 - Train Loss: 0.4292 | Val Loss: 0.3212\n",
            "Epoch 33/80 - Train Loss: 0.4167 | Val Loss: 0.3368\n",
            "Epoch 34/80 - Train Loss: 0.4189 | Val Loss: 0.3093\n",
            "✔️ Best model saved at epoch 34\n",
            "Epoch 35/80 - Train Loss: 0.4221 | Val Loss: 0.3147\n",
            "Epoch 36/80 - Train Loss: 0.3782 | Val Loss: 0.2927\n",
            "✔️ Best model saved at epoch 36\n",
            "Epoch 37/80 - Train Loss: 0.3981 | Val Loss: 0.3213\n",
            "Epoch 38/80 - Train Loss: 0.3824 | Val Loss: 0.5416\n",
            "Epoch 39/80 - Train Loss: 0.3831 | Val Loss: 0.2714\n",
            "✔️ Best model saved at epoch 39\n",
            "Epoch 40/80 - Train Loss: 0.3457 | Val Loss: 0.2967\n",
            "Epoch 41/80 - Train Loss: 0.3873 | Val Loss: 0.2735\n",
            "Epoch 42/80 - Train Loss: 0.3571 | Val Loss: 0.2706\n",
            "✔️ Best model saved at epoch 42\n",
            "Epoch 43/80 - Train Loss: 0.3445 | Val Loss: 0.2543\n",
            "✔️ Best model saved at epoch 43\n",
            "Epoch 44/80 - Train Loss: 0.3328 | Val Loss: 0.2370\n",
            "✔️ Best model saved at epoch 44\n",
            "Epoch 45/80 - Train Loss: 0.3364 | Val Loss: 0.2457\n",
            "Epoch 46/80 - Train Loss: 0.3171 | Val Loss: 0.2463\n",
            "Epoch 47/80 - Train Loss: 0.3291 | Val Loss: 0.2315\n",
            "✔️ Best model saved at epoch 47\n",
            "Epoch 48/80 - Train Loss: 0.3332 | Val Loss: 0.2966\n",
            "Epoch 49/80 - Train Loss: 0.3441 | Val Loss: 0.2294\n",
            "✔️ Best model saved at epoch 49\n",
            "Epoch 50/80 - Train Loss: 0.3200 | Val Loss: 0.2388\n",
            "Epoch 51/80 - Train Loss: 0.3135 | Val Loss: 0.2185\n",
            "✔️ Best model saved at epoch 51\n",
            "Epoch 52/80 - Train Loss: 0.3078 | Val Loss: 0.2416\n",
            "Epoch 53/80 - Train Loss: 0.3049 | Val Loss: 0.2156\n",
            "✔️ Best model saved at epoch 53\n",
            "Epoch 54/80 - Train Loss: 0.2842 | Val Loss: 0.2201\n",
            "Epoch 55/80 - Train Loss: 0.2876 | Val Loss: 0.2346\n",
            "Epoch 56/80 - Train Loss: 0.2886 | Val Loss: 0.2102\n",
            "✔️ Best model saved at epoch 56\n",
            "Epoch 57/80 - Train Loss: 0.2736 | Val Loss: 0.2453\n",
            "Epoch 58/80 - Train Loss: 0.2644 | Val Loss: 0.2079\n",
            "✔️ Best model saved at epoch 58\n",
            "Epoch 59/80 - Train Loss: 0.2758 | Val Loss: 0.1956\n",
            "✔️ Best model saved at epoch 59\n",
            "Epoch 60/80 - Train Loss: 0.2825 | Val Loss: 0.2075\n",
            "Epoch 61/80 - Train Loss: 0.2742 | Val Loss: 0.2211\n",
            "Epoch 62/80 - Train Loss: 0.3036 | Val Loss: 0.2411\n",
            "Epoch 63/80 - Train Loss: 0.2744 | Val Loss: 0.1919\n",
            "✔️ Best model saved at epoch 63\n",
            "Epoch 64/80 - Train Loss: 0.2761 | Val Loss: 0.1897\n",
            "✔️ Best model saved at epoch 64\n",
            "Epoch 65/80 - Train Loss: 0.2483 | Val Loss: 0.1890\n",
            "✔️ Best model saved at epoch 65\n",
            "Epoch 66/80 - Train Loss: 0.2405 | Val Loss: 0.1937\n",
            "Epoch 67/80 - Train Loss: 0.2548 | Val Loss: 0.1952\n",
            "Epoch 68/80 - Train Loss: 0.2199 | Val Loss: 0.1944\n",
            "Epoch 69/80 - Train Loss: 0.2319 | Val Loss: 0.2052\n",
            "Epoch 70/80 - Train Loss: 0.2249 | Val Loss: 0.1800\n",
            "✔️ Best model saved at epoch 70\n",
            "Epoch 71/80 - Train Loss: 0.2384 | Val Loss: 0.1836\n",
            "Epoch 72/80 - Train Loss: 0.2388 | Val Loss: 0.2105\n",
            "Epoch 73/80 - Train Loss: 0.2502 | Val Loss: 0.2065\n",
            "Epoch 74/80 - Train Loss: 0.2341 | Val Loss: 0.1975\n",
            "Epoch 75/80 - Train Loss: 0.2391 | Val Loss: 0.1744\n",
            "✔️ Best model saved at epoch 75\n",
            "Epoch 76/80 - Train Loss: 0.2450 | Val Loss: 0.2292\n",
            "Epoch 77/80 - Train Loss: 0.2498 | Val Loss: 0.1718\n",
            "✔️ Best model saved at epoch 77\n",
            "Epoch 78/80 - Train Loss: 0.2135 | Val Loss: 0.2346\n",
            "Epoch 79/80 - Train Loss: 0.1963 | Val Loss: 0.1952\n",
            "Epoch 80/80 - Train Loss: 0.1910 | Val Loss: 0.2028\n",
            "Evaluation Metrics:\n",
            "pixel_accuracy: 0.9766705971575798\n",
            "precision: [0.98816252 0.76773695 0.92656781 0.87791499]\n",
            "recall: [0.98707114 0.88822047 0.6653252  0.37729462]\n",
            "f1_score: [0.98761652 0.82359566 0.77451048 0.52777256]\n",
            "iou: [0.975536   0.70009574 0.6320009  0.35848576]\n",
            "dice_score: [0.98761652 0.82359566 0.77451048 0.52777256]\n",
            "Total params: 9,163,428\n",
            "Model size: 34.96 MB\n"
          ]
        }
      ],
      "source": [
        "# from inside /content/project_root\n",
        "!python train.py \\\n",
        "  --model unetpp \\\n",
        "  --data-dir data \\\n",
        "  --output-dir /content/Finaldraft/outputs \\\n",
        "  --img-size 640 \\\n",
        "  --batch-size 8 \\\n",
        "  --epochs 80 \\\n",
        "  --lr 1e-4 \\\n",
        "  --patience 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jk4c3J0Fg4Wf",
        "outputId": "800fea4e-1f16-4c23-8f9d-56a93e821075"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:111: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "Epoch 1/120 - Train Loss: 0.8474 | Val Loss: 0.7683\n",
            "✔️ Best model saved at epoch 1\n",
            "Epoch 2/120 - Train Loss: 0.7805 | Val Loss: 0.7133\n",
            "✔️ Best model saved at epoch 2\n",
            "Epoch 3/120 - Train Loss: 0.7706 | Val Loss: 0.7064\n",
            "✔️ Best model saved at epoch 3\n",
            "Epoch 4/120 - Train Loss: 0.7520 | Val Loss: 0.6840\n",
            "✔️ Best model saved at epoch 4\n",
            "Epoch 5/120 - Train Loss: 0.7320 | Val Loss: 0.6690\n",
            "✔️ Best model saved at epoch 5\n",
            "Epoch 6/120 - Train Loss: 0.7229 | Val Loss: 0.7124\n",
            "Epoch 7/120 - Train Loss: 0.7194 | Val Loss: 0.6504\n",
            "✔️ Best model saved at epoch 7\n",
            "Epoch 8/120 - Train Loss: 0.7065 | Val Loss: 0.6414\n",
            "✔️ Best model saved at epoch 8\n",
            "Epoch 9/120 - Train Loss: 0.7063 | Val Loss: 0.6730\n",
            "Epoch 10/120 - Train Loss: 0.6987 | Val Loss: 0.6370\n",
            "✔️ Best model saved at epoch 10\n",
            "Epoch 11/120 - Train Loss: 0.6922 | Val Loss: 0.6303\n",
            "✔️ Best model saved at epoch 11\n",
            "Epoch 12/120 - Train Loss: 0.6876 | Val Loss: 0.6251\n",
            "✔️ Best model saved at epoch 12\n",
            "Epoch 13/120 - Train Loss: 0.6864 | Val Loss: 0.6438\n",
            "Epoch 14/120 - Train Loss: 0.6811 | Val Loss: 0.6246\n",
            "✔️ Best model saved at epoch 14\n",
            "Epoch 15/120 - Train Loss: 0.6756 | Val Loss: 0.6238\n",
            "✔️ Best model saved at epoch 15\n",
            "Epoch 16/120 - Train Loss: 0.6747 | Val Loss: 0.6189\n",
            "✔️ Best model saved at epoch 16\n",
            "Epoch 17/120 - Train Loss: 0.6727 | Val Loss: 0.6283\n",
            "Epoch 18/120 - Train Loss: 0.6726 | Val Loss: 0.6215\n",
            "Epoch 19/120 - Train Loss: 0.6792 | Val Loss: 0.6388\n",
            "Epoch 20/120 - Train Loss: 0.6744 | Val Loss: 0.6209\n",
            "Epoch 21/120 - Train Loss: 0.6687 | Val Loss: 0.6143\n",
            "✔️ Best model saved at epoch 21\n",
            "Epoch 22/120 - Train Loss: 0.6619 | Val Loss: 0.6172\n",
            "Epoch 23/120 - Train Loss: 0.6672 | Val Loss: 0.6176\n",
            "Epoch 24/120 - Train Loss: 0.6663 | Val Loss: 0.6156\n",
            "Epoch 25/120 - Train Loss: 0.6747 | Val Loss: 0.6144\n",
            "Epoch 26/120 - Train Loss: 0.6589 | Val Loss: 0.6119\n",
            "✔️ Best model saved at epoch 26\n",
            "Epoch 27/120 - Train Loss: 0.6559 | Val Loss: 0.6334\n",
            "Epoch 28/120 - Train Loss: 0.6601 | Val Loss: 0.6209\n",
            "Epoch 29/120 - Train Loss: 0.6566 | Val Loss: 0.6198\n",
            "Epoch 30/120 - Train Loss: 0.6739 | Val Loss: 0.6131\n",
            "Epoch 31/120 - Train Loss: 0.6583 | Val Loss: 0.6080\n",
            "✔️ Best model saved at epoch 31\n",
            "Epoch 32/120 - Train Loss: 0.6548 | Val Loss: 0.6317\n",
            "Epoch 33/120 - Train Loss: 0.6632 | Val Loss: 0.6088\n",
            "Epoch 34/120 - Train Loss: 0.6567 | Val Loss: 0.6079\n",
            "✔️ Best model saved at epoch 34\n",
            "Epoch 35/120 - Train Loss: 0.6549 | Val Loss: 0.6074\n",
            "✔️ Best model saved at epoch 35\n",
            "Epoch 36/120 - Train Loss: 0.6482 | Val Loss: 0.6104\n",
            "Epoch 37/120 - Train Loss: 0.6510 | Val Loss: 0.6161\n",
            "Epoch 38/120 - Train Loss: 0.6477 | Val Loss: 0.6067\n",
            "✔️ Best model saved at epoch 38\n",
            "Epoch 39/120 - Train Loss: 0.6534 | Val Loss: 0.6137\n",
            "Epoch 40/120 - Train Loss: 0.6493 | Val Loss: 0.6159\n",
            "Epoch 41/120 - Train Loss: 0.6511 | Val Loss: 0.6110\n",
            "Epoch 42/120 - Train Loss: 0.6552 | Val Loss: 0.6065\n",
            "✔️ Best model saved at epoch 42\n",
            "Epoch 43/120 - Train Loss: 0.6567 | Val Loss: 0.6117\n",
            "Epoch 44/120 - Train Loss: 0.6385 | Val Loss: 0.6054\n",
            "✔️ Best model saved at epoch 44\n",
            "Epoch 45/120 - Train Loss: 0.6474 | Val Loss: 0.6078\n",
            "Epoch 46/120 - Train Loss: 0.6550 | Val Loss: 0.6070\n",
            "Epoch 47/120 - Train Loss: 0.6521 | Val Loss: 0.6114\n",
            "Epoch 48/120 - Train Loss: 0.6445 | Val Loss: 0.6049\n",
            "✔️ Best model saved at epoch 48\n",
            "Epoch 49/120 - Train Loss: 0.6541 | Val Loss: 0.6135\n",
            "Epoch 50/120 - Train Loss: 0.6466 | Val Loss: 0.6011\n",
            "✔️ Best model saved at epoch 50\n",
            "Epoch 51/120 - Train Loss: 0.6478 | Val Loss: 0.6038\n",
            "Epoch 52/120 - Train Loss: 0.6534 | Val Loss: 0.6080\n",
            "Epoch 53/120 - Train Loss: 0.6490 | Val Loss: 0.6081\n",
            "Epoch 54/120 - Train Loss: 0.6533 | Val Loss: 0.6055\n",
            "Epoch 55/120 - Train Loss: 0.6432 | Val Loss: 0.6247\n",
            "Epoch 56/120 - Train Loss: 0.6453 | Val Loss: 0.6041\n",
            "Epoch 57/120 - Train Loss: 0.6481 | Val Loss: 0.6062\n",
            "Epoch 58/120 - Train Loss: 0.6431 | Val Loss: 0.6036\n",
            "Epoch 59/120 - Train Loss: 0.6509 | Val Loss: 0.6144\n",
            "Epoch 60/120 - Train Loss: 0.6446 | Val Loss: 0.6116\n",
            "Epoch 61/120 - Train Loss: 0.6462 | Val Loss: 0.6061\n",
            "Epoch 62/120 - Train Loss: 0.6404 | Val Loss: 0.6046\n",
            "Epoch 63/120 - Train Loss: 0.6447 | Val Loss: 0.6105\n",
            "Epoch 64/120 - Train Loss: 0.6519 | Val Loss: 0.6047\n",
            "Epoch 65/120 - Train Loss: 0.6503 | Val Loss: 0.6267\n",
            "⏹️ Early stopping.\n",
            "Evaluation Metrics:\n",
            "pixel_accuracy: 0.9035573366855053\n",
            "precision: [0.9951228  0.32316844 0.60670146 0.70277639]\n",
            "recall: [0.90261628 0.96016822 0.80504611 0.80064355]\n",
            "f1_score: [0.94661489 0.48357702 0.69194048 0.74852457]\n",
            "iou: [0.89864086 0.31889324 0.52898242 0.59811368]\n",
            "dice_score: [0.94661489 0.48357702 0.69194048 0.74852457]\n",
            "Total params: 26,963,652\n",
            "Model size: 102.86 MB\n"
          ]
        }
      ],
      "source": [
        "# from inside /content/project_root\n",
        "!python train.py \\\n",
        "  --model unet3plus \\\n",
        "  --data-dir data \\\n",
        "  --output-dir /content/Finaldraft/outputs \\\n",
        "  --img-size 640 \\\n",
        "  --batch-size 2 \\\n",
        "  --epochs 120 \\\n",
        "  --lr 1e-4 \\\n",
        "  --patience 15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "MF_mdL6avm_R",
        "outputId": "0a2f6597-449c-4b1c-ba0b-244fa275beee"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/Finaldraft/outputs/unet3plus.zip'"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import shutil\n",
        "shutil.make_archive('/content/Finaldraft/outputs/unet3plus', 'zip', '/content/Finaldraft/outputs/unet3plus')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "leqUjzQoawiL",
        "outputId": "1269ea38-49ca-47fd-e0b0-9c62c47e2592"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_cbdce04d-71d5-4897-a568-282b787747b6\", \"unet3plus.zip\", 103533043)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download('/content/Finaldraft/outputs/unet3plus.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7MtDaYNa0HE",
        "outputId": "f03329b7-18fb-4de6-a711-e927446e673d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:111: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "Epoch 1/80 - Train Loss: 0.9837 | Val Loss: 0.8684\n",
            "✔️ Best model saved at epoch 1\n",
            "Epoch 2/80 - Train Loss: 0.8445 | Val Loss: 0.7084\n",
            "✔️ Best model saved at epoch 2\n",
            "Epoch 3/80 - Train Loss: 0.7886 | Val Loss: 0.6323\n",
            "✔️ Best model saved at epoch 3\n",
            "Epoch 4/80 - Train Loss: 0.7221 | Val Loss: 0.5358\n",
            "✔️ Best model saved at epoch 4\n",
            "Epoch 5/80 - Train Loss: 0.6696 | Val Loss: 0.5148\n",
            "✔️ Best model saved at epoch 5\n",
            "Epoch 6/80 - Train Loss: 0.6834 | Val Loss: 0.5260\n",
            "Epoch 7/80 - Train Loss: 0.6482 | Val Loss: 0.4844\n",
            "✔️ Best model saved at epoch 7\n",
            "Epoch 8/80 - Train Loss: 0.6182 | Val Loss: 0.4297\n",
            "✔️ Best model saved at epoch 8\n",
            "Epoch 9/80 - Train Loss: 0.5948 | Val Loss: 0.4570\n",
            "Epoch 10/80 - Train Loss: 0.5620 | Val Loss: 0.4088\n",
            "✔️ Best model saved at epoch 10\n",
            "Epoch 11/80 - Train Loss: 0.5816 | Val Loss: 0.4781\n",
            "Epoch 12/80 - Train Loss: 0.5490 | Val Loss: 0.4156\n",
            "Epoch 13/80 - Train Loss: 0.5397 | Val Loss: 0.3792\n",
            "✔️ Best model saved at epoch 13\n",
            "Epoch 14/80 - Train Loss: 0.5173 | Val Loss: 0.3723\n",
            "✔️ Best model saved at epoch 14\n",
            "Epoch 15/80 - Train Loss: 0.5117 | Val Loss: 0.3650\n",
            "✔️ Best model saved at epoch 15\n",
            "Epoch 16/80 - Train Loss: 0.4879 | Val Loss: 0.3717\n",
            "Epoch 17/80 - Train Loss: 0.4866 | Val Loss: 0.3482\n",
            "✔️ Best model saved at epoch 17\n",
            "Epoch 18/80 - Train Loss: 0.4787 | Val Loss: 0.3410\n",
            "✔️ Best model saved at epoch 18\n",
            "Epoch 19/80 - Train Loss: 0.4584 | Val Loss: 0.3504\n",
            "Epoch 20/80 - Train Loss: 0.4691 | Val Loss: 0.3256\n",
            "✔️ Best model saved at epoch 20\n",
            "Epoch 21/80 - Train Loss: 0.4375 | Val Loss: 0.3274\n",
            "Epoch 22/80 - Train Loss: 0.4402 | Val Loss: 0.3356\n",
            "Epoch 23/80 - Train Loss: 0.4305 | Val Loss: 0.3098\n",
            "✔️ Best model saved at epoch 23\n",
            "Epoch 24/80 - Train Loss: 0.4267 | Val Loss: 0.2970\n",
            "✔️ Best model saved at epoch 24\n",
            "Epoch 25/80 - Train Loss: 0.4109 | Val Loss: 0.2943\n",
            "✔️ Best model saved at epoch 25\n",
            "Epoch 26/80 - Train Loss: 0.3856 | Val Loss: 0.3267\n",
            "Epoch 27/80 - Train Loss: 0.4237 | Val Loss: 0.3089\n",
            "Epoch 28/80 - Train Loss: 0.3885 | Val Loss: 0.3173\n",
            "Epoch 29/80 - Train Loss: 0.3797 | Val Loss: 0.2702\n",
            "✔️ Best model saved at epoch 29\n",
            "Epoch 30/80 - Train Loss: 0.3752 | Val Loss: 0.2879\n",
            "Epoch 31/80 - Train Loss: 0.3670 | Val Loss: 0.3200\n",
            "Epoch 32/80 - Train Loss: 0.3403 | Val Loss: 0.2541\n",
            "✔️ Best model saved at epoch 32\n",
            "Epoch 33/80 - Train Loss: 0.3412 | Val Loss: 0.2649\n",
            "Epoch 34/80 - Train Loss: 0.3559 | Val Loss: 0.2938\n",
            "Epoch 35/80 - Train Loss: 0.3407 | Val Loss: 0.2616\n",
            "Epoch 36/80 - Train Loss: 0.3225 | Val Loss: 0.2428\n",
            "✔️ Best model saved at epoch 36\n",
            "Epoch 37/80 - Train Loss: 0.3142 | Val Loss: 0.2673\n",
            "Epoch 38/80 - Train Loss: 0.3067 | Val Loss: 0.2619\n",
            "Epoch 39/80 - Train Loss: 0.2956 | Val Loss: 0.2545\n",
            "Epoch 40/80 - Train Loss: 0.3165 | Val Loss: 0.2585\n",
            "Epoch 41/80 - Train Loss: 0.3339 | Val Loss: 0.2517\n",
            "Epoch 42/80 - Train Loss: 0.2864 | Val Loss: 0.2463\n",
            "Epoch 43/80 - Train Loss: 0.2710 | Val Loss: 0.2407\n",
            "✔️ Best model saved at epoch 43\n",
            "Epoch 44/80 - Train Loss: 0.2731 | Val Loss: 0.2446\n",
            "Epoch 45/80 - Train Loss: 0.2840 | Val Loss: 0.2672\n",
            "Epoch 46/80 - Train Loss: 0.2785 | Val Loss: 0.2693\n",
            "Epoch 47/80 - Train Loss: 0.2591 | Val Loss: 0.2369\n",
            "✔️ Best model saved at epoch 47\n",
            "Epoch 48/80 - Train Loss: 0.2594 | Val Loss: 0.2338\n",
            "✔️ Best model saved at epoch 48\n",
            "Epoch 49/80 - Train Loss: 0.2616 | Val Loss: 0.3135\n",
            "Epoch 50/80 - Train Loss: 0.2502 | Val Loss: 0.2588\n",
            "Epoch 51/80 - Train Loss: 0.2801 | Val Loss: 0.2445\n",
            "Epoch 52/80 - Train Loss: 0.2632 | Val Loss: 0.2177\n",
            "✔️ Best model saved at epoch 52\n",
            "Epoch 53/80 - Train Loss: 0.2363 | Val Loss: 0.2389\n",
            "Epoch 54/80 - Train Loss: 0.2377 | Val Loss: 0.2413\n",
            "Epoch 55/80 - Train Loss: 0.2617 | Val Loss: 0.2441\n",
            "Epoch 56/80 - Train Loss: 0.2290 | Val Loss: 0.2450\n",
            "Epoch 57/80 - Train Loss: 0.2176 | Val Loss: 0.2102\n",
            "✔️ Best model saved at epoch 57\n",
            "Epoch 58/80 - Train Loss: 0.2114 | Val Loss: 0.2151\n",
            "Epoch 59/80 - Train Loss: 0.2399 | Val Loss: 0.2570\n",
            "Epoch 60/80 - Train Loss: 0.2190 | Val Loss: 0.2406\n",
            "Epoch 61/80 - Train Loss: 0.2167 | Val Loss: 0.2562\n",
            "Epoch 62/80 - Train Loss: 0.2152 | Val Loss: 0.2585\n",
            "Epoch 63/80 - Train Loss: 0.2155 | Val Loss: 0.2444\n",
            "Epoch 64/80 - Train Loss: 0.2101 | Val Loss: 0.2400\n",
            "Epoch 65/80 - Train Loss: 0.1944 | Val Loss: 0.2159\n",
            "Epoch 66/80 - Train Loss: 0.2165 | Val Loss: 0.2076\n",
            "✔️ Best model saved at epoch 66\n",
            "Epoch 67/80 - Train Loss: 0.1983 | Val Loss: 0.2462\n",
            "Epoch 68/80 - Train Loss: 0.1965 | Val Loss: 0.2581\n",
            "Epoch 69/80 - Train Loss: 0.2001 | Val Loss: 0.2272\n",
            "Epoch 70/80 - Train Loss: 0.1996 | Val Loss: 0.2460\n",
            "Epoch 71/80 - Train Loss: 0.1908 | Val Loss: 0.2279\n",
            "Epoch 72/80 - Train Loss: 0.1874 | Val Loss: 0.1965\n",
            "✔️ Best model saved at epoch 72\n",
            "Epoch 73/80 - Train Loss: 0.1884 | Val Loss: 0.2449\n",
            "Epoch 74/80 - Train Loss: 0.2019 | Val Loss: 0.2367\n",
            "Epoch 75/80 - Train Loss: 0.2050 | Val Loss: 0.1975\n",
            "Epoch 76/80 - Train Loss: 0.1972 | Val Loss: 0.2025\n",
            "Epoch 77/80 - Train Loss: 0.1925 | Val Loss: 0.2147\n",
            "Epoch 78/80 - Train Loss: 0.1840 | Val Loss: 0.2023\n",
            "Epoch 79/80 - Train Loss: 0.1906 | Val Loss: 0.2003\n",
            "Epoch 80/80 - Train Loss: 0.1678 | Val Loss: 0.2192\n",
            "Evaluation Metrics:\n",
            "pixel_accuracy: 0.9669961872506649\n",
            "precision: [0.98746232 0.64832228 0.9005825  0.87499493]\n",
            "recall: [0.97753247 0.88615393 0.66888925 0.24087461]\n",
            "f1_score: [0.9824723  0.74880709 0.76763401 0.37775753]\n",
            "iou: [0.96554846 0.59847454 0.62289452 0.23286132]\n",
            "dice_score: [0.9824723  0.74880709 0.76763401 0.37775753]\n",
            "Total params: 2,270,768\n",
            "Model size: 8.66 MB\n"
          ]
        }
      ],
      "source": [
        "# from inside /content/project_root\n",
        "!python train.py \\\n",
        "  --model bisenetmulticlass \\\n",
        "  --data-dir data \\\n",
        "  --output-dir /content/Finaldraft/outputs \\\n",
        "  --img-size 640 \\\n",
        "  --batch-size 8 \\\n",
        "  --epochs 80 \\\n",
        "  --lr 1e-4 \\\n",
        "  --patience 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOG4o5h2ii4V",
        "outputId": "45d48b24-da3b-47de-e8b6-6b8b7c8b2d5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:111: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "Epoch 1/80 - Train Loss: 0.9227 | Val Loss: 0.7063\n",
            "✔️ Best model saved at epoch 1\n",
            "Epoch 2/80 - Train Loss: 0.8019 | Val Loss: 0.6311\n",
            "✔️ Best model saved at epoch 2\n",
            "Epoch 3/80 - Train Loss: 0.7468 | Val Loss: 0.5844\n",
            "✔️ Best model saved at epoch 3\n",
            "Epoch 4/80 - Train Loss: 0.7003 | Val Loss: 0.5871\n",
            "Epoch 5/80 - Train Loss: 0.6778 | Val Loss: 0.5008\n",
            "✔️ Best model saved at epoch 5\n",
            "Epoch 6/80 - Train Loss: 0.6119 | Val Loss: 0.5054\n",
            "Epoch 7/80 - Train Loss: 0.6157 | Val Loss: 0.5061\n",
            "Epoch 8/80 - Train Loss: 0.5938 | Val Loss: 0.4589\n",
            "✔️ Best model saved at epoch 8\n",
            "Epoch 9/80 - Train Loss: 0.5925 | Val Loss: 0.4353\n",
            "✔️ Best model saved at epoch 9\n",
            "Epoch 10/80 - Train Loss: 0.5494 | Val Loss: 0.3970\n",
            "✔️ Best model saved at epoch 10\n",
            "Epoch 11/80 - Train Loss: 0.5452 | Val Loss: 0.4148\n",
            "Epoch 12/80 - Train Loss: 0.5084 | Val Loss: 0.4178\n",
            "Epoch 13/80 - Train Loss: 0.4957 | Val Loss: 0.3674\n",
            "✔️ Best model saved at epoch 13\n",
            "Epoch 14/80 - Train Loss: 0.4817 | Val Loss: 0.3562\n",
            "✔️ Best model saved at epoch 14\n",
            "Epoch 15/80 - Train Loss: 0.4857 | Val Loss: 0.3496\n",
            "✔️ Best model saved at epoch 15\n",
            "Epoch 16/80 - Train Loss: 0.4712 | Val Loss: 0.3351\n",
            "✔️ Best model saved at epoch 16\n",
            "Epoch 17/80 - Train Loss: 0.4245 | Val Loss: 0.3397\n",
            "Epoch 18/80 - Train Loss: 0.4271 | Val Loss: 0.3072\n",
            "✔️ Best model saved at epoch 18\n",
            "Epoch 19/80 - Train Loss: 0.4440 | Val Loss: 0.3604\n",
            "Epoch 20/80 - Train Loss: 0.4090 | Val Loss: 0.2855\n",
            "✔️ Best model saved at epoch 20\n",
            "Epoch 21/80 - Train Loss: 0.4147 | Val Loss: 0.2999\n",
            "Epoch 22/80 - Train Loss: 0.3855 | Val Loss: 0.2908\n",
            "Epoch 23/80 - Train Loss: 0.3994 | Val Loss: 0.2904\n",
            "Epoch 24/80 - Train Loss: 0.3692 | Val Loss: 0.2767\n",
            "✔️ Best model saved at epoch 24\n",
            "Epoch 25/80 - Train Loss: 0.3667 | Val Loss: 0.2849\n",
            "Epoch 26/80 - Train Loss: 0.3654 | Val Loss: 0.2564\n",
            "✔️ Best model saved at epoch 26\n",
            "Epoch 27/80 - Train Loss: 0.3495 | Val Loss: 0.2361\n",
            "✔️ Best model saved at epoch 27\n",
            "Epoch 28/80 - Train Loss: 0.3251 | Val Loss: 0.2975\n",
            "Epoch 29/80 - Train Loss: 0.3486 | Val Loss: 0.2619\n",
            "Epoch 30/80 - Train Loss: 0.3170 | Val Loss: 0.2445\n",
            "Epoch 31/80 - Train Loss: 0.2980 | Val Loss: 0.2517\n",
            "Epoch 32/80 - Train Loss: 0.3342 | Val Loss: 0.2612\n",
            "Epoch 33/80 - Train Loss: 0.3203 | Val Loss: 0.2798\n",
            "Epoch 34/80 - Train Loss: 0.2961 | Val Loss: 0.2637\n",
            "Epoch 35/80 - Train Loss: 0.2823 | Val Loss: 0.2367\n",
            "Epoch 36/80 - Train Loss: 0.3193 | Val Loss: 0.2416\n",
            "Epoch 37/80 - Train Loss: 0.2891 | Val Loss: 0.2578\n",
            "⏹️ Early stopping.\n",
            "Evaluation Metrics:\n",
            "pixel_accuracy: 0.9400045191988032\n",
            "precision: [0.98462674 0.4608788  0.54725574 0.78420061]\n",
            "recall: [0.95133259 0.78935866 0.71261329 0.53004927]\n",
            "f1_score: [0.96769337 0.58196732 0.61908294 0.63255088]\n",
            "iou: [0.93740885 0.41040473 0.44831291 0.46257727]\n",
            "dice_score: [0.96769337 0.58196732 0.61908294 0.63255088]\n",
            "Total params: 7,786,528\n",
            "Model size: 29.70 MB\n"
          ]
        }
      ],
      "source": [
        "# from inside /content/project_root\n",
        "!python train.py \\\n",
        "  --model stdc \\\n",
        "  --data-dir data \\\n",
        "  --output-dir /content/Finaldraft/outputs \\\n",
        "  --img-size 640 \\\n",
        "  --batch-size 8 \\\n",
        "  --epochs 80 \\\n",
        "  --lr 1e-4 \\\n",
        "  --patience 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjCJFag12qiM",
        "outputId": "69cdbfa9-f93f-4600-9ab9-38f34fbce140"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:111: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "Epoch 1/80 - Train Loss: 1.0020 | Val Loss: 0.6997\n",
            "✔️ Best model saved at epoch 1\n",
            "Epoch 2/80 - Train Loss: 0.8772 | Val Loss: 0.6871\n",
            "✔️ Best model saved at epoch 2\n",
            "Epoch 3/80 - Train Loss: 0.7813 | Val Loss: 0.6413\n",
            "✔️ Best model saved at epoch 3\n",
            "Epoch 4/80 - Train Loss: 0.7316 | Val Loss: 0.6027\n",
            "✔️ Best model saved at epoch 4\n",
            "Epoch 5/80 - Train Loss: 0.6997 | Val Loss: 0.5915\n",
            "✔️ Best model saved at epoch 5\n",
            "Epoch 6/80 - Train Loss: 0.6864 | Val Loss: 0.6532\n",
            "Epoch 7/80 - Train Loss: 0.6497 | Val Loss: 0.4851\n",
            "✔️ Best model saved at epoch 7\n",
            "Epoch 8/80 - Train Loss: 0.6215 | Val Loss: 0.5130\n",
            "Epoch 9/80 - Train Loss: 0.5875 | Val Loss: 0.4385\n",
            "✔️ Best model saved at epoch 9\n",
            "Epoch 10/80 - Train Loss: 0.5737 | Val Loss: 0.4165\n",
            "✔️ Best model saved at epoch 10\n",
            "Epoch 11/80 - Train Loss: 0.5447 | Val Loss: 0.4309\n",
            "Epoch 12/80 - Train Loss: 0.5304 | Val Loss: 0.3930\n",
            "✔️ Best model saved at epoch 12\n",
            "Epoch 13/80 - Train Loss: 0.5277 | Val Loss: 0.3675\n",
            "✔️ Best model saved at epoch 13\n",
            "Epoch 14/80 - Train Loss: 0.4802 | Val Loss: 0.3923\n",
            "Epoch 15/80 - Train Loss: 0.5058 | Val Loss: 0.3524\n",
            "✔️ Best model saved at epoch 15\n",
            "Epoch 16/80 - Train Loss: 0.4977 | Val Loss: 0.4176\n",
            "Epoch 17/80 - Train Loss: 0.4788 | Val Loss: 0.3794\n",
            "Epoch 18/80 - Train Loss: 0.4745 | Val Loss: 0.3712\n",
            "Epoch 19/80 - Train Loss: 0.4514 | Val Loss: 0.3882\n",
            "Epoch 20/80 - Train Loss: 0.4550 | Val Loss: 0.3671\n",
            "Epoch 21/80 - Train Loss: 0.4464 | Val Loss: 0.3507\n",
            "✔️ Best model saved at epoch 21\n",
            "Epoch 22/80 - Train Loss: 0.4146 | Val Loss: 0.3257\n",
            "✔️ Best model saved at epoch 22\n",
            "Epoch 23/80 - Train Loss: 0.4078 | Val Loss: 0.3326\n",
            "Epoch 24/80 - Train Loss: 0.3952 | Val Loss: 0.3077\n",
            "✔️ Best model saved at epoch 24\n",
            "Epoch 25/80 - Train Loss: 0.3807 | Val Loss: 0.2894\n",
            "✔️ Best model saved at epoch 25\n",
            "Epoch 26/80 - Train Loss: 0.3609 | Val Loss: 0.3124\n",
            "Epoch 27/80 - Train Loss: 0.3513 | Val Loss: 0.3023\n",
            "Epoch 28/80 - Train Loss: 0.3553 | Val Loss: 0.3199\n",
            "Epoch 29/80 - Train Loss: 0.3857 | Val Loss: 0.3477\n",
            "Epoch 30/80 - Train Loss: 0.3601 | Val Loss: 0.3244\n",
            "Epoch 31/80 - Train Loss: 0.3515 | Val Loss: 0.2711\n",
            "✔️ Best model saved at epoch 31\n",
            "Epoch 32/80 - Train Loss: 0.3430 | Val Loss: 0.2823\n",
            "Epoch 33/80 - Train Loss: 0.3168 | Val Loss: 0.2461\n",
            "✔️ Best model saved at epoch 33\n",
            "Epoch 34/80 - Train Loss: 0.3247 | Val Loss: 0.2469\n",
            "Epoch 35/80 - Train Loss: 0.3130 | Val Loss: 0.2697\n",
            "Epoch 36/80 - Train Loss: 0.3001 | Val Loss: 0.2834\n",
            "Epoch 37/80 - Train Loss: 0.2925 | Val Loss: 0.2660\n",
            "Epoch 38/80 - Train Loss: 0.2980 | Val Loss: 0.2387\n",
            "✔️ Best model saved at epoch 38\n",
            "Epoch 39/80 - Train Loss: 0.2824 | Val Loss: 0.2309\n",
            "✔️ Best model saved at epoch 39\n",
            "Epoch 40/80 - Train Loss: 0.3006 | Val Loss: 0.2934\n",
            "Epoch 41/80 - Train Loss: 0.2847 | Val Loss: 0.2365\n",
            "Epoch 42/80 - Train Loss: 0.2692 | Val Loss: 0.2256\n",
            "✔️ Best model saved at epoch 42\n",
            "Epoch 43/80 - Train Loss: 0.2629 | Val Loss: 0.2263\n",
            "Epoch 44/80 - Train Loss: 0.2861 | Val Loss: 0.2586\n",
            "Epoch 45/80 - Train Loss: 0.2469 | Val Loss: 0.2205\n",
            "✔️ Best model saved at epoch 45\n",
            "Epoch 46/80 - Train Loss: 0.2407 | Val Loss: 0.2202\n",
            "✔️ Best model saved at epoch 46\n",
            "Epoch 47/80 - Train Loss: 0.2481 | Val Loss: 0.2417\n",
            "Epoch 48/80 - Train Loss: 0.2421 | Val Loss: 0.2108\n",
            "✔️ Best model saved at epoch 48\n",
            "Epoch 49/80 - Train Loss: 0.2450 | Val Loss: 0.2507\n",
            "Epoch 50/80 - Train Loss: 0.2402 | Val Loss: 0.2261\n",
            "Epoch 51/80 - Train Loss: 0.2408 | Val Loss: 0.3037\n",
            "Epoch 52/80 - Train Loss: 0.2286 | Val Loss: 0.2242\n",
            "Epoch 53/80 - Train Loss: 0.2185 | Val Loss: 0.2402\n",
            "Epoch 54/80 - Train Loss: 0.2120 | Val Loss: 0.2095\n",
            "✔️ Best model saved at epoch 54\n",
            "Epoch 55/80 - Train Loss: 0.2214 | Val Loss: 0.2478\n",
            "Epoch 56/80 - Train Loss: 0.2140 | Val Loss: 0.2117\n",
            "Epoch 57/80 - Train Loss: 0.2166 | Val Loss: 0.2072\n",
            "✔️ Best model saved at epoch 57\n",
            "Epoch 58/80 - Train Loss: 0.2158 | Val Loss: 0.2340\n",
            "Epoch 59/80 - Train Loss: 0.1943 | Val Loss: 0.1968\n",
            "✔️ Best model saved at epoch 59\n",
            "Epoch 60/80 - Train Loss: 0.2195 | Val Loss: 0.2291\n",
            "Epoch 61/80 - Train Loss: 0.2050 | Val Loss: 0.2505\n",
            "Epoch 62/80 - Train Loss: 0.1979 | Val Loss: 0.2238\n",
            "Epoch 63/80 - Train Loss: 0.1705 | Val Loss: 0.2075\n",
            "Epoch 64/80 - Train Loss: 0.1910 | Val Loss: 0.1915\n",
            "✔️ Best model saved at epoch 64\n",
            "Epoch 65/80 - Train Loss: 0.1907 | Val Loss: 0.2252\n",
            "Epoch 66/80 - Train Loss: 0.2061 | Val Loss: 0.2460\n",
            "Epoch 67/80 - Train Loss: 0.1854 | Val Loss: 0.2486\n",
            "Epoch 68/80 - Train Loss: 0.2069 | Val Loss: 0.2865\n",
            "Epoch 69/80 - Train Loss: 0.1943 | Val Loss: 0.2233\n",
            "Epoch 70/80 - Train Loss: 0.1883 | Val Loss: 0.2321\n",
            "Epoch 71/80 - Train Loss: 0.1909 | Val Loss: 0.2108\n",
            "Epoch 72/80 - Train Loss: 0.1802 | Val Loss: 0.2069\n",
            "Epoch 73/80 - Train Loss: 0.1758 | Val Loss: 0.2678\n",
            "Epoch 74/80 - Train Loss: 0.1613 | Val Loss: 0.2045\n",
            "⏹️ Early stopping.\n",
            "Evaluation Metrics:\n",
            "pixel_accuracy: 0.9652937998670212\n",
            "precision: [0.98961649 0.62860732 0.78367893 0.82583506]\n",
            "recall: [0.97346607 0.89982914 0.73991298 0.41407551]\n",
            "f1_score: [0.98147484 0.740154   0.76116735 0.55158505]\n",
            "iou: [0.96362356 0.58749562 0.61442307 0.38081978]\n",
            "dice_score: [0.98147484 0.740154   0.76116735 0.55158505]\n",
            "Total params: 5,540,704\n",
            "Model size: 21.14 MB\n"
          ]
        }
      ],
      "source": [
        "# from inside /content/project_root\n",
        "!python train.py \\\n",
        "  --model ddrnet \\\n",
        "  --data-dir data \\\n",
        "  --output-dir /content/Finaldraft/outputs \\\n",
        "  --img-size 640 \\\n",
        "  --batch-size 8 \\\n",
        "  --epochs 80 \\\n",
        "  --lr 1e-4 \\\n",
        "  --patience 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMeDAjB2vHHH"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOgZyCGoMPY0",
        "outputId": "309f2023-f29b-4a2c-85cd-01e94099ef09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTovWOHGNOK5",
        "outputId": "0fea219c-1402-4ebf-b937-39166da630c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!unzip -q /content/drive/MyDrive/projects/Finaldraft.zip -d /content/\n",
        "%cd /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eThVFRDfNYJj",
        "outputId": "b18d8be6-ef4c-45c0-8aa1-801b205f4b6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m115.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m95.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# !pip install -q torch torchvision albumentations scikit-learn opencv-python\n",
        "# !pip install -q segmentation-models-pytorch\n",
        "\n",
        "!pip install -r /content/Requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJqaTUJfQg_W",
        "outputId": "c57350b9-babd-49d4-a873-9cb895297787"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/Finaldraft\n"
          ]
        }
      ],
      "source": [
        "%cd /content/Finaldraft/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WAPVxQTdxZJ",
        "outputId": "01dec075-40ff-46f3-e4ef-ee9ab03891ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/Finaldraft\n",
            "augmentation.py  models      __pycache__       train.py\n",
            "data\t\t network.py  README.md\t       visualize.py\n",
            "eval.py\t\t outputs     requirements.txt\n"
          ]
        }
      ],
      "source": [
        "%cd /content/Finaldraft\n",
        "!mkdir -p outputs\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tnf9Ynt0NxUu",
        "outputId": "fb5af0fc-2acf-4e1f-a4a8-f4bdecce4dc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:111: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "Epoch 1/80 - Train Loss: 0.8825 | Val Loss: 0.7168\n",
            "✔️ Best model saved at epoch 1\n",
            "Epoch 2/80 - Train Loss: 0.7776 | Val Loss: 0.6572\n",
            "✔️ Best model saved at epoch 2\n",
            "Epoch 3/80 - Train Loss: 0.7154 | Val Loss: 0.6096\n",
            "✔️ Best model saved at epoch 3\n",
            "Epoch 4/80 - Train Loss: 0.6720 | Val Loss: 0.5589\n",
            "✔️ Best model saved at epoch 4\n",
            "Epoch 5/80 - Train Loss: 0.6423 | Val Loss: 0.5316\n",
            "✔️ Best model saved at epoch 5\n",
            "Epoch 6/80 - Train Loss: 0.6253 | Val Loss: 0.5796\n",
            "Epoch 7/80 - Train Loss: 0.5993 | Val Loss: 0.4952\n",
            "✔️ Best model saved at epoch 7\n",
            "Epoch 8/80 - Train Loss: 0.5777 | Val Loss: 0.4921\n",
            "✔️ Best model saved at epoch 8\n",
            "Epoch 9/80 - Train Loss: 0.5768 | Val Loss: 0.4812\n",
            "✔️ Best model saved at epoch 9\n",
            "Epoch 10/80 - Train Loss: 0.5520 | Val Loss: 0.4853\n",
            "Epoch 11/80 - Train Loss: 0.5506 | Val Loss: 0.4907\n",
            "Epoch 12/80 - Train Loss: 0.5457 | Val Loss: 0.4540\n",
            "✔️ Best model saved at epoch 12\n",
            "Epoch 13/80 - Train Loss: 0.5414 | Val Loss: 0.4483\n",
            "✔️ Best model saved at epoch 13\n",
            "Epoch 14/80 - Train Loss: 0.5251 | Val Loss: 0.4645\n",
            "Epoch 15/80 - Train Loss: 0.5131 | Val Loss: 0.4481\n",
            "✔️ Best model saved at epoch 15\n",
            "Epoch 16/80 - Train Loss: 0.4950 | Val Loss: 0.4346\n",
            "✔️ Best model saved at epoch 16\n",
            "Epoch 17/80 - Train Loss: 0.4970 | Val Loss: 0.4216\n",
            "✔️ Best model saved at epoch 17\n",
            "Epoch 18/80 - Train Loss: 0.4812 | Val Loss: 0.4434\n",
            "Epoch 19/80 - Train Loss: 0.4801 | Val Loss: 0.4036\n",
            "✔️ Best model saved at epoch 19\n",
            "Epoch 20/80 - Train Loss: 0.4722 | Val Loss: 0.3788\n",
            "✔️ Best model saved at epoch 20\n",
            "Epoch 21/80 - Train Loss: 0.4634 | Val Loss: 0.4079\n",
            "Epoch 22/80 - Train Loss: 0.4509 | Val Loss: 0.4055\n",
            "Epoch 23/80 - Train Loss: 0.4388 | Val Loss: 0.3813\n",
            "Epoch 24/80 - Train Loss: 0.4318 | Val Loss: 0.3556\n",
            "✔️ Best model saved at epoch 24\n",
            "Epoch 25/80 - Train Loss: 0.4164 | Val Loss: 0.3625\n",
            "Epoch 26/80 - Train Loss: 0.4124 | Val Loss: 0.4089\n",
            "Epoch 27/80 - Train Loss: 0.4023 | Val Loss: 0.3717\n",
            "Epoch 28/80 - Train Loss: 0.4083 | Val Loss: 0.3691\n",
            "Epoch 29/80 - Train Loss: 0.4013 | Val Loss: 0.3512\n",
            "✔️ Best model saved at epoch 29\n",
            "Epoch 30/80 - Train Loss: 0.3797 | Val Loss: 0.3227\n",
            "✔️ Best model saved at epoch 30\n",
            "Epoch 31/80 - Train Loss: 0.3653 | Val Loss: 0.3124\n",
            "✔️ Best model saved at epoch 31\n",
            "Epoch 32/80 - Train Loss: 0.3706 | Val Loss: 0.3295\n",
            "Epoch 33/80 - Train Loss: 0.3598 | Val Loss: 0.3220\n",
            "Epoch 34/80 - Train Loss: 0.3540 | Val Loss: 0.2930\n",
            "✔️ Best model saved at epoch 34\n",
            "Epoch 35/80 - Train Loss: 0.3355 | Val Loss: 0.2935\n",
            "Epoch 36/80 - Train Loss: 0.3514 | Val Loss: 0.2801\n",
            "✔️ Best model saved at epoch 36\n",
            "Epoch 37/80 - Train Loss: 0.3342 | Val Loss: 0.2874\n",
            "Epoch 38/80 - Train Loss: 0.3269 | Val Loss: 0.3391\n",
            "Epoch 39/80 - Train Loss: 0.3104 | Val Loss: 0.2834\n",
            "Epoch 40/80 - Train Loss: 0.3197 | Val Loss: 0.3034\n",
            "Epoch 41/80 - Train Loss: 0.3247 | Val Loss: 0.2494\n",
            "✔️ Best model saved at epoch 41\n",
            "Epoch 42/80 - Train Loss: 0.3051 | Val Loss: 0.3032\n",
            "Epoch 43/80 - Train Loss: 0.3158 | Val Loss: 0.2617\n",
            "Epoch 44/80 - Train Loss: 0.2958 | Val Loss: 0.2688\n",
            "Epoch 45/80 - Train Loss: 0.2889 | Val Loss: 0.2480\n",
            "✔️ Best model saved at epoch 45\n",
            "Epoch 46/80 - Train Loss: 0.3090 | Val Loss: 0.2780\n",
            "Epoch 47/80 - Train Loss: 0.2793 | Val Loss: 0.2683\n",
            "Epoch 48/80 - Train Loss: 0.2816 | Val Loss: 0.2650\n",
            "Epoch 49/80 - Train Loss: 0.2689 | Val Loss: 0.2275\n",
            "✔️ Best model saved at epoch 49\n",
            "Epoch 50/80 - Train Loss: 0.2715 | Val Loss: 0.2411\n",
            "Epoch 51/80 - Train Loss: 0.2571 | Val Loss: 0.2375\n",
            "Epoch 52/80 - Train Loss: 0.2545 | Val Loss: 0.2307\n",
            "Epoch 53/80 - Train Loss: 0.2556 | Val Loss: 0.2514\n",
            "Epoch 54/80 - Train Loss: 0.2563 | Val Loss: 0.2394\n",
            "Epoch 55/80 - Train Loss: 0.2619 | Val Loss: 0.2951\n",
            "Epoch 56/80 - Train Loss: 0.2495 | Val Loss: 0.2791\n",
            "Epoch 57/80 - Train Loss: 0.2557 | Val Loss: 0.2252\n",
            "✔️ Best model saved at epoch 57\n",
            "Epoch 58/80 - Train Loss: 0.2464 | Val Loss: 0.2625\n",
            "Epoch 59/80 - Train Loss: 0.2413 | Val Loss: 0.2193\n",
            "✔️ Best model saved at epoch 59\n",
            "Epoch 60/80 - Train Loss: 0.2480 | Val Loss: 0.2236\n",
            "Epoch 61/80 - Train Loss: 0.2348 | Val Loss: 0.2121\n",
            "✔️ Best model saved at epoch 61\n",
            "Epoch 62/80 - Train Loss: 0.2406 | Val Loss: 0.2250\n",
            "Epoch 63/80 - Train Loss: 0.2359 | Val Loss: 0.2187\n",
            "Epoch 64/80 - Train Loss: 0.2286 | Val Loss: 0.2183\n",
            "Epoch 65/80 - Train Loss: 0.2209 | Val Loss: 0.2281\n",
            "Epoch 66/80 - Train Loss: 0.2043 | Val Loss: 0.2458\n",
            "Epoch 67/80 - Train Loss: 0.2099 | Val Loss: 0.2172\n",
            "Epoch 68/80 - Train Loss: 0.2137 | Val Loss: 0.1996\n",
            "✔️ Best model saved at epoch 68\n",
            "Epoch 69/80 - Train Loss: 0.2029 | Val Loss: 0.2059\n",
            "Epoch 70/80 - Train Loss: 0.2026 | Val Loss: 0.2487\n",
            "Epoch 71/80 - Train Loss: 0.1988 | Val Loss: 0.2393\n",
            "Epoch 72/80 - Train Loss: 0.2162 | Val Loss: 0.2275\n",
            "Epoch 73/80 - Train Loss: 0.2123 | Val Loss: 0.2044\n",
            "Epoch 74/80 - Train Loss: 0.1924 | Val Loss: 0.2043\n",
            "Epoch 75/80 - Train Loss: 0.1886 | Val Loss: 0.2349\n",
            "Epoch 76/80 - Train Loss: 0.1909 | Val Loss: 0.1992\n",
            "✔️ Best model saved at epoch 76\n",
            "Epoch 77/80 - Train Loss: 0.2050 | Val Loss: 0.2443\n",
            "Epoch 78/80 - Train Loss: 0.2174 | Val Loss: 0.2177\n",
            "Epoch 79/80 - Train Loss: 0.1838 | Val Loss: 0.2074\n",
            "Epoch 80/80 - Train Loss: 0.1808 | Val Loss: 0.1791\n",
            "✔️ Best model saved at epoch 80\n",
            "Evaluation Metrics:\n",
            "pixel_accuracy: 0.9423043527910786\n",
            "precision: [0.96977491 0.79295658 0.83403471 0.82075873]\n",
            "recall: [0.96321663 0.84806142 0.80727308 0.76975569]\n",
            "f1_score: [0.96648464 0.81958379 0.82043572 0.79443945]\n",
            "iou: [0.93514299 0.69431764 0.69554134 0.65897931]\n",
            "dice_score: [0.96648464 0.81958379 0.82043572 0.79443945]\n",
            "Total params: 31,037,828\n",
            "Model size: 118.40 MB\n"
          ]
        }
      ],
      "source": [
        "#run training\n",
        "!python train.py \\\n",
        "  --model unet \\\n",
        "  --data-dir data \\\n",
        "  --output-dir /content/Finaldraft/outputs \\\n",
        "  --img-size 640 \\\n",
        "  --batch-size 8 \\\n",
        "  --epochs 80 \\\n",
        "  --lr 1e-4 \\\n",
        "  --patience 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOc_aDOPgc2T",
        "outputId": "a67516dd-656e-4822-e2d5-b71f6616d5df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:111: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "Epoch 1/80 - Train Loss: 1.0495 | Val Loss: 0.9470\n",
            "✔️ Best model saved at epoch 1\n",
            "Epoch 2/80 - Train Loss: 0.9422 | Val Loss: 0.8706\n",
            "✔️ Best model saved at epoch 2\n",
            "Epoch 3/80 - Train Loss: 0.8697 | Val Loss: 0.7514\n",
            "✔️ Best model saved at epoch 3\n",
            "Epoch 4/80 - Train Loss: 0.8341 | Val Loss: 0.7393\n",
            "✔️ Best model saved at epoch 4\n",
            "Epoch 5/80 - Train Loss: 0.7988 | Val Loss: 0.7541\n",
            "Epoch 6/80 - Train Loss: 0.7764 | Val Loss: 0.6931\n",
            "✔️ Best model saved at epoch 6\n",
            "Epoch 7/80 - Train Loss: 0.7494 | Val Loss: 0.6484\n",
            "✔️ Best model saved at epoch 7\n",
            "Epoch 8/80 - Train Loss: 0.7232 | Val Loss: 0.6228\n",
            "✔️ Best model saved at epoch 8\n",
            "Epoch 9/80 - Train Loss: 0.7041 | Val Loss: 0.6054\n",
            "✔️ Best model saved at epoch 9\n",
            "Epoch 10/80 - Train Loss: 0.6808 | Val Loss: 0.5808\n",
            "✔️ Best model saved at epoch 10\n",
            "Epoch 11/80 - Train Loss: 0.6535 | Val Loss: 0.5867\n",
            "Epoch 12/80 - Train Loss: 0.6543 | Val Loss: 0.5905\n",
            "Epoch 13/80 - Train Loss: 0.6269 | Val Loss: 0.5478\n",
            "✔️ Best model saved at epoch 13\n",
            "Epoch 14/80 - Train Loss: 0.6158 | Val Loss: 0.5478\n",
            "Epoch 15/80 - Train Loss: 0.5943 | Val Loss: 0.5318\n",
            "✔️ Best model saved at epoch 15\n",
            "Epoch 16/80 - Train Loss: 0.6019 | Val Loss: 0.5039\n",
            "✔️ Best model saved at epoch 16\n",
            "Epoch 17/80 - Train Loss: 0.5897 | Val Loss: 0.5179\n",
            "Epoch 18/80 - Train Loss: 0.5642 | Val Loss: 0.5004\n",
            "✔️ Best model saved at epoch 18\n",
            "Epoch 19/80 - Train Loss: 0.5661 | Val Loss: 0.4771\n",
            "✔️ Best model saved at epoch 19\n",
            "Epoch 20/80 - Train Loss: 0.5476 | Val Loss: 0.4877\n",
            "Epoch 21/80 - Train Loss: 0.5407 | Val Loss: 0.4807\n",
            "Epoch 22/80 - Train Loss: 0.5268 | Val Loss: 0.4646\n",
            "✔️ Best model saved at epoch 22\n",
            "Epoch 23/80 - Train Loss: 0.5224 | Val Loss: 0.4684\n",
            "Epoch 24/80 - Train Loss: 0.5219 | Val Loss: 0.4478\n",
            "✔️ Best model saved at epoch 24\n",
            "Epoch 25/80 - Train Loss: 0.5193 | Val Loss: 0.4292\n",
            "✔️ Best model saved at epoch 25\n",
            "Epoch 26/80 - Train Loss: 0.5004 | Val Loss: 0.4442\n",
            "Epoch 27/80 - Train Loss: 0.4826 | Val Loss: 0.4357\n",
            "Epoch 28/80 - Train Loss: 0.4851 | Val Loss: 0.4148\n",
            "✔️ Best model saved at epoch 28\n",
            "Epoch 29/80 - Train Loss: 0.4703 | Val Loss: 0.4383\n",
            "Epoch 30/80 - Train Loss: 0.4660 | Val Loss: 0.4215\n",
            "Epoch 31/80 - Train Loss: 0.4687 | Val Loss: 0.3985\n",
            "✔️ Best model saved at epoch 31\n",
            "Epoch 32/80 - Train Loss: 0.4483 | Val Loss: 0.4522\n",
            "Epoch 33/80 - Train Loss: 0.4338 | Val Loss: 0.4205\n",
            "Epoch 34/80 - Train Loss: 0.4272 | Val Loss: 0.3779\n",
            "✔️ Best model saved at epoch 34\n",
            "Epoch 35/80 - Train Loss: 0.4160 | Val Loss: 0.3764\n",
            "✔️ Best model saved at epoch 35\n",
            "Epoch 36/80 - Train Loss: 0.4177 | Val Loss: 0.3467\n",
            "✔️ Best model saved at epoch 36\n",
            "Epoch 37/80 - Train Loss: 0.3977 | Val Loss: 0.3512\n",
            "Epoch 38/80 - Train Loss: 0.3885 | Val Loss: 0.3445\n",
            "✔️ Best model saved at epoch 38\n",
            "Epoch 39/80 - Train Loss: 0.3916 | Val Loss: 0.5830\n",
            "Epoch 40/80 - Train Loss: 0.3963 | Val Loss: 0.3390\n",
            "✔️ Best model saved at epoch 40\n",
            "Epoch 41/80 - Train Loss: 0.3724 | Val Loss: 0.3539\n",
            "Epoch 42/80 - Train Loss: 0.3671 | Val Loss: 0.3812\n",
            "Epoch 43/80 - Train Loss: 0.3580 | Val Loss: 0.2953\n",
            "✔️ Best model saved at epoch 43\n",
            "Epoch 44/80 - Train Loss: 0.3470 | Val Loss: 0.3131\n",
            "Epoch 45/80 - Train Loss: 0.3381 | Val Loss: 0.3186\n",
            "Epoch 46/80 - Train Loss: 0.3317 | Val Loss: 0.3238\n",
            "Epoch 47/80 - Train Loss: 0.3271 | Val Loss: 0.2991\n",
            "Epoch 48/80 - Train Loss: 0.3325 | Val Loss: 0.3108\n",
            "Epoch 49/80 - Train Loss: 0.3297 | Val Loss: 0.3227\n",
            "Epoch 50/80 - Train Loss: 0.3277 | Val Loss: 0.2880\n",
            "✔️ Best model saved at epoch 50\n",
            "Epoch 51/80 - Train Loss: 0.3010 | Val Loss: 0.2706\n",
            "✔️ Best model saved at epoch 51\n",
            "Epoch 52/80 - Train Loss: 0.2959 | Val Loss: 0.3584\n",
            "Epoch 53/80 - Train Loss: 0.2990 | Val Loss: 0.2736\n",
            "Epoch 54/80 - Train Loss: 0.2816 | Val Loss: 0.2595\n",
            "✔️ Best model saved at epoch 54\n",
            "Epoch 55/80 - Train Loss: 0.2813 | Val Loss: 0.2834\n",
            "Epoch 56/80 - Train Loss: 0.2919 | Val Loss: 0.2857\n",
            "Epoch 57/80 - Train Loss: 0.2763 | Val Loss: 0.2493\n",
            "✔️ Best model saved at epoch 57\n",
            "Epoch 58/80 - Train Loss: 0.2657 | Val Loss: 0.2540\n",
            "Epoch 59/80 - Train Loss: 0.2521 | Val Loss: 0.2480\n",
            "✔️ Best model saved at epoch 59\n",
            "Epoch 60/80 - Train Loss: 0.2617 | Val Loss: 0.2767\n",
            "Epoch 61/80 - Train Loss: 0.2715 | Val Loss: 0.2576\n",
            "Epoch 62/80 - Train Loss: 0.2752 | Val Loss: 0.2722\n",
            "Epoch 63/80 - Train Loss: 0.2607 | Val Loss: 0.2351\n",
            "✔️ Best model saved at epoch 63\n",
            "Epoch 64/80 - Train Loss: 0.2464 | Val Loss: 0.2661\n",
            "Epoch 65/80 - Train Loss: 0.2352 | Val Loss: 0.2407\n",
            "Epoch 66/80 - Train Loss: 0.2408 | Val Loss: 0.2401\n",
            "Epoch 67/80 - Train Loss: 0.2229 | Val Loss: 0.2436\n",
            "Epoch 68/80 - Train Loss: 0.2281 | Val Loss: 0.2509\n",
            "Epoch 69/80 - Train Loss: 0.2394 | Val Loss: 0.2609\n",
            "Epoch 70/80 - Train Loss: 0.2241 | Val Loss: 0.2540\n",
            "Epoch 71/80 - Train Loss: 0.2214 | Val Loss: 0.2327\n",
            "✔️ Best model saved at epoch 71\n",
            "Epoch 72/80 - Train Loss: 0.2146 | Val Loss: 0.2545\n",
            "Epoch 73/80 - Train Loss: 0.2250 | Val Loss: 0.2356\n",
            "Epoch 74/80 - Train Loss: 0.2075 | Val Loss: 0.2137\n",
            "✔️ Best model saved at epoch 74\n",
            "Epoch 75/80 - Train Loss: 0.2238 | Val Loss: 0.2447\n",
            "Epoch 76/80 - Train Loss: 0.1960 | Val Loss: 0.2206\n",
            "Epoch 77/80 - Train Loss: 0.2043 | Val Loss: 0.2338\n",
            "Epoch 78/80 - Train Loss: 0.2063 | Val Loss: 0.2441\n",
            "Epoch 79/80 - Train Loss: 0.2036 | Val Loss: 0.2086\n",
            "✔️ Best model saved at epoch 79\n",
            "Epoch 80/80 - Train Loss: 0.1969 | Val Loss: 0.2694\n",
            "Evaluation Metrics:\n",
            "pixel_accuracy: 0.9169629300025202\n",
            "precision: [0.96720641 0.78567574 0.49005327 0.7867613 ]\n",
            "recall: [0.93790497 0.82533561 0.78626939 0.7111107 ]\n",
            "f1_score: [0.95233035 0.8050175  0.60378758 0.74702562]\n",
            "iou: [0.90899871 0.67366468 0.43244679 0.59620183]\n",
            "dice_score: [0.95233035 0.8050175  0.60378758 0.74702562]\n",
            "Total params: 41,896,932\n",
            "Model size: 159.82 MB\n"
          ]
        }
      ],
      "source": [
        "#run training\n",
        "!python train.py \\\n",
        "  --model unet_vgg16 \\\n",
        "  --data-dir data \\\n",
        "  --output-dir /content/Finaldraft/outputs \\\n",
        "  --img-size 640 \\\n",
        "  --batch-size 8 \\\n",
        "  --epochs 80 \\\n",
        "  --lr 1e-4 \\\n",
        "  --patience 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vt_DT6gIQZsb",
        "outputId": "b4fa202e-1d24-49fe-e678-a6193e723040"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:111: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "Epoch 1/80 - Train Loss: 0.8519 | Val Loss: 0.6719\n",
            "✔️ Best model saved at epoch 1\n",
            "Epoch 2/80 - Train Loss: 0.7273 | Val Loss: 0.6083\n",
            "✔️ Best model saved at epoch 2\n",
            "Epoch 3/80 - Train Loss: 0.6824 | Val Loss: 0.5889\n",
            "✔️ Best model saved at epoch 3\n",
            "Epoch 4/80 - Train Loss: 0.6592 | Val Loss: 0.5860\n",
            "✔️ Best model saved at epoch 4\n",
            "Epoch 5/80 - Train Loss: 0.6374 | Val Loss: 0.5162\n",
            "✔️ Best model saved at epoch 5\n",
            "Epoch 6/80 - Train Loss: 0.6089 | Val Loss: 0.4996\n",
            "✔️ Best model saved at epoch 6\n",
            "Epoch 7/80 - Train Loss: 0.5969 | Val Loss: 0.5103\n",
            "Epoch 8/80 - Train Loss: 0.5741 | Val Loss: 0.5107\n",
            "Epoch 9/80 - Train Loss: 0.5692 | Val Loss: 0.4778\n",
            "✔️ Best model saved at epoch 9\n",
            "Epoch 10/80 - Train Loss: 0.5672 | Val Loss: 0.4693\n",
            "✔️ Best model saved at epoch 10\n",
            "Epoch 11/80 - Train Loss: 0.5516 | Val Loss: 0.5008\n",
            "Epoch 12/80 - Train Loss: 0.5367 | Val Loss: 0.5005\n",
            "Epoch 13/80 - Train Loss: 0.5329 | Val Loss: 0.4638\n",
            "✔️ Best model saved at epoch 13\n",
            "Epoch 14/80 - Train Loss: 0.5314 | Val Loss: 0.4718\n",
            "Epoch 15/80 - Train Loss: 0.5185 | Val Loss: 0.4307\n",
            "✔️ Best model saved at epoch 15\n",
            "Epoch 16/80 - Train Loss: 0.5195 | Val Loss: 0.4190\n",
            "✔️ Best model saved at epoch 16\n",
            "Epoch 17/80 - Train Loss: 0.4980 | Val Loss: 0.4167\n",
            "✔️ Best model saved at epoch 17\n",
            "Epoch 18/80 - Train Loss: 0.4942 | Val Loss: 0.3972\n",
            "✔️ Best model saved at epoch 18\n",
            "Epoch 19/80 - Train Loss: 0.4677 | Val Loss: 0.4150\n",
            "Epoch 20/80 - Train Loss: 0.4609 | Val Loss: 0.3833\n",
            "✔️ Best model saved at epoch 20\n",
            "Epoch 21/80 - Train Loss: 0.4467 | Val Loss: 0.3772\n",
            "✔️ Best model saved at epoch 21\n",
            "Epoch 22/80 - Train Loss: 0.4458 | Val Loss: 0.3676\n",
            "✔️ Best model saved at epoch 22\n",
            "Epoch 23/80 - Train Loss: 0.4491 | Val Loss: 0.3827\n",
            "Epoch 24/80 - Train Loss: 0.4722 | Val Loss: 0.4015\n",
            "Epoch 25/80 - Train Loss: 0.4506 | Val Loss: 0.3580\n",
            "✔️ Best model saved at epoch 25\n",
            "Epoch 26/80 - Train Loss: 0.4171 | Val Loss: 0.4040\n",
            "Epoch 27/80 - Train Loss: 0.4266 | Val Loss: 0.3670\n",
            "Epoch 28/80 - Train Loss: 0.4169 | Val Loss: 0.3769\n",
            "Epoch 29/80 - Train Loss: 0.4209 | Val Loss: 0.3433\n",
            "✔️ Best model saved at epoch 29\n",
            "Epoch 30/80 - Train Loss: 0.4115 | Val Loss: 0.4065\n",
            "Epoch 31/80 - Train Loss: 0.3974 | Val Loss: 0.3369\n",
            "✔️ Best model saved at epoch 31\n",
            "Epoch 32/80 - Train Loss: 0.3803 | Val Loss: 0.3202\n",
            "✔️ Best model saved at epoch 32\n",
            "Epoch 33/80 - Train Loss: 0.3841 | Val Loss: 0.3477\n",
            "Epoch 34/80 - Train Loss: 0.3809 | Val Loss: 0.3161\n",
            "✔️ Best model saved at epoch 34\n",
            "Epoch 35/80 - Train Loss: 0.3656 | Val Loss: 0.3040\n",
            "✔️ Best model saved at epoch 35\n",
            "Epoch 36/80 - Train Loss: 0.3578 | Val Loss: 0.2866\n",
            "✔️ Best model saved at epoch 36\n",
            "Epoch 37/80 - Train Loss: 0.3684 | Val Loss: 0.3546\n",
            "Epoch 38/80 - Train Loss: 0.3473 | Val Loss: 0.3117\n",
            "Epoch 39/80 - Train Loss: 0.3339 | Val Loss: 0.2857\n",
            "✔️ Best model saved at epoch 39\n",
            "Epoch 40/80 - Train Loss: 0.3314 | Val Loss: 0.3301\n",
            "Epoch 41/80 - Train Loss: 0.3291 | Val Loss: 0.3346\n",
            "Epoch 42/80 - Train Loss: 0.3144 | Val Loss: 0.2812\n",
            "✔️ Best model saved at epoch 42\n",
            "Epoch 43/80 - Train Loss: 0.3230 | Val Loss: 0.3084\n",
            "Epoch 44/80 - Train Loss: 0.3098 | Val Loss: 0.2922\n",
            "Epoch 45/80 - Train Loss: 0.3092 | Val Loss: 0.4852\n",
            "Epoch 46/80 - Train Loss: 0.3107 | Val Loss: 0.2576\n",
            "✔️ Best model saved at epoch 46\n",
            "Epoch 47/80 - Train Loss: 0.2902 | Val Loss: 0.2636\n",
            "Epoch 48/80 - Train Loss: 0.2982 | Val Loss: 0.2663\n",
            "Epoch 49/80 - Train Loss: 0.2854 | Val Loss: 0.2519\n",
            "✔️ Best model saved at epoch 49\n",
            "Epoch 50/80 - Train Loss: 0.2698 | Val Loss: 0.2533\n",
            "Epoch 51/80 - Train Loss: 0.2930 | Val Loss: 0.2471\n",
            "✔️ Best model saved at epoch 51\n",
            "Epoch 52/80 - Train Loss: 0.2754 | Val Loss: 0.2599\n",
            "Epoch 53/80 - Train Loss: 0.2738 | Val Loss: 0.2369\n",
            "✔️ Best model saved at epoch 53\n",
            "Epoch 54/80 - Train Loss: 0.2744 | Val Loss: 0.2653\n",
            "Epoch 55/80 - Train Loss: 0.2785 | Val Loss: 0.2433\n",
            "Epoch 56/80 - Train Loss: 0.2785 | Val Loss: 0.2392\n",
            "Epoch 57/80 - Train Loss: 0.2594 | Val Loss: 0.2348\n",
            "✔️ Best model saved at epoch 57\n",
            "Epoch 58/80 - Train Loss: 0.2803 | Val Loss: 0.2340\n",
            "✔️ Best model saved at epoch 58\n",
            "Epoch 59/80 - Train Loss: 0.2534 | Val Loss: 0.2190\n",
            "✔️ Best model saved at epoch 59\n",
            "Epoch 60/80 - Train Loss: 0.2502 | Val Loss: 0.2369\n",
            "Epoch 61/80 - Train Loss: 0.2504 | Val Loss: 0.2191\n",
            "Epoch 62/80 - Train Loss: 0.2504 | Val Loss: 0.2227\n",
            "Epoch 63/80 - Train Loss: 0.2412 | Val Loss: 0.2383\n",
            "Epoch 64/80 - Train Loss: 0.2270 | Val Loss: 0.2224\n",
            "Epoch 65/80 - Train Loss: 0.2229 | Val Loss: 0.2064\n",
            "✔️ Best model saved at epoch 65\n",
            "Epoch 66/80 - Train Loss: 0.2353 | Val Loss: 0.2236\n",
            "Epoch 67/80 - Train Loss: 0.2271 | Val Loss: 0.2557\n",
            "Epoch 68/80 - Train Loss: 0.2210 | Val Loss: 0.2212\n",
            "Epoch 69/80 - Train Loss: 0.2201 | Val Loss: 0.2255\n",
            "Epoch 70/80 - Train Loss: 0.2167 | Val Loss: 0.2208\n",
            "Epoch 71/80 - Train Loss: 0.2284 | Val Loss: 0.2345\n",
            "Epoch 72/80 - Train Loss: 0.2101 | Val Loss: 0.2379\n",
            "Epoch 73/80 - Train Loss: 0.2095 | Val Loss: 0.2051\n",
            "✔️ Best model saved at epoch 73\n",
            "Epoch 74/80 - Train Loss: 0.1965 | Val Loss: 0.1938\n",
            "✔️ Best model saved at epoch 74\n",
            "Epoch 75/80 - Train Loss: 0.1974 | Val Loss: 0.2079\n",
            "Epoch 76/80 - Train Loss: 0.2069 | Val Loss: 0.2076\n",
            "Epoch 77/80 - Train Loss: 0.2040 | Val Loss: 0.2166\n",
            "Epoch 78/80 - Train Loss: 0.1997 | Val Loss: 0.2134\n",
            "Epoch 79/80 - Train Loss: 0.1926 | Val Loss: 0.2108\n",
            "Epoch 80/80 - Train Loss: 0.1850 | Val Loss: 0.2444\n",
            "Evaluation Metrics:\n",
            "pixel_accuracy: 0.9306586284022177\n",
            "precision: [0.93549024 0.93037323 0.80361649 0.89868169]\n",
            "recall: [0.98610278 0.61554095 0.70923883 0.64564454]\n",
            "f1_score: [0.96012996 0.74089859 0.75348384 0.7514331 ]\n",
            "iou: [0.92331728 0.58843441 0.60447178 0.60183648]\n",
            "dice_score: [0.96012996 0.74089859 0.75348384 0.7514331 ]\n",
            "Total params: 34,878,768\n",
            "Model size: 133.05 MB\n"
          ]
        }
      ],
      "source": [
        "#run training\n",
        "!python train.py \\\n",
        "  --model attunet \\\n",
        "  --data-dir data \\\n",
        "  --output-dir /content/Finaldraft/outputs \\\n",
        "  --img-size 640 \\\n",
        "  --batch-size 8 \\\n",
        "  --epochs 80 \\\n",
        "  --lr 1e-4 \\\n",
        "  --patience 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDxkl7CbhWNn",
        "outputId": "b24d0c33-cb0e-42ff-b2bc-19f4cc96d0bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:111: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "config.json: 100% 156/156 [00:00<00:00, 1.14MB/s]\n",
            "model.safetensors: 100% 87.3M/87.3M [00:00<00:00, 199MB/s]\n",
            "Epoch 1/80 - Train Loss: 0.8507 | Val Loss: 0.5634\n",
            "✔️ Best model saved at epoch 1\n",
            "Epoch 2/80 - Train Loss: 0.5377 | Val Loss: 0.7675\n",
            "Epoch 3/80 - Train Loss: 0.4157 | Val Loss: 0.3209\n",
            "✔️ Best model saved at epoch 3\n",
            "Epoch 4/80 - Train Loss: 0.3354 | Val Loss: 0.2884\n",
            "✔️ Best model saved at epoch 4\n",
            "Epoch 5/80 - Train Loss: 0.2832 | Val Loss: 0.2482\n",
            "✔️ Best model saved at epoch 5\n",
            "Epoch 6/80 - Train Loss: 0.2396 | Val Loss: 0.2338\n",
            "✔️ Best model saved at epoch 6\n",
            "Epoch 7/80 - Train Loss: 0.2201 | Val Loss: 0.2206\n",
            "✔️ Best model saved at epoch 7\n",
            "Epoch 8/80 - Train Loss: 0.1997 | Val Loss: 0.2220\n",
            "Epoch 9/80 - Train Loss: 0.1845 | Val Loss: 0.2006\n",
            "✔️ Best model saved at epoch 9\n",
            "Epoch 10/80 - Train Loss: 0.1739 | Val Loss: 0.2218\n",
            "Epoch 11/80 - Train Loss: 0.1689 | Val Loss: 0.1940\n",
            "✔️ Best model saved at epoch 11\n",
            "Epoch 12/80 - Train Loss: 0.1481 | Val Loss: 0.1818\n",
            "✔️ Best model saved at epoch 12\n",
            "Epoch 13/80 - Train Loss: 0.1331 | Val Loss: 0.1702\n",
            "✔️ Best model saved at epoch 13\n",
            "Epoch 14/80 - Train Loss: 0.1254 | Val Loss: 0.1871\n",
            "Epoch 15/80 - Train Loss: 0.1265 | Val Loss: 0.1611\n",
            "✔️ Best model saved at epoch 15\n",
            "Epoch 16/80 - Train Loss: 0.1111 | Val Loss: 0.1560\n",
            "✔️ Best model saved at epoch 16\n",
            "Epoch 17/80 - Train Loss: 0.1143 | Val Loss: 0.1591\n",
            "Epoch 18/80 - Train Loss: 0.1122 | Val Loss: 0.1513\n",
            "✔️ Best model saved at epoch 18\n",
            "Epoch 19/80 - Train Loss: 0.0963 | Val Loss: 0.1474\n",
            "✔️ Best model saved at epoch 19\n",
            "Epoch 20/80 - Train Loss: 0.1040 | Val Loss: 0.1615\n",
            "Epoch 21/80 - Train Loss: 0.1035 | Val Loss: 0.1561\n",
            "Epoch 22/80 - Train Loss: 0.1049 | Val Loss: 0.1580\n",
            "Epoch 23/80 - Train Loss: 0.0909 | Val Loss: 0.1462\n",
            "✔️ Best model saved at epoch 23\n",
            "Epoch 24/80 - Train Loss: 0.0850 | Val Loss: 0.1384\n",
            "✔️ Best model saved at epoch 24\n",
            "Epoch 25/80 - Train Loss: 0.0806 | Val Loss: 0.1330\n",
            "✔️ Best model saved at epoch 25\n",
            "Epoch 26/80 - Train Loss: 0.0790 | Val Loss: 0.1242\n",
            "✔️ Best model saved at epoch 26\n",
            "Epoch 27/80 - Train Loss: 0.0721 | Val Loss: 0.1374\n",
            "Epoch 28/80 - Train Loss: 0.0739 | Val Loss: 0.1359\n",
            "Epoch 29/80 - Train Loss: 0.0703 | Val Loss: 0.1351\n",
            "Epoch 30/80 - Train Loss: 0.0686 | Val Loss: 0.1342\n",
            "Epoch 31/80 - Train Loss: 0.0691 | Val Loss: 0.1330\n",
            "Epoch 32/80 - Train Loss: 0.0693 | Val Loss: 0.1648\n",
            "Epoch 33/80 - Train Loss: 0.1040 | Val Loss: 0.1750\n",
            "Epoch 34/80 - Train Loss: 0.1085 | Val Loss: 0.1451\n",
            "Epoch 35/80 - Train Loss: 0.1099 | Val Loss: 0.1521\n",
            "Epoch 36/80 - Train Loss: 0.0809 | Val Loss: 0.1411\n",
            "Epoch 37/80 - Train Loss: 0.0764 | Val Loss: 0.1440\n",
            "Epoch 38/80 - Train Loss: 0.0680 | Val Loss: 0.1304\n",
            "Epoch 39/80 - Train Loss: 0.0692 | Val Loss: 0.1225\n",
            "✔️ Best model saved at epoch 39\n",
            "Epoch 40/80 - Train Loss: 0.0627 | Val Loss: 0.1244\n",
            "Epoch 41/80 - Train Loss: 0.0800 | Val Loss: 0.1451\n",
            "Epoch 42/80 - Train Loss: 0.0728 | Val Loss: 0.1265\n",
            "Epoch 43/80 - Train Loss: 0.0622 | Val Loss: 0.1312\n",
            "Epoch 44/80 - Train Loss: 0.0580 | Val Loss: 0.1250\n",
            "Epoch 45/80 - Train Loss: 0.0565 | Val Loss: 0.1288\n",
            "Epoch 46/80 - Train Loss: 0.0581 | Val Loss: 0.1319\n",
            "Epoch 47/80 - Train Loss: 0.0564 | Val Loss: 0.1280\n",
            "Epoch 48/80 - Train Loss: 0.0531 | Val Loss: 0.1259\n",
            "Epoch 49/80 - Train Loss: 0.0567 | Val Loss: 0.1304\n",
            "Epoch 50/80 - Train Loss: 0.0516 | Val Loss: 0.1386\n",
            "Epoch 51/80 - Train Loss: 0.0526 | Val Loss: 0.1344\n",
            "Epoch 52/80 - Train Loss: 0.0546 | Val Loss: 0.1217\n",
            "✔️ Best model saved at epoch 52\n",
            "Epoch 53/80 - Train Loss: 0.0531 | Val Loss: 0.1324\n",
            "Epoch 54/80 - Train Loss: 0.0524 | Val Loss: 0.1267\n",
            "Epoch 55/80 - Train Loss: 0.0509 | Val Loss: 0.1422\n",
            "Epoch 56/80 - Train Loss: 0.0485 | Val Loss: 0.1251\n",
            "Epoch 57/80 - Train Loss: 0.0484 | Val Loss: 0.1351\n",
            "Epoch 58/80 - Train Loss: 0.0494 | Val Loss: 0.1274\n",
            "Epoch 59/80 - Train Loss: 0.0488 | Val Loss: 0.1231\n",
            "Epoch 60/80 - Train Loss: 0.0461 | Val Loss: 0.1218\n",
            "Epoch 61/80 - Train Loss: 0.0494 | Val Loss: 0.1649\n",
            "Epoch 62/80 - Train Loss: 0.0531 | Val Loss: 0.1174\n",
            "✔️ Best model saved at epoch 62\n",
            "Epoch 63/80 - Train Loss: 0.0604 | Val Loss: 0.1303\n",
            "Epoch 64/80 - Train Loss: 0.0540 | Val Loss: 0.1447\n",
            "Epoch 65/80 - Train Loss: 0.0585 | Val Loss: 0.1248\n",
            "Epoch 66/80 - Train Loss: 0.0514 | Val Loss: 0.1228\n",
            "Epoch 67/80 - Train Loss: 0.0480 | Val Loss: 0.1176\n",
            "Epoch 68/80 - Train Loss: 0.0506 | Val Loss: 0.1144\n",
            "✔️ Best model saved at epoch 68\n",
            "Epoch 69/80 - Train Loss: 0.0512 | Val Loss: 0.1222\n",
            "Epoch 70/80 - Train Loss: 0.0465 | Val Loss: 0.1230\n",
            "Epoch 71/80 - Train Loss: 0.0466 | Val Loss: 0.1247\n",
            "Epoch 72/80 - Train Loss: 0.0457 | Val Loss: 0.1341\n",
            "Epoch 73/80 - Train Loss: 0.0517 | Val Loss: 0.1218\n",
            "Epoch 74/80 - Train Loss: 0.0604 | Val Loss: 0.1768\n",
            "Epoch 75/80 - Train Loss: 0.0684 | Val Loss: 0.1365\n",
            "Epoch 76/80 - Train Loss: 0.0605 | Val Loss: 0.1236\n",
            "Epoch 77/80 - Train Loss: 0.0516 | Val Loss: 0.1463\n",
            "Epoch 78/80 - Train Loss: 0.0665 | Val Loss: 0.1882\n",
            "Epoch 79/80 - Train Loss: 0.0718 | Val Loss: 0.1635\n",
            "Epoch 80/80 - Train Loss: 0.0707 | Val Loss: 0.1453\n",
            "Evaluation Metrics:\n",
            "pixel_accuracy: 0.9710194643082157\n",
            "precision: [0.97517906 0.96989586 0.9300761  0.82695048]\n",
            "recall: [0.99133636 0.86425034 0.86355728 0.86391664]\n",
            "f1_score: [0.98319133 0.91403054 0.89558323 0.84502947]\n",
            "iou: [0.96693839 0.84167243 0.81091057 0.73164593]\n",
            "dice_score: [0.98319133 0.91403054 0.89558323 0.84502947]\n",
            "Total params: 22,438,228\n",
            "Model size: 85.60 MB\n"
          ]
        }
      ],
      "source": [
        "#run training\n",
        "!python train.py \\\n",
        "  --model deeplabv3plus_resnet34\\\n",
        "  --data-dir data \\\n",
        "  --output-dir /content/Finaldraft/outputs \\\n",
        "  --img-size 640 \\\n",
        "  --batch-size 8 \\\n",
        "  --epochs 80 \\\n",
        "  --lr 1e-4 \\\n",
        "  --patience 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bHPDE0oXou5",
        "outputId": "283948b5-7b59-43af-d833-b8edb4270b5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:111: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "config.json: 100% 135/135 [00:00<00:00, 981kB/s]\n",
            "model.safetensors: 100% 14.3M/14.3M [00:00<00:00, 83.1MB/s]\n",
            "Epoch 1/80 - Train Loss: 0.8318 | Val Loss: 0.5954\n",
            "✔️ Best model saved at epoch 1\n",
            "Epoch 2/80 - Train Loss: 0.5622 | Val Loss: 0.4316\n",
            "✔️ Best model saved at epoch 2\n",
            "Epoch 3/80 - Train Loss: 0.4504 | Val Loss: 0.3484\n",
            "✔️ Best model saved at epoch 3\n",
            "Epoch 4/80 - Train Loss: 0.3548 | Val Loss: 0.2899\n",
            "✔️ Best model saved at epoch 4\n",
            "Epoch 5/80 - Train Loss: 0.2993 | Val Loss: 0.2713\n",
            "✔️ Best model saved at epoch 5\n",
            "Epoch 6/80 - Train Loss: 0.2677 | Val Loss: 0.2429\n",
            "✔️ Best model saved at epoch 6\n",
            "Epoch 7/80 - Train Loss: 0.2529 | Val Loss: 0.2270\n",
            "✔️ Best model saved at epoch 7\n",
            "Epoch 8/80 - Train Loss: 0.2191 | Val Loss: 0.2095\n",
            "✔️ Best model saved at epoch 8\n",
            "Epoch 9/80 - Train Loss: 0.1890 | Val Loss: 0.2085\n",
            "✔️ Best model saved at epoch 9\n",
            "Epoch 10/80 - Train Loss: 0.1915 | Val Loss: 0.2057\n",
            "✔️ Best model saved at epoch 10\n",
            "Epoch 11/80 - Train Loss: 0.1836 | Val Loss: 0.2033\n",
            "✔️ Best model saved at epoch 11\n",
            "Epoch 12/80 - Train Loss: 0.1677 | Val Loss: 0.1863\n",
            "✔️ Best model saved at epoch 12\n",
            "Epoch 13/80 - Train Loss: 0.1609 | Val Loss: 0.1872\n",
            "Epoch 14/80 - Train Loss: 0.1552 | Val Loss: 0.1767\n",
            "✔️ Best model saved at epoch 14\n",
            "Epoch 15/80 - Train Loss: 0.1452 | Val Loss: 0.2132\n",
            "Epoch 16/80 - Train Loss: 0.1617 | Val Loss: 0.1818\n",
            "Epoch 17/80 - Train Loss: 0.1389 | Val Loss: 0.1718\n",
            "✔️ Best model saved at epoch 17\n",
            "Epoch 18/80 - Train Loss: 0.1228 | Val Loss: 0.1643\n",
            "✔️ Best model saved at epoch 18\n",
            "Epoch 19/80 - Train Loss: 0.1148 | Val Loss: 0.1611\n",
            "✔️ Best model saved at epoch 19\n",
            "Epoch 20/80 - Train Loss: 0.1215 | Val Loss: 0.1548\n",
            "✔️ Best model saved at epoch 20\n",
            "Epoch 21/80 - Train Loss: 0.1112 | Val Loss: 0.1577\n",
            "Epoch 22/80 - Train Loss: 0.1096 | Val Loss: 0.1895\n",
            "Epoch 23/80 - Train Loss: 0.1082 | Val Loss: 0.1651\n",
            "Epoch 24/80 - Train Loss: 0.1005 | Val Loss: 0.1522\n",
            "✔️ Best model saved at epoch 24\n",
            "Epoch 25/80 - Train Loss: 0.0960 | Val Loss: 0.1482\n",
            "✔️ Best model saved at epoch 25\n",
            "Epoch 26/80 - Train Loss: 0.1019 | Val Loss: 0.1639\n",
            "Epoch 27/80 - Train Loss: 0.0951 | Val Loss: 0.1620\n",
            "Epoch 28/80 - Train Loss: 0.0934 | Val Loss: 0.1515\n",
            "Epoch 29/80 - Train Loss: 0.0973 | Val Loss: 0.1447\n",
            "✔️ Best model saved at epoch 29\n",
            "Epoch 30/80 - Train Loss: 0.0954 | Val Loss: 0.1492\n",
            "Epoch 31/80 - Train Loss: 0.0817 | Val Loss: 0.1505\n",
            "Epoch 32/80 - Train Loss: 0.0807 | Val Loss: 0.1443\n",
            "✔️ Best model saved at epoch 32\n",
            "Epoch 33/80 - Train Loss: 0.0953 | Val Loss: 0.1781\n",
            "Epoch 34/80 - Train Loss: 0.0884 | Val Loss: 0.1517\n",
            "Epoch 35/80 - Train Loss: 0.0806 | Val Loss: 0.1466\n",
            "Epoch 36/80 - Train Loss: 0.0907 | Val Loss: 0.1991\n",
            "Epoch 37/80 - Train Loss: 0.0913 | Val Loss: 0.1693\n",
            "Epoch 38/80 - Train Loss: 0.0773 | Val Loss: 0.1495\n",
            "Epoch 39/80 - Train Loss: 0.0813 | Val Loss: 0.1485\n",
            "Epoch 40/80 - Train Loss: 0.0770 | Val Loss: 0.1458\n",
            "Epoch 41/80 - Train Loss: 0.0751 | Val Loss: 0.1376\n",
            "✔️ Best model saved at epoch 41\n",
            "Epoch 42/80 - Train Loss: 0.0740 | Val Loss: 0.1572\n",
            "Epoch 43/80 - Train Loss: 0.0722 | Val Loss: 0.1403\n",
            "Epoch 44/80 - Train Loss: 0.0795 | Val Loss: 0.1522\n",
            "Epoch 45/80 - Train Loss: 0.1020 | Val Loss: 0.1591\n",
            "Epoch 46/80 - Train Loss: 0.0781 | Val Loss: 0.1384\n",
            "Epoch 47/80 - Train Loss: 0.0692 | Val Loss: 0.1527\n",
            "Epoch 48/80 - Train Loss: 0.0699 | Val Loss: 0.1490\n",
            "Epoch 49/80 - Train Loss: 0.0650 | Val Loss: 0.1463\n",
            "Epoch 50/80 - Train Loss: 0.0657 | Val Loss: 0.1402\n",
            "Epoch 51/80 - Train Loss: 0.0647 | Val Loss: 0.1452\n",
            "Epoch 52/80 - Train Loss: 0.0608 | Val Loss: 0.1473\n",
            "Epoch 53/80 - Train Loss: 0.0629 | Val Loss: 0.1418\n",
            "Epoch 54/80 - Train Loss: 0.0622 | Val Loss: 0.1414\n",
            "Epoch 55/80 - Train Loss: 0.0654 | Val Loss: 0.1419\n",
            "Epoch 56/80 - Train Loss: 0.0614 | Val Loss: 0.1427\n",
            "Epoch 57/80 - Train Loss: 0.0592 | Val Loss: 0.1530\n",
            "Epoch 58/80 - Train Loss: 0.0632 | Val Loss: 0.1514\n",
            "Epoch 59/80 - Train Loss: 0.0622 | Val Loss: 0.1477\n",
            "Epoch 60/80 - Train Loss: 0.0622 | Val Loss: 0.1394\n",
            "Epoch 61/80 - Train Loss: 0.0590 | Val Loss: 0.1504\n",
            "⏹️ Early stopping.\n",
            "Evaluation Metrics:\n",
            "pixel_accuracy: 0.9673963386781754\n",
            "precision: [0.97641773 0.91907462 0.91472293 0.89861079]\n",
            "recall: [0.98642026 0.89813355 0.84023131 0.69130651]\n",
            "f1_score: [0.98139351 0.90848342 0.87589616 0.78144377]\n",
            "iou: [0.96346678 0.83231299 0.77919507 0.6412866 ]\n",
            "dice_score: [0.98139351 0.90848342 0.87589616 0.78144377]\n",
            "Total params: 4,136,820\n",
            "Model size: 15.78 MB\n"
          ]
        }
      ],
      "source": [
        "#run training\n",
        "!python train.py \\\n",
        "  --model deeplabv3plus_mit_b0\\\n",
        "  --data-dir data \\\n",
        "  --output-dir /content/Finaldraft/outputs \\\n",
        "  --img-size 640 \\\n",
        "  --batch-size 8 \\\n",
        "  --epochs 80 \\\n",
        "  --lr 1e-4 \\\n",
        "  --patience 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGVqN8j2pQ3_",
        "outputId": "d33bd646-7e1b-45a7-8822-c6d9cdc2226d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:111: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "Epoch 1/80 - Train Loss: 0.9631 | Val Loss: 0.7701\n",
            "✔️ Best model saved at epoch 1\n",
            "Epoch 2/80 - Train Loss: 0.8373 | Val Loss: 0.7106\n",
            "✔️ Best model saved at epoch 2\n",
            "Epoch 3/80 - Train Loss: 0.7874 | Val Loss: 0.7926\n",
            "Epoch 4/80 - Train Loss: 0.7467 | Val Loss: 0.6316\n",
            "✔️ Best model saved at epoch 4\n",
            "Epoch 5/80 - Train Loss: 0.7197 | Val Loss: 0.6066\n",
            "✔️ Best model saved at epoch 5\n",
            "Epoch 6/80 - Train Loss: 0.6934 | Val Loss: 0.6624\n",
            "Epoch 7/80 - Train Loss: 0.6693 | Val Loss: 0.5540\n",
            "✔️ Best model saved at epoch 7\n",
            "Epoch 8/80 - Train Loss: 0.6447 | Val Loss: 0.5333\n",
            "✔️ Best model saved at epoch 8\n",
            "Epoch 9/80 - Train Loss: 0.6313 | Val Loss: 0.5298\n",
            "✔️ Best model saved at epoch 9\n",
            "Epoch 10/80 - Train Loss: 0.6192 | Val Loss: 0.5338\n",
            "Epoch 11/80 - Train Loss: 0.6125 | Val Loss: 0.4953\n",
            "✔️ Best model saved at epoch 11\n",
            "Epoch 12/80 - Train Loss: 0.5930 | Val Loss: 0.4992\n",
            "Epoch 13/80 - Train Loss: 0.5914 | Val Loss: 0.4764\n",
            "✔️ Best model saved at epoch 13\n",
            "Epoch 14/80 - Train Loss: 0.5810 | Val Loss: 0.4905\n",
            "Epoch 15/80 - Train Loss: 0.5712 | Val Loss: 0.4804\n",
            "Epoch 16/80 - Train Loss: 0.5673 | Val Loss: 0.4820\n",
            "Epoch 17/80 - Train Loss: 0.5578 | Val Loss: 0.4774\n",
            "Epoch 18/80 - Train Loss: 0.5566 | Val Loss: 0.4631\n",
            "✔️ Best model saved at epoch 18\n",
            "Epoch 19/80 - Train Loss: 0.5633 | Val Loss: 0.4661\n",
            "Epoch 20/80 - Train Loss: 0.5413 | Val Loss: 0.4639\n",
            "Epoch 21/80 - Train Loss: 0.5442 | Val Loss: 0.4423\n",
            "✔️ Best model saved at epoch 21\n",
            "Epoch 22/80 - Train Loss: 0.5432 | Val Loss: 0.4387\n",
            "✔️ Best model saved at epoch 22\n",
            "Epoch 23/80 - Train Loss: 0.5336 | Val Loss: 0.4457\n",
            "Epoch 24/80 - Train Loss: 0.5238 | Val Loss: 0.4513\n",
            "Epoch 25/80 - Train Loss: 0.5268 | Val Loss: 0.4650\n",
            "Epoch 26/80 - Train Loss: 0.5174 | Val Loss: 0.4191\n",
            "✔️ Best model saved at epoch 26\n",
            "Epoch 27/80 - Train Loss: 0.5173 | Val Loss: 0.5252\n",
            "Epoch 28/80 - Train Loss: 0.5265 | Val Loss: 0.4386\n",
            "Epoch 29/80 - Train Loss: 0.5181 | Val Loss: 0.4227\n",
            "Epoch 30/80 - Train Loss: 0.5043 | Val Loss: 0.4478\n",
            "Epoch 31/80 - Train Loss: 0.5048 | Val Loss: 0.4492\n",
            "Epoch 32/80 - Train Loss: 0.5148 | Val Loss: 0.4179\n",
            "✔️ Best model saved at epoch 32\n",
            "Epoch 33/80 - Train Loss: 0.5099 | Val Loss: 0.4271\n",
            "Epoch 34/80 - Train Loss: 0.5025 | Val Loss: 0.4125\n",
            "✔️ Best model saved at epoch 34\n",
            "Epoch 35/80 - Train Loss: 0.4843 | Val Loss: 0.4140\n",
            "Epoch 36/80 - Train Loss: 0.4915 | Val Loss: 0.4269\n",
            "Epoch 37/80 - Train Loss: 0.4947 | Val Loss: 0.4048\n",
            "✔️ Best model saved at epoch 37\n",
            "Epoch 38/80 - Train Loss: 0.4723 | Val Loss: 0.4328\n",
            "Epoch 39/80 - Train Loss: 0.4812 | Val Loss: 0.4098\n",
            "Epoch 40/80 - Train Loss: 0.4804 | Val Loss: 0.4480\n",
            "Epoch 41/80 - Train Loss: 0.4782 | Val Loss: 0.4220\n",
            "Epoch 42/80 - Train Loss: 0.4630 | Val Loss: 0.3982\n",
            "✔️ Best model saved at epoch 42\n",
            "Epoch 43/80 - Train Loss: 0.4657 | Val Loss: 0.4018\n",
            "Epoch 44/80 - Train Loss: 0.4595 | Val Loss: 0.4212\n",
            "Epoch 45/80 - Train Loss: 0.4540 | Val Loss: 0.3811\n",
            "✔️ Best model saved at epoch 45\n",
            "Epoch 46/80 - Train Loss: 0.4542 | Val Loss: 0.3641\n",
            "✔️ Best model saved at epoch 46\n",
            "Epoch 47/80 - Train Loss: 0.4372 | Val Loss: 0.3813\n",
            "Epoch 48/80 - Train Loss: 0.4479 | Val Loss: 0.4576\n",
            "Epoch 49/80 - Train Loss: 0.4565 | Val Loss: 0.3601\n",
            "✔️ Best model saved at epoch 49\n",
            "Epoch 50/80 - Train Loss: 0.4226 | Val Loss: 0.3608\n",
            "Epoch 51/80 - Train Loss: 0.4368 | Val Loss: 0.3555\n",
            "✔️ Best model saved at epoch 51\n",
            "Epoch 52/80 - Train Loss: 0.4200 | Val Loss: 0.3507\n",
            "✔️ Best model saved at epoch 52\n",
            "Epoch 53/80 - Train Loss: 0.4135 | Val Loss: 0.3487\n",
            "✔️ Best model saved at epoch 53\n",
            "Epoch 54/80 - Train Loss: 0.4157 | Val Loss: 0.3604\n",
            "Epoch 55/80 - Train Loss: 0.4005 | Val Loss: 0.3578\n",
            "Epoch 56/80 - Train Loss: 0.4031 | Val Loss: 0.3448\n",
            "✔️ Best model saved at epoch 56\n",
            "Epoch 57/80 - Train Loss: 0.4020 | Val Loss: 0.3343\n",
            "✔️ Best model saved at epoch 57\n",
            "Epoch 58/80 - Train Loss: 0.3816 | Val Loss: 0.3518\n",
            "Epoch 59/80 - Train Loss: 0.3975 | Val Loss: 0.3547\n",
            "Epoch 60/80 - Train Loss: 0.3950 | Val Loss: 0.3494\n",
            "Epoch 61/80 - Train Loss: 0.3968 | Val Loss: 0.3563\n",
            "Epoch 62/80 - Train Loss: 0.3824 | Val Loss: 0.3368\n",
            "Epoch 63/80 - Train Loss: 0.3817 | Val Loss: 0.3472\n",
            "Epoch 64/80 - Train Loss: 0.3680 | Val Loss: 0.3338\n",
            "✔️ Best model saved at epoch 64\n",
            "Epoch 65/80 - Train Loss: 0.3809 | Val Loss: 0.3248\n",
            "✔️ Best model saved at epoch 65\n",
            "Epoch 66/80 - Train Loss: 0.3737 | Val Loss: 0.3280\n",
            "Epoch 67/80 - Train Loss: 0.3541 | Val Loss: 0.3329\n",
            "Epoch 68/80 - Train Loss: 0.3534 | Val Loss: 0.3189\n",
            "✔️ Best model saved at epoch 68\n",
            "Epoch 69/80 - Train Loss: 0.3441 | Val Loss: 0.3201\n",
            "Epoch 70/80 - Train Loss: 0.3519 | Val Loss: 0.2909\n",
            "✔️ Best model saved at epoch 70\n",
            "Epoch 71/80 - Train Loss: 0.3526 | Val Loss: 0.3133\n",
            "Epoch 72/80 - Train Loss: 0.3389 | Val Loss: 0.3041\n",
            "Epoch 73/80 - Train Loss: 0.3412 | Val Loss: 0.3101\n",
            "Epoch 74/80 - Train Loss: 0.3425 | Val Loss: 0.3071\n",
            "Epoch 75/80 - Train Loss: 0.3253 | Val Loss: 0.3090\n",
            "Epoch 76/80 - Train Loss: 0.3307 | Val Loss: 0.2796\n",
            "✔️ Best model saved at epoch 76\n",
            "Epoch 77/80 - Train Loss: 0.3441 | Val Loss: 0.2957\n",
            "Epoch 78/80 - Train Loss: 0.3210 | Val Loss: 0.3132\n",
            "Epoch 79/80 - Train Loss: 0.3170 | Val Loss: 0.2870\n",
            "Epoch 80/80 - Train Loss: 0.3167 | Val Loss: 0.2750\n",
            "✔️ Best model saved at epoch 80\n",
            "Evaluation Metrics:\n",
            "pixel_accuracy: 0.9126531194871472\n",
            "precision: [0.94267692 0.7513983  0.7541884  0.59529892]\n",
            "recall: [0.95668195 0.70619316 0.65967758 0.53428303]\n",
            "f1_score: [0.94962779 0.72809474 0.70377417 0.56314304]\n",
            "iou: [0.90408695 0.57244417 0.54294102 0.39192701]\n",
            "dice_score: [0.94962779 0.72809474 0.70377417 0.56314304]\n",
            "Total params: 15,112,876\n",
            "Model size: 57.65 MB\n"
          ]
        }
      ],
      "source": [
        "#run training\n",
        "!python train.py \\\n",
        "  --model unet_mobilenet \\\n",
        "  --data-dir data \\\n",
        "  --output-dir /content/Finaldraft/outputs \\\n",
        "  --img-size 640 \\\n",
        "  --batch-size 8 \\\n",
        "  --epochs 80 \\\n",
        "  --lr 1e-4 \\\n",
        "  --patience 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxTaOCBagorJ",
        "outputId": "b9a0bbd9-6e8c-44aa-edb6-08ed61e7726a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:111: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "Epoch 1/80 - Train Loss: 0.7070 | Val Loss: 0.5121\n",
            "✔️ Best model saved at epoch 1\n",
            "Epoch 2/80 - Train Loss: 0.5713 | Val Loss: 0.4667\n",
            "✔️ Best model saved at epoch 2\n",
            "Epoch 3/80 - Train Loss: 0.5536 | Val Loss: 0.4906\n",
            "Epoch 4/80 - Train Loss: 0.5562 | Val Loss: 0.4748\n",
            "Epoch 5/80 - Train Loss: 0.5303 | Val Loss: 0.4971\n",
            "Epoch 6/80 - Train Loss: 0.5384 | Val Loss: 0.5013\n",
            "Epoch 7/80 - Train Loss: 0.5359 | Val Loss: 0.4401\n",
            "✔️ Best model saved at epoch 7\n",
            "Epoch 8/80 - Train Loss: 0.5174 | Val Loss: 0.4283\n",
            "✔️ Best model saved at epoch 8\n",
            "Epoch 9/80 - Train Loss: 0.5230 | Val Loss: 0.4904\n",
            "Epoch 10/80 - Train Loss: 0.5031 | Val Loss: 0.4294\n",
            "Epoch 11/80 - Train Loss: 0.5000 | Val Loss: 0.4068\n",
            "✔️ Best model saved at epoch 11\n",
            "Epoch 12/80 - Train Loss: 0.4887 | Val Loss: 0.4066\n",
            "✔️ Best model saved at epoch 12\n",
            "Epoch 13/80 - Train Loss: 0.5011 | Val Loss: 0.4238\n",
            "Epoch 14/80 - Train Loss: 0.4871 | Val Loss: 0.4681\n",
            "Epoch 15/80 - Train Loss: 0.4750 | Val Loss: 0.3883\n",
            "✔️ Best model saved at epoch 15\n",
            "Epoch 16/80 - Train Loss: 0.4630 | Val Loss: 0.3968\n",
            "Epoch 17/80 - Train Loss: 0.4517 | Val Loss: 0.3952\n",
            "Epoch 18/80 - Train Loss: 0.4506 | Val Loss: 0.4082\n",
            "Epoch 19/80 - Train Loss: 0.4454 | Val Loss: 0.3582\n",
            "✔️ Best model saved at epoch 19\n",
            "Epoch 20/80 - Train Loss: 0.4475 | Val Loss: 0.3537\n",
            "✔️ Best model saved at epoch 20\n",
            "Epoch 21/80 - Train Loss: 0.4176 | Val Loss: 0.3889\n",
            "Epoch 22/80 - Train Loss: 0.4184 | Val Loss: 0.3539\n",
            "Epoch 23/80 - Train Loss: 0.4084 | Val Loss: 0.3341\n",
            "✔️ Best model saved at epoch 23\n",
            "Epoch 24/80 - Train Loss: 0.4110 | Val Loss: 0.3660\n",
            "Epoch 25/80 - Train Loss: 0.4021 | Val Loss: 0.3804\n",
            "Epoch 26/80 - Train Loss: 0.3955 | Val Loss: 0.3418\n",
            "Epoch 27/80 - Train Loss: 0.3920 | Val Loss: 0.3221\n",
            "✔️ Best model saved at epoch 27\n",
            "Epoch 28/80 - Train Loss: 0.3889 | Val Loss: 0.3277\n",
            "Epoch 29/80 - Train Loss: 0.3945 | Val Loss: 0.3261\n",
            "Epoch 30/80 - Train Loss: 0.3769 | Val Loss: 0.3437\n",
            "Epoch 31/80 - Train Loss: 0.3804 | Val Loss: 0.3471\n",
            "Epoch 32/80 - Train Loss: 0.3658 | Val Loss: 0.3262\n",
            "Epoch 33/80 - Train Loss: 0.3863 | Val Loss: 0.3063\n",
            "✔️ Best model saved at epoch 33\n",
            "Epoch 34/80 - Train Loss: 0.3641 | Val Loss: 0.2976\n",
            "✔️ Best model saved at epoch 34\n",
            "Epoch 35/80 - Train Loss: 0.3647 | Val Loss: 0.2976\n",
            "Epoch 36/80 - Train Loss: 0.3619 | Val Loss: 0.3002\n",
            "Epoch 37/80 - Train Loss: 0.3617 | Val Loss: 0.3463\n",
            "Epoch 38/80 - Train Loss: 0.3527 | Val Loss: 0.2901\n",
            "✔️ Best model saved at epoch 38\n",
            "Epoch 39/80 - Train Loss: 0.3410 | Val Loss: 0.2861\n",
            "✔️ Best model saved at epoch 39\n",
            "Epoch 40/80 - Train Loss: 0.3319 | Val Loss: 0.3045\n",
            "Epoch 41/80 - Train Loss: 0.3493 | Val Loss: 0.3952\n",
            "Epoch 42/80 - Train Loss: 0.3450 | Val Loss: 0.3070\n",
            "Epoch 43/80 - Train Loss: 0.3482 | Val Loss: 0.2797\n",
            "✔️ Best model saved at epoch 43\n",
            "Epoch 44/80 - Train Loss: 0.3396 | Val Loss: 0.2826\n",
            "Epoch 45/80 - Train Loss: 0.3335 | Val Loss: 0.2729\n",
            "✔️ Best model saved at epoch 45\n",
            "Epoch 46/80 - Train Loss: 0.3227 | Val Loss: 0.2923\n",
            "Epoch 47/80 - Train Loss: 0.3342 | Val Loss: 0.2875\n",
            "Epoch 48/80 - Train Loss: 0.3206 | Val Loss: 0.2772\n",
            "Epoch 49/80 - Train Loss: 0.3203 | Val Loss: 0.2836\n",
            "Epoch 50/80 - Train Loss: 0.3218 | Val Loss: 0.3034\n",
            "Epoch 51/80 - Train Loss: 0.3288 | Val Loss: 0.2942\n",
            "Epoch 52/80 - Train Loss: 0.2986 | Val Loss: 0.2785\n",
            "Epoch 53/80 - Train Loss: 0.3018 | Val Loss: 0.2628\n",
            "✔️ Best model saved at epoch 53\n",
            "Epoch 54/80 - Train Loss: 0.3107 | Val Loss: 0.2521\n",
            "✔️ Best model saved at epoch 54\n",
            "Epoch 55/80 - Train Loss: 0.3115 | Val Loss: 0.2861\n",
            "Epoch 56/80 - Train Loss: 0.2964 | Val Loss: 0.2675\n",
            "Epoch 57/80 - Train Loss: 0.3079 | Val Loss: 0.3076\n",
            "Epoch 58/80 - Train Loss: 0.3063 | Val Loss: 0.3169\n",
            "Epoch 59/80 - Train Loss: 0.2904 | Val Loss: 0.2660\n",
            "Epoch 60/80 - Train Loss: 0.2897 | Val Loss: 0.2895\n",
            "Epoch 61/80 - Train Loss: 0.2911 | Val Loss: 0.3179\n",
            "Epoch 62/80 - Train Loss: 0.2967 | Val Loss: 0.2875\n",
            "Epoch 63/80 - Train Loss: 0.2870 | Val Loss: 0.2709\n",
            "Epoch 64/80 - Train Loss: 0.3015 | Val Loss: 0.2555\n",
            "Epoch 65/80 - Train Loss: 0.2912 | Val Loss: 0.2655\n",
            "Epoch 66/80 - Train Loss: 0.2858 | Val Loss: 0.2722\n",
            "Epoch 67/80 - Train Loss: 0.2750 | Val Loss: 0.2882\n",
            "Epoch 68/80 - Train Loss: 0.2685 | Val Loss: 0.2496\n",
            "✔️ Best model saved at epoch 68\n",
            "Epoch 69/80 - Train Loss: 0.2718 | Val Loss: 0.2464\n",
            "✔️ Best model saved at epoch 69\n",
            "Epoch 70/80 - Train Loss: 0.2836 | Val Loss: 0.2419\n",
            "✔️ Best model saved at epoch 70\n",
            "Epoch 71/80 - Train Loss: 0.2724 | Val Loss: 0.2488\n",
            "Epoch 72/80 - Train Loss: 0.2750 | Val Loss: 0.2450\n",
            "Epoch 73/80 - Train Loss: 0.2717 | Val Loss: 0.2529\n",
            "Epoch 74/80 - Train Loss: 0.2783 | Val Loss: 0.2434\n",
            "Epoch 75/80 - Train Loss: 0.2685 | Val Loss: 0.2457\n",
            "Epoch 76/80 - Train Loss: 0.2730 | Val Loss: 0.2473\n",
            "Epoch 77/80 - Train Loss: 0.2667 | Val Loss: 0.2637\n",
            "Epoch 78/80 - Train Loss: 0.2563 | Val Loss: 0.2353\n",
            "✔️ Best model saved at epoch 78\n",
            "Epoch 79/80 - Train Loss: 0.2574 | Val Loss: 0.2717\n",
            "Epoch 80/80 - Train Loss: 0.2585 | Val Loss: 0.2535\n",
            "Evaluation Metrics:\n",
            "pixel_accuracy: 0.9063116651965726\n",
            "precision: [0.944987   0.71820664 0.66277347 0.68465338]\n",
            "recall: [0.94617114 0.67076235 0.73608916 0.80017686]\n",
            "f1_score: [0.9455787  0.69367419 0.69751004 0.7379211 ]\n",
            "iou: [0.89677504 0.53101164 0.53552048 0.58468699]\n",
            "dice_score: [0.9455787  0.69367419 0.69751004 0.7379211 ]\n",
            "Total params: 13,043,204\n",
            "Model size: 49.76 MB\n"
          ]
        }
      ],
      "source": [
        "#run training\n",
        "!python train.py \\\n",
        "  --model resunet \\\n",
        "  --data-dir data \\\n",
        "  --output-dir /content/Finaldraft/outputs \\\n",
        "  --img-size 640 \\\n",
        "  --batch-size 8 \\\n",
        "  --epochs 80 \\\n",
        "  --lr 1e-4 \\\n",
        "  --patience 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxbudqkogzlC",
        "outputId": "9eb98b8c-c59e-4625-851f-7d6f422062e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:111: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "Epoch 1/80 - Train Loss: 1.0666 | Val Loss: 1.2335\n",
            "✔️ Best model saved at epoch 1\n",
            "Epoch 2/80 - Train Loss: 0.9335 | Val Loss: 0.8939\n",
            "✔️ Best model saved at epoch 2\n",
            "Epoch 3/80 - Train Loss: 0.8807 | Val Loss: 0.8372\n",
            "✔️ Best model saved at epoch 3\n",
            "Epoch 4/80 - Train Loss: 0.8447 | Val Loss: 0.8206\n",
            "✔️ Best model saved at epoch 4\n",
            "Epoch 5/80 - Train Loss: 0.8194 | Val Loss: 0.7715\n",
            "✔️ Best model saved at epoch 5\n",
            "Epoch 6/80 - Train Loss: 0.7965 | Val Loss: 0.7665\n",
            "✔️ Best model saved at epoch 6\n",
            "Epoch 7/80 - Train Loss: 0.7746 | Val Loss: 1.5040\n",
            "Epoch 8/80 - Train Loss: 0.7525 | Val Loss: 0.6304\n",
            "✔️ Best model saved at epoch 8\n",
            "Epoch 9/80 - Train Loss: 0.7257 | Val Loss: 0.6613\n",
            "Epoch 10/80 - Train Loss: 0.7163 | Val Loss: 0.6129\n",
            "✔️ Best model saved at epoch 10\n",
            "Epoch 11/80 - Train Loss: 0.6952 | Val Loss: 0.5895\n",
            "✔️ Best model saved at epoch 11\n",
            "Epoch 12/80 - Train Loss: 0.6776 | Val Loss: 0.5719\n",
            "✔️ Best model saved at epoch 12\n",
            "Epoch 13/80 - Train Loss: 0.6699 | Val Loss: 0.5609\n",
            "✔️ Best model saved at epoch 13\n",
            "Epoch 14/80 - Train Loss: 0.6478 | Val Loss: 0.5682\n",
            "Epoch 15/80 - Train Loss: 0.6349 | Val Loss: 0.5455\n",
            "✔️ Best model saved at epoch 15\n",
            "Epoch 16/80 - Train Loss: 0.6143 | Val Loss: 0.5214\n",
            "✔️ Best model saved at epoch 16\n",
            "Epoch 17/80 - Train Loss: 0.6076 | Val Loss: 0.5234\n",
            "Epoch 18/80 - Train Loss: 0.5865 | Val Loss: 0.5018\n",
            "✔️ Best model saved at epoch 18\n",
            "Epoch 19/80 - Train Loss: 0.5784 | Val Loss: 0.4914\n",
            "✔️ Best model saved at epoch 19\n",
            "Epoch 20/80 - Train Loss: 0.5618 | Val Loss: 0.4790\n",
            "✔️ Best model saved at epoch 20\n",
            "Epoch 21/80 - Train Loss: 0.5674 | Val Loss: 0.4923\n",
            "Epoch 22/80 - Train Loss: 0.5482 | Val Loss: 0.4767\n",
            "✔️ Best model saved at epoch 22\n",
            "Epoch 23/80 - Train Loss: 0.5393 | Val Loss: 0.4651\n",
            "✔️ Best model saved at epoch 23\n",
            "Epoch 24/80 - Train Loss: 0.5343 | Val Loss: 0.4501\n",
            "✔️ Best model saved at epoch 24\n",
            "Epoch 25/80 - Train Loss: 0.5203 | Val Loss: 0.4333\n",
            "✔️ Best model saved at epoch 25\n",
            "Epoch 26/80 - Train Loss: 0.5443 | Val Loss: 0.4414\n",
            "Epoch 27/80 - Train Loss: 0.5093 | Val Loss: 0.4287\n",
            "✔️ Best model saved at epoch 27\n",
            "Epoch 28/80 - Train Loss: 0.5041 | Val Loss: 0.4122\n",
            "✔️ Best model saved at epoch 28\n",
            "Epoch 29/80 - Train Loss: 0.4901 | Val Loss: 0.4167\n",
            "Epoch 30/80 - Train Loss: 0.4921 | Val Loss: 0.3953\n",
            "✔️ Best model saved at epoch 30\n",
            "Epoch 31/80 - Train Loss: 0.4714 | Val Loss: 0.3719\n",
            "✔️ Best model saved at epoch 31\n",
            "Epoch 32/80 - Train Loss: 0.4722 | Val Loss: 0.3980\n",
            "Epoch 33/80 - Train Loss: 0.4460 | Val Loss: 0.4079\n",
            "Epoch 34/80 - Train Loss: 0.4460 | Val Loss: 0.3739\n",
            "Epoch 35/80 - Train Loss: 0.4338 | Val Loss: 0.4175\n",
            "Epoch 36/80 - Train Loss: 0.4233 | Val Loss: 0.3682\n",
            "✔️ Best model saved at epoch 36\n",
            "Epoch 37/80 - Train Loss: 0.4100 | Val Loss: 0.3745\n",
            "Epoch 38/80 - Train Loss: 0.4033 | Val Loss: 0.3242\n",
            "✔️ Best model saved at epoch 38\n",
            "Epoch 39/80 - Train Loss: 0.3967 | Val Loss: 0.3774\n",
            "Epoch 40/80 - Train Loss: 0.4072 | Val Loss: 0.3550\n",
            "Epoch 41/80 - Train Loss: 0.3781 | Val Loss: 0.3845\n",
            "Epoch 42/80 - Train Loss: 0.3779 | Val Loss: 0.3005\n",
            "✔️ Best model saved at epoch 42\n",
            "Epoch 43/80 - Train Loss: 0.3778 | Val Loss: 0.3264\n",
            "Epoch 44/80 - Train Loss: 0.3443 | Val Loss: 0.3555\n",
            "Epoch 45/80 - Train Loss: 0.3463 | Val Loss: 0.3228\n",
            "Epoch 46/80 - Train Loss: 0.3448 | Val Loss: 0.3305\n",
            "Epoch 47/80 - Train Loss: 0.3386 | Val Loss: 0.3066\n",
            "Epoch 48/80 - Train Loss: 0.3222 | Val Loss: 0.3127\n",
            "Epoch 49/80 - Train Loss: 0.3196 | Val Loss: 0.2937\n",
            "✔️ Best model saved at epoch 49\n",
            "Epoch 50/80 - Train Loss: 0.3112 | Val Loss: 0.3271\n",
            "Epoch 51/80 - Train Loss: 0.3087 | Val Loss: 0.2777\n",
            "✔️ Best model saved at epoch 51\n",
            "Epoch 52/80 - Train Loss: 0.2959 | Val Loss: 0.3000\n",
            "Epoch 53/80 - Train Loss: 0.2882 | Val Loss: 0.2761\n",
            "✔️ Best model saved at epoch 53\n",
            "Epoch 54/80 - Train Loss: 0.2888 | Val Loss: 0.2811\n",
            "Epoch 55/80 - Train Loss: 0.2867 | Val Loss: 0.2701\n",
            "✔️ Best model saved at epoch 55\n",
            "Epoch 56/80 - Train Loss: 0.2845 | Val Loss: 0.2800\n",
            "Epoch 57/80 - Train Loss: 0.2947 | Val Loss: 0.2409\n",
            "✔️ Best model saved at epoch 57\n",
            "Epoch 58/80 - Train Loss: 0.2666 | Val Loss: 0.2557\n",
            "Epoch 59/80 - Train Loss: 0.2606 | Val Loss: 0.2860\n",
            "Epoch 60/80 - Train Loss: 0.2681 | Val Loss: 0.2782\n",
            "Epoch 61/80 - Train Loss: 0.2599 | Val Loss: 0.2494\n",
            "Epoch 62/80 - Train Loss: 0.2480 | Val Loss: 0.2570\n",
            "Epoch 63/80 - Train Loss: 0.2433 | Val Loss: 0.2355\n",
            "✔️ Best model saved at epoch 63\n",
            "Epoch 64/80 - Train Loss: 0.2434 | Val Loss: 0.2472\n",
            "Epoch 65/80 - Train Loss: 0.2370 | Val Loss: 0.2349\n",
            "✔️ Best model saved at epoch 65\n",
            "Epoch 66/80 - Train Loss: 0.2369 | Val Loss: 0.2516\n",
            "Epoch 67/80 - Train Loss: 0.2306 | Val Loss: 0.2295\n",
            "✔️ Best model saved at epoch 67\n",
            "Epoch 68/80 - Train Loss: 0.2342 | Val Loss: 0.2511\n",
            "Epoch 69/80 - Train Loss: 0.2337 | Val Loss: 0.2829\n",
            "Epoch 70/80 - Train Loss: 0.2222 | Val Loss: 0.2436\n",
            "Epoch 71/80 - Train Loss: 0.2085 | Val Loss: 0.2031\n",
            "✔️ Best model saved at epoch 71\n",
            "Epoch 72/80 - Train Loss: 0.2211 | Val Loss: 0.2759\n",
            "Epoch 73/80 - Train Loss: 0.2049 | Val Loss: 0.2381\n",
            "Epoch 74/80 - Train Loss: 0.2267 | Val Loss: 0.2125\n",
            "Epoch 75/80 - Train Loss: 0.2014 | Val Loss: 0.2435\n",
            "Epoch 76/80 - Train Loss: 0.1964 | Val Loss: 0.2444\n",
            "Epoch 77/80 - Train Loss: 0.2050 | Val Loss: 0.2065\n",
            "Epoch 78/80 - Train Loss: 0.2038 | Val Loss: 0.2333\n",
            "Epoch 79/80 - Train Loss: 0.2105 | Val Loss: 0.2059\n",
            "Epoch 80/80 - Train Loss: 0.1960 | Val Loss: 0.2084\n",
            "Evaluation Metrics:\n",
            "pixel_accuracy: 0.9357565406060988\n",
            "precision: [0.97253531 0.77376388 0.72266017 0.78461055]\n",
            "recall: [0.95353994 0.86469126 0.78211989 0.8147049 ]\n",
            "f1_score: [0.96294395 0.81670452 0.75121528 0.79937458]\n",
            "iou: [0.92853609 0.69019492 0.60155708 0.66579848]\n",
            "dice_score: [0.96294395 0.81670452 0.75121528 0.79937458]\n",
            "Total params: 9,163,428\n",
            "Model size: 34.96 MB\n"
          ]
        }
      ],
      "source": [
        "#run training\n",
        "!python train.py \\\n",
        "  --model unetpp \\\n",
        "  --data-dir data \\\n",
        "  --output-dir /content/Finaldraft/outputs \\\n",
        "  --img-size 640 \\\n",
        "  --batch-size 8 \\\n",
        "  --epochs 80 \\\n",
        "  --lr 1e-4 \\\n",
        "  --patience 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jk4c3J0Fg4Wf",
        "outputId": "81ac715c-0057-4749-841b-fdf507055bda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:111: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "Epoch 1/80 - Train Loss: 0.9294 | Val Loss: 0.8540\n",
            "✔️ Best model saved at epoch 1\n",
            "Epoch 2/80 - Train Loss: 0.8993 | Val Loss: 0.8452\n",
            "✔️ Best model saved at epoch 2\n",
            "Epoch 3/80 - Train Loss: 0.8746 | Val Loss: 0.8361\n",
            "✔️ Best model saved at epoch 3\n",
            "Epoch 4/80 - Train Loss: 0.8612 | Val Loss: 0.8235\n",
            "✔️ Best model saved at epoch 4\n",
            "Epoch 5/80 - Train Loss: 0.8530 | Val Loss: 0.8435\n",
            "Epoch 6/80 - Train Loss: 0.8530 | Val Loss: 0.8127\n",
            "✔️ Best model saved at epoch 6\n",
            "Epoch 7/80 - Train Loss: 0.8562 | Val Loss: 0.8140\n",
            "Epoch 8/80 - Train Loss: 0.8399 | Val Loss: 0.8114\n",
            "✔️ Best model saved at epoch 8\n",
            "Epoch 9/80 - Train Loss: 0.8406 | Val Loss: 0.7972\n",
            "✔️ Best model saved at epoch 9\n",
            "Epoch 10/80 - Train Loss: 0.8399 | Val Loss: 0.7895\n",
            "✔️ Best model saved at epoch 10\n",
            "Epoch 11/80 - Train Loss: 0.8375 | Val Loss: 0.7943\n",
            "Epoch 12/80 - Train Loss: 0.8298 | Val Loss: 0.7713\n",
            "✔️ Best model saved at epoch 12\n",
            "Epoch 13/80 - Train Loss: 0.8185 | Val Loss: 0.7836\n",
            "Epoch 14/80 - Train Loss: 0.8161 | Val Loss: 0.7887\n",
            "Epoch 15/80 - Train Loss: 0.8233 | Val Loss: 0.7714\n",
            "Epoch 16/80 - Train Loss: 0.8171 | Val Loss: 0.7857\n",
            "Epoch 17/80 - Train Loss: 0.8149 | Val Loss: 0.7788\n",
            "Epoch 18/80 - Train Loss: 0.8090 | Val Loss: 0.7848\n",
            "Epoch 19/80 - Train Loss: 0.8085 | Val Loss: 0.7833\n",
            "Epoch 20/80 - Train Loss: 0.8117 | Val Loss: 0.7751\n",
            "Epoch 21/80 - Train Loss: 0.8137 | Val Loss: 0.7675\n",
            "✔️ Best model saved at epoch 21\n",
            "Epoch 22/80 - Train Loss: 0.8034 | Val Loss: 0.7639\n",
            "✔️ Best model saved at epoch 22\n",
            "Epoch 23/80 - Train Loss: 0.8021 | Val Loss: 0.7676\n",
            "Epoch 24/80 - Train Loss: 0.8041 | Val Loss: 0.7694\n",
            "Epoch 25/80 - Train Loss: 0.8041 | Val Loss: 0.7599\n",
            "✔️ Best model saved at epoch 25\n",
            "Epoch 26/80 - Train Loss: 0.8065 | Val Loss: 0.7762\n",
            "Epoch 27/80 - Train Loss: 0.7985 | Val Loss: 0.7624\n",
            "Epoch 28/80 - Train Loss: 0.7884 | Val Loss: 0.7604\n",
            "Epoch 29/80 - Train Loss: 0.7913 | Val Loss: 0.7645\n",
            "Epoch 30/80 - Train Loss: 0.7879 | Val Loss: 0.7581\n",
            "✔️ Best model saved at epoch 30\n",
            "Epoch 31/80 - Train Loss: 0.7959 | Val Loss: 0.7720\n",
            "Epoch 32/80 - Train Loss: 0.7982 | Val Loss: 0.7548\n",
            "✔️ Best model saved at epoch 32\n",
            "Epoch 33/80 - Train Loss: 0.7845 | Val Loss: 0.7563\n",
            "Epoch 34/80 - Train Loss: 0.7874 | Val Loss: 0.7573\n",
            "Epoch 35/80 - Train Loss: 0.7924 | Val Loss: 0.7659\n",
            "Epoch 36/80 - Train Loss: 0.7839 | Val Loss: 0.7563\n",
            "Epoch 37/80 - Train Loss: 0.7867 | Val Loss: 0.7533\n",
            "✔️ Best model saved at epoch 37\n",
            "Epoch 38/80 - Train Loss: 0.7838 | Val Loss: 0.7712\n",
            "Epoch 39/80 - Train Loss: 0.7849 | Val Loss: 0.7685\n",
            "Epoch 40/80 - Train Loss: 0.7786 | Val Loss: 0.7525\n",
            "✔️ Best model saved at epoch 40\n",
            "Epoch 41/80 - Train Loss: 0.7799 | Val Loss: 0.7799\n",
            "Epoch 42/80 - Train Loss: 0.7865 | Val Loss: 0.7491\n",
            "✔️ Best model saved at epoch 42\n",
            "Epoch 43/80 - Train Loss: 0.7836 | Val Loss: 0.7606\n",
            "Epoch 44/80 - Train Loss: 0.7777 | Val Loss: 0.7441\n",
            "✔️ Best model saved at epoch 44\n",
            "Epoch 45/80 - Train Loss: 0.7708 | Val Loss: 0.7635\n",
            "Epoch 46/80 - Train Loss: 0.7785 | Val Loss: 0.7588\n",
            "Epoch 47/80 - Train Loss: 0.7810 | Val Loss: 0.7635\n",
            "Epoch 48/80 - Train Loss: 0.7824 | Val Loss: 0.7645\n",
            "Epoch 49/80 - Train Loss: 0.7794 | Val Loss: 0.7547\n",
            "Epoch 50/80 - Train Loss: 0.7743 | Val Loss: 0.7565\n",
            "Epoch 51/80 - Train Loss: 0.7748 | Val Loss: 0.7632\n",
            "Epoch 52/80 - Train Loss: 0.7747 | Val Loss: 0.7772\n",
            "Epoch 53/80 - Train Loss: 0.7687 | Val Loss: 0.7409\n",
            "✔️ Best model saved at epoch 53\n",
            "Epoch 54/80 - Train Loss: 0.7613 | Val Loss: 0.7351\n",
            "✔️ Best model saved at epoch 54\n",
            "Epoch 55/80 - Train Loss: 0.7738 | Val Loss: 0.7530\n",
            "Epoch 56/80 - Train Loss: 0.7685 | Val Loss: 0.7598\n",
            "Epoch 57/80 - Train Loss: 0.7740 | Val Loss: 0.7473\n",
            "Epoch 58/80 - Train Loss: 0.7691 | Val Loss: 0.7473\n",
            "Epoch 59/80 - Train Loss: 0.7676 | Val Loss: 0.7731\n",
            "Epoch 60/80 - Train Loss: 0.7620 | Val Loss: 0.7513\n",
            "Epoch 61/80 - Train Loss: 0.7659 | Val Loss: 0.7491\n",
            "Epoch 62/80 - Train Loss: 0.7584 | Val Loss: 0.7557\n",
            "Epoch 63/80 - Train Loss: 0.7650 | Val Loss: 0.7364\n",
            "Epoch 64/80 - Train Loss: 0.7618 | Val Loss: 0.7526\n",
            "⏹️ Early stopping.\n",
            "Evaluation Metrics:\n",
            "pixel_accuracy: 0.8467122133316533\n",
            "precision: [0.96081034 0.58439372 0.32670496 0.65224792]\n",
            "recall: [0.85560113 0.83913891 0.73381846 0.65617435]\n",
            "f1_score: [0.90515879 0.68897263 0.45212038 0.65420524]\n",
            "iou: [0.82674893 0.52552116 0.29209015 0.48611071]\n",
            "dice_score: [0.90515879 0.68897263 0.45212038 0.65420524]\n",
            "Total params: 26,963,652\n",
            "Model size: 102.86 MB\n"
          ]
        }
      ],
      "source": [
        "#run training\n",
        "!python train.py \\\n",
        "  --model unet3plus \\\n",
        "  --data-dir data \\\n",
        "  --output-dir /content/Finaldraft/outputs \\\n",
        "  --img-size 640 \\\n",
        "  --batch-size 2 \\\n",
        "  --epochs 80 \\\n",
        "  --lr 1e-4 \\\n",
        "  --patience 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7MtDaYNa0HE",
        "outputId": "b3451c95-eae3-460c-da97-c9ac7f68f5de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:111: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "Epoch 1/80 - Train Loss: 0.8716 | Val Loss: 0.8039\n",
            "✔️ Best model saved at epoch 1\n",
            "Epoch 2/80 - Train Loss: 0.7827 | Val Loss: 0.6590\n",
            "✔️ Best model saved at epoch 2\n",
            "Epoch 3/80 - Train Loss: 0.7235 | Val Loss: 0.5989\n",
            "✔️ Best model saved at epoch 3\n",
            "Epoch 4/80 - Train Loss: 0.6821 | Val Loss: 0.5921\n",
            "✔️ Best model saved at epoch 4\n",
            "Epoch 5/80 - Train Loss: 0.6616 | Val Loss: 0.6133\n",
            "Epoch 6/80 - Train Loss: 0.6400 | Val Loss: 0.5437\n",
            "✔️ Best model saved at epoch 6\n",
            "Epoch 7/80 - Train Loss: 0.6248 | Val Loss: 0.5673\n",
            "Epoch 8/80 - Train Loss: 0.6284 | Val Loss: 0.5312\n",
            "✔️ Best model saved at epoch 8\n",
            "Epoch 9/80 - Train Loss: 0.5828 | Val Loss: 0.5150\n",
            "✔️ Best model saved at epoch 9\n",
            "Epoch 10/80 - Train Loss: 0.5643 | Val Loss: 0.4966\n",
            "✔️ Best model saved at epoch 10\n",
            "Epoch 11/80 - Train Loss: 0.5529 | Val Loss: 0.4738\n",
            "✔️ Best model saved at epoch 11\n",
            "Epoch 12/80 - Train Loss: 0.5493 | Val Loss: 0.4772\n",
            "Epoch 13/80 - Train Loss: 0.5385 | Val Loss: 0.4710\n",
            "✔️ Best model saved at epoch 13\n",
            "Epoch 14/80 - Train Loss: 0.5416 | Val Loss: 0.4822\n",
            "Epoch 15/80 - Train Loss: 0.5114 | Val Loss: 0.4580\n",
            "✔️ Best model saved at epoch 15\n",
            "Epoch 16/80 - Train Loss: 0.5043 | Val Loss: 0.5237\n",
            "Epoch 17/80 - Train Loss: 0.4947 | Val Loss: 0.4520\n",
            "✔️ Best model saved at epoch 17\n",
            "Epoch 18/80 - Train Loss: 0.4811 | Val Loss: 0.4647\n",
            "Epoch 19/80 - Train Loss: 0.4966 | Val Loss: 0.4328\n",
            "✔️ Best model saved at epoch 19\n",
            "Epoch 20/80 - Train Loss: 0.4604 | Val Loss: 0.4198\n",
            "✔️ Best model saved at epoch 20\n",
            "Epoch 21/80 - Train Loss: 0.4747 | Val Loss: 0.4084\n",
            "✔️ Best model saved at epoch 21\n",
            "Epoch 22/80 - Train Loss: 0.4573 | Val Loss: 0.4130\n",
            "Epoch 23/80 - Train Loss: 0.4582 | Val Loss: 0.4354\n",
            "Epoch 24/80 - Train Loss: 0.4457 | Val Loss: 0.4201\n",
            "Epoch 25/80 - Train Loss: 0.4133 | Val Loss: 0.3963\n",
            "✔️ Best model saved at epoch 25\n",
            "Epoch 26/80 - Train Loss: 0.4000 | Val Loss: 0.4187\n",
            "Epoch 27/80 - Train Loss: 0.4184 | Val Loss: 0.4053\n",
            "Epoch 28/80 - Train Loss: 0.4193 | Val Loss: 0.4133\n",
            "Epoch 29/80 - Train Loss: 0.3907 | Val Loss: 0.3732\n",
            "✔️ Best model saved at epoch 29\n",
            "Epoch 30/80 - Train Loss: 0.3981 | Val Loss: 0.3816\n",
            "Epoch 31/80 - Train Loss: 0.3907 | Val Loss: 0.3747\n",
            "Epoch 32/80 - Train Loss: 0.4096 | Val Loss: 0.3759\n",
            "Epoch 33/80 - Train Loss: 0.3869 | Val Loss: 0.3815\n",
            "Epoch 34/80 - Train Loss: 0.3785 | Val Loss: 0.3412\n",
            "✔️ Best model saved at epoch 34\n",
            "Epoch 35/80 - Train Loss: 0.3863 | Val Loss: 0.3580\n",
            "Epoch 36/80 - Train Loss: 0.3649 | Val Loss: 0.3651\n",
            "Epoch 37/80 - Train Loss: 0.3685 | Val Loss: 0.3796\n",
            "Epoch 38/80 - Train Loss: 0.3713 | Val Loss: 0.3581\n",
            "Epoch 39/80 - Train Loss: 0.3597 | Val Loss: 0.3796\n",
            "Epoch 40/80 - Train Loss: 0.3361 | Val Loss: 0.3601\n",
            "Epoch 41/80 - Train Loss: 0.3589 | Val Loss: 0.3418\n",
            "Epoch 42/80 - Train Loss: 0.3520 | Val Loss: 0.3294\n",
            "✔️ Best model saved at epoch 42\n",
            "Epoch 43/80 - Train Loss: 0.3305 | Val Loss: 0.3430\n",
            "Epoch 44/80 - Train Loss: 0.3053 | Val Loss: 0.3180\n",
            "✔️ Best model saved at epoch 44\n",
            "Epoch 45/80 - Train Loss: 0.3133 | Val Loss: 0.3374\n",
            "Epoch 46/80 - Train Loss: 0.3035 | Val Loss: 0.3372\n",
            "Epoch 47/80 - Train Loss: 0.3341 | Val Loss: 0.3400\n",
            "Epoch 48/80 - Train Loss: 0.3067 | Val Loss: 0.3323\n",
            "Epoch 49/80 - Train Loss: 0.2976 | Val Loss: 0.3080\n",
            "✔️ Best model saved at epoch 49\n",
            "Epoch 50/80 - Train Loss: 0.2822 | Val Loss: 0.4016\n",
            "Epoch 51/80 - Train Loss: 0.2960 | Val Loss: 0.3123\n",
            "Epoch 52/80 - Train Loss: 0.2911 | Val Loss: 0.3076\n",
            "✔️ Best model saved at epoch 52\n",
            "Epoch 53/80 - Train Loss: 0.2892 | Val Loss: 0.3103\n",
            "Epoch 54/80 - Train Loss: 0.2860 | Val Loss: 0.3051\n",
            "✔️ Best model saved at epoch 54\n",
            "Epoch 55/80 - Train Loss: 0.2762 | Val Loss: 0.3021\n",
            "✔️ Best model saved at epoch 55\n",
            "Epoch 56/80 - Train Loss: 0.2663 | Val Loss: 0.2923\n",
            "✔️ Best model saved at epoch 56\n",
            "Epoch 57/80 - Train Loss: 0.2844 | Val Loss: 0.3144\n",
            "Epoch 58/80 - Train Loss: 0.3000 | Val Loss: 0.3036\n",
            "Epoch 59/80 - Train Loss: 0.2560 | Val Loss: 0.3197\n",
            "Epoch 60/80 - Train Loss: 0.2512 | Val Loss: 0.3237\n",
            "Epoch 61/80 - Train Loss: 0.2510 | Val Loss: 0.2945\n",
            "Epoch 62/80 - Train Loss: 0.2791 | Val Loss: 0.3521\n",
            "Epoch 63/80 - Train Loss: 0.2930 | Val Loss: 0.3267\n",
            "Epoch 64/80 - Train Loss: 0.2536 | Val Loss: 0.2938\n",
            "Epoch 65/80 - Train Loss: 0.2447 | Val Loss: 0.3045\n",
            "Epoch 66/80 - Train Loss: 0.2432 | Val Loss: 0.2949\n",
            "⏹️ Early stopping.\n",
            "Evaluation Metrics:\n",
            "pixel_accuracy: 0.9256722136466734\n",
            "precision: [0.97480677 0.71616671 0.72262778 0.7231781 ]\n",
            "recall: [0.93812326 0.91230901 0.75452388 0.71315059]\n",
            "f1_score: [0.95611328 0.80242564 0.73823146 0.71812934]\n",
            "iou: [0.9159167  0.67004244 0.58507677 0.56021981]\n",
            "dice_score: [0.95611328 0.80242564 0.73823146 0.71812934]\n",
            "Total params: 2,270,768\n",
            "Model size: 8.66 MB\n"
          ]
        }
      ],
      "source": [
        "#run training\n",
        "!python train.py \\\n",
        "  --model bisenetmulticlass \\\n",
        "  --data-dir data \\\n",
        "  --output-dir /content/Finaldraft/outputs \\\n",
        "  --img-size 640 \\\n",
        "  --batch-size 8 \\\n",
        "  --epochs 80 \\\n",
        "  --lr 1e-4 \\\n",
        "  --patience 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOG4o5h2ii4V",
        "outputId": "d1962200-7046-412d-8d73-6b1848fdd599"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:111: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "Epoch 1/80 - Train Loss: 0.9394 | Val Loss: 0.7740\n",
            "✔️ Best model saved at epoch 1\n",
            "Epoch 2/80 - Train Loss: 0.7705 | Val Loss: 0.6643\n",
            "✔️ Best model saved at epoch 2\n",
            "Epoch 3/80 - Train Loss: 0.7497 | Val Loss: 0.6281\n",
            "✔️ Best model saved at epoch 3\n",
            "Epoch 4/80 - Train Loss: 0.7186 | Val Loss: 0.6064\n",
            "✔️ Best model saved at epoch 4\n",
            "Epoch 5/80 - Train Loss: 0.6813 | Val Loss: 0.5820\n",
            "✔️ Best model saved at epoch 5\n",
            "Epoch 6/80 - Train Loss: 0.6614 | Val Loss: 0.5658\n",
            "✔️ Best model saved at epoch 6\n",
            "Epoch 7/80 - Train Loss: 0.6688 | Val Loss: 0.6264\n",
            "Epoch 8/80 - Train Loss: 0.6529 | Val Loss: 0.5737\n",
            "Epoch 9/80 - Train Loss: 0.6348 | Val Loss: 0.5809\n",
            "Epoch 10/80 - Train Loss: 0.5923 | Val Loss: 0.5284\n",
            "✔️ Best model saved at epoch 10\n",
            "Epoch 11/80 - Train Loss: 0.5947 | Val Loss: 0.5919\n",
            "Epoch 12/80 - Train Loss: 0.5710 | Val Loss: 0.5161\n",
            "✔️ Best model saved at epoch 12\n",
            "Epoch 13/80 - Train Loss: 0.5776 | Val Loss: 0.5366\n",
            "Epoch 14/80 - Train Loss: 0.5612 | Val Loss: 0.5310\n",
            "Epoch 15/80 - Train Loss: 0.5504 | Val Loss: 0.5072\n",
            "✔️ Best model saved at epoch 15\n",
            "Epoch 16/80 - Train Loss: 0.5530 | Val Loss: 0.4793\n",
            "✔️ Best model saved at epoch 16\n",
            "Epoch 17/80 - Train Loss: 0.5541 | Val Loss: 0.4877\n",
            "Epoch 18/80 - Train Loss: 0.5687 | Val Loss: 0.4826\n",
            "Epoch 19/80 - Train Loss: 0.5288 | Val Loss: 0.4872\n",
            "Epoch 20/80 - Train Loss: 0.5225 | Val Loss: 0.5746\n",
            "Epoch 21/80 - Train Loss: 0.4929 | Val Loss: 0.4466\n",
            "✔️ Best model saved at epoch 21\n",
            "Epoch 22/80 - Train Loss: 0.4854 | Val Loss: 0.4713\n",
            "Epoch 23/80 - Train Loss: 0.4914 | Val Loss: 0.4485\n",
            "Epoch 24/80 - Train Loss: 0.4935 | Val Loss: 0.4614\n",
            "Epoch 25/80 - Train Loss: 0.4729 | Val Loss: 0.4546\n",
            "Epoch 26/80 - Train Loss: 0.4504 | Val Loss: 0.4539\n",
            "Epoch 27/80 - Train Loss: 0.4666 | Val Loss: 0.4484\n",
            "Epoch 28/80 - Train Loss: 0.4521 | Val Loss: 0.4352\n",
            "✔️ Best model saved at epoch 28\n",
            "Epoch 29/80 - Train Loss: 0.4375 | Val Loss: 0.4443\n",
            "Epoch 30/80 - Train Loss: 0.4337 | Val Loss: 0.4225\n",
            "✔️ Best model saved at epoch 30\n",
            "Epoch 31/80 - Train Loss: 0.4618 | Val Loss: 0.4168\n",
            "✔️ Best model saved at epoch 31\n",
            "Epoch 32/80 - Train Loss: 0.4175 | Val Loss: 0.4174\n",
            "Epoch 33/80 - Train Loss: 0.4166 | Val Loss: 0.4332\n",
            "Epoch 34/80 - Train Loss: 0.3944 | Val Loss: 0.4068\n",
            "✔️ Best model saved at epoch 34\n",
            "Epoch 35/80 - Train Loss: 0.4078 | Val Loss: 0.4021\n",
            "✔️ Best model saved at epoch 35\n",
            "Epoch 36/80 - Train Loss: 0.4150 | Val Loss: 0.4127\n",
            "Epoch 37/80 - Train Loss: 0.3972 | Val Loss: 0.6800\n",
            "Epoch 38/80 - Train Loss: 0.3938 | Val Loss: 0.3929\n",
            "✔️ Best model saved at epoch 38\n",
            "Epoch 39/80 - Train Loss: 0.4062 | Val Loss: 0.4262\n",
            "Epoch 40/80 - Train Loss: 0.4037 | Val Loss: 0.3927\n",
            "✔️ Best model saved at epoch 40\n",
            "Epoch 41/80 - Train Loss: 0.3618 | Val Loss: 0.3855\n",
            "✔️ Best model saved at epoch 41\n",
            "Epoch 42/80 - Train Loss: 0.3713 | Val Loss: 0.4282\n",
            "Epoch 43/80 - Train Loss: 0.3628 | Val Loss: 0.4269\n",
            "Epoch 44/80 - Train Loss: 0.3578 | Val Loss: 0.4184\n",
            "Epoch 45/80 - Train Loss: 0.3504 | Val Loss: 0.3896\n",
            "Epoch 46/80 - Train Loss: 0.3624 | Val Loss: 0.4006\n",
            "Epoch 47/80 - Train Loss: 0.3372 | Val Loss: 0.3730\n",
            "✔️ Best model saved at epoch 47\n",
            "Epoch 48/80 - Train Loss: 0.3506 | Val Loss: 0.3833\n",
            "Epoch 49/80 - Train Loss: 0.3289 | Val Loss: 0.3643\n",
            "✔️ Best model saved at epoch 49\n",
            "Epoch 50/80 - Train Loss: 0.3459 | Val Loss: 0.4281\n",
            "Epoch 51/80 - Train Loss: 0.3315 | Val Loss: 0.3688\n",
            "Epoch 52/80 - Train Loss: 0.3116 | Val Loss: 0.3429\n",
            "✔️ Best model saved at epoch 52\n",
            "Epoch 53/80 - Train Loss: 0.3195 | Val Loss: 0.3663\n",
            "Epoch 54/80 - Train Loss: 0.2903 | Val Loss: 0.3303\n",
            "✔️ Best model saved at epoch 54\n",
            "Epoch 55/80 - Train Loss: 0.2862 | Val Loss: 0.4068\n",
            "Epoch 56/80 - Train Loss: 0.3403 | Val Loss: 0.5560\n",
            "Epoch 57/80 - Train Loss: 0.3728 | Val Loss: 0.4099\n",
            "Epoch 58/80 - Train Loss: 0.3185 | Val Loss: 0.4477\n",
            "Epoch 59/80 - Train Loss: 0.3350 | Val Loss: 0.4161\n",
            "Epoch 60/80 - Train Loss: 0.3099 | Val Loss: 0.3469\n",
            "Epoch 61/80 - Train Loss: 0.3081 | Val Loss: 0.3581\n",
            "Epoch 62/80 - Train Loss: 0.2834 | Val Loss: 0.3404\n",
            "Epoch 63/80 - Train Loss: 0.2573 | Val Loss: 0.3369\n",
            "Epoch 64/80 - Train Loss: 0.2535 | Val Loss: 0.3119\n",
            "✔️ Best model saved at epoch 64\n",
            "Epoch 65/80 - Train Loss: 0.2599 | Val Loss: 0.3333\n",
            "Epoch 66/80 - Train Loss: 0.2577 | Val Loss: 0.3092\n",
            "✔️ Best model saved at epoch 66\n",
            "Epoch 67/80 - Train Loss: 0.2760 | Val Loss: 0.3400\n",
            "Epoch 68/80 - Train Loss: 0.2578 | Val Loss: 0.3497\n",
            "Epoch 69/80 - Train Loss: 0.2637 | Val Loss: 0.3614\n",
            "Epoch 70/80 - Train Loss: 0.2489 | Val Loss: 0.3260\n",
            "Epoch 71/80 - Train Loss: 0.2419 | Val Loss: 0.3422\n",
            "Epoch 72/80 - Train Loss: 0.2256 | Val Loss: 0.3132\n",
            "Epoch 73/80 - Train Loss: 0.2353 | Val Loss: 0.3397\n",
            "Epoch 74/80 - Train Loss: 0.2270 | Val Loss: 0.3677\n",
            "Epoch 75/80 - Train Loss: 0.2356 | Val Loss: 0.3584\n",
            "Epoch 76/80 - Train Loss: 0.2328 | Val Loss: 0.3427\n",
            "⏹️ Early stopping.\n",
            "Evaluation Metrics:\n",
            "pixel_accuracy: 0.9119225089780746\n",
            "precision: [0.97390026 0.64889416 0.79682419 0.61069667]\n",
            "recall: [0.92442324 0.91786535 0.67520469 0.70848177]\n",
            "f1_score: [0.94851697 0.76029213 0.73099031 0.65596502]\n",
            "iou: [0.9020754  0.6132833  0.5760321  0.48805651]\n",
            "dice_score: [0.94851697 0.76029213 0.73099031 0.65596502]\n",
            "Total params: 7,786,528\n",
            "Model size: 29.70 MB\n"
          ]
        }
      ],
      "source": [
        "#run training\n",
        "!python train.py \\\n",
        "  --model stdc \\\n",
        "  --data-dir data \\\n",
        "  --output-dir /content/Finaldraft/outputs \\\n",
        "  --img-size 640 \\\n",
        "  --batch-size 8 \\\n",
        "  --epochs 80 \\\n",
        "  --lr 1e-4 \\\n",
        "  --patience 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjCJFag12qiM",
        "outputId": "fa503354-ff38-4b5f-9a75-ae049e8de0e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:111: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "Epoch 1/80 - Train Loss: 0.9403 | Val Loss: 0.7969\n",
            "✔️ Best model saved at epoch 1\n",
            "Epoch 2/80 - Train Loss: 0.8220 | Val Loss: 0.7918\n",
            "✔️ Best model saved at epoch 2\n",
            "Epoch 3/80 - Train Loss: 0.7719 | Val Loss: 0.6807\n",
            "✔️ Best model saved at epoch 3\n",
            "Epoch 4/80 - Train Loss: 0.7206 | Val Loss: 0.7647\n",
            "Epoch 5/80 - Train Loss: 0.6742 | Val Loss: 0.6800\n",
            "✔️ Best model saved at epoch 5\n",
            "Epoch 6/80 - Train Loss: 0.6813 | Val Loss: 0.5807\n",
            "✔️ Best model saved at epoch 6\n",
            "Epoch 7/80 - Train Loss: 0.6658 | Val Loss: 0.6086\n",
            "Epoch 8/80 - Train Loss: 0.6403 | Val Loss: 0.5511\n",
            "✔️ Best model saved at epoch 8\n",
            "Epoch 9/80 - Train Loss: 0.6578 | Val Loss: 0.6070\n",
            "Epoch 10/80 - Train Loss: 0.6205 | Val Loss: 0.5434\n",
            "✔️ Best model saved at epoch 10\n",
            "Epoch 11/80 - Train Loss: 0.6070 | Val Loss: 0.5383\n",
            "✔️ Best model saved at epoch 11\n",
            "Epoch 12/80 - Train Loss: 0.5707 | Val Loss: 0.5832\n",
            "Epoch 13/80 - Train Loss: 0.6036 | Val Loss: 0.5804\n",
            "Epoch 14/80 - Train Loss: 0.6296 | Val Loss: 0.5573\n",
            "Epoch 15/80 - Train Loss: 0.5956 | Val Loss: 0.5298\n",
            "✔️ Best model saved at epoch 15\n",
            "Epoch 16/80 - Train Loss: 0.5892 | Val Loss: 0.5065\n",
            "✔️ Best model saved at epoch 16\n",
            "Epoch 17/80 - Train Loss: 0.5818 | Val Loss: 0.5349\n",
            "Epoch 18/80 - Train Loss: 0.5470 | Val Loss: 0.4938\n",
            "✔️ Best model saved at epoch 18\n",
            "Epoch 19/80 - Train Loss: 0.5135 | Val Loss: 0.5345\n",
            "Epoch 20/80 - Train Loss: 0.5402 | Val Loss: 0.5030\n",
            "Epoch 21/80 - Train Loss: 0.5371 | Val Loss: 0.4677\n",
            "✔️ Best model saved at epoch 21\n",
            "Epoch 22/80 - Train Loss: 0.5204 | Val Loss: 0.4780\n",
            "Epoch 23/80 - Train Loss: 0.4900 | Val Loss: 0.5148\n",
            "Epoch 24/80 - Train Loss: 0.5059 | Val Loss: 0.4682\n",
            "Epoch 25/80 - Train Loss: 0.4733 | Val Loss: 0.4634\n",
            "✔️ Best model saved at epoch 25\n",
            "Epoch 26/80 - Train Loss: 0.4815 | Val Loss: 0.5099\n",
            "Epoch 27/80 - Train Loss: 0.4766 | Val Loss: 0.4396\n",
            "✔️ Best model saved at epoch 27\n",
            "Epoch 28/80 - Train Loss: 0.4627 | Val Loss: 0.4464\n",
            "Epoch 29/80 - Train Loss: 0.4656 | Val Loss: 0.4858\n",
            "Epoch 30/80 - Train Loss: 0.4467 | Val Loss: 0.4445\n",
            "Epoch 31/80 - Train Loss: 0.4275 | Val Loss: 0.4148\n",
            "✔️ Best model saved at epoch 31\n",
            "Epoch 32/80 - Train Loss: 0.4482 | Val Loss: 0.4521\n",
            "Epoch 33/80 - Train Loss: 0.4100 | Val Loss: 0.4477\n",
            "Epoch 34/80 - Train Loss: 0.4248 | Val Loss: 0.4030\n",
            "✔️ Best model saved at epoch 34\n",
            "Epoch 35/80 - Train Loss: 0.4220 | Val Loss: 0.4757\n",
            "Epoch 36/80 - Train Loss: 0.3844 | Val Loss: 0.5142\n",
            "Epoch 37/80 - Train Loss: 0.4062 | Val Loss: 0.4256\n",
            "Epoch 38/80 - Train Loss: 0.3894 | Val Loss: 0.3917\n",
            "✔️ Best model saved at epoch 38\n",
            "Epoch 39/80 - Train Loss: 0.3897 | Val Loss: 0.3692\n",
            "✔️ Best model saved at epoch 39\n",
            "Epoch 40/80 - Train Loss: 0.3777 | Val Loss: 0.3873\n",
            "Epoch 41/80 - Train Loss: 0.3619 | Val Loss: 0.3801\n",
            "Epoch 42/80 - Train Loss: 0.3934 | Val Loss: 0.4062\n",
            "Epoch 43/80 - Train Loss: 0.3881 | Val Loss: 0.3890\n",
            "Epoch 44/80 - Train Loss: 0.3644 | Val Loss: 0.3950\n",
            "Epoch 45/80 - Train Loss: 0.3146 | Val Loss: 0.3511\n",
            "✔️ Best model saved at epoch 45\n",
            "Epoch 46/80 - Train Loss: 0.3389 | Val Loss: 0.3510\n",
            "✔️ Best model saved at epoch 46\n",
            "Epoch 47/80 - Train Loss: 0.3322 | Val Loss: 0.3675\n",
            "Epoch 48/80 - Train Loss: 0.3035 | Val Loss: 0.3579\n",
            "Epoch 49/80 - Train Loss: 0.3214 | Val Loss: 0.3668\n",
            "Epoch 50/80 - Train Loss: 0.3360 | Val Loss: 0.3461\n",
            "✔️ Best model saved at epoch 50\n",
            "Epoch 51/80 - Train Loss: 0.3291 | Val Loss: 0.3486\n",
            "Epoch 52/80 - Train Loss: 0.3084 | Val Loss: 0.3464\n",
            "Epoch 53/80 - Train Loss: 0.3226 | Val Loss: 0.3443\n",
            "✔️ Best model saved at epoch 53\n",
            "Epoch 54/80 - Train Loss: 0.3046 | Val Loss: 0.4230\n",
            "Epoch 55/80 - Train Loss: 0.2956 | Val Loss: 0.3120\n",
            "✔️ Best model saved at epoch 55\n",
            "Epoch 56/80 - Train Loss: 0.2699 | Val Loss: 0.3194\n",
            "Epoch 57/80 - Train Loss: 0.2868 | Val Loss: 0.3441\n",
            "Epoch 58/80 - Train Loss: 0.2690 | Val Loss: 0.3602\n",
            "Epoch 59/80 - Train Loss: 0.2749 | Val Loss: 0.3293\n",
            "Epoch 60/80 - Train Loss: 0.2952 | Val Loss: 0.4141\n",
            "Epoch 61/80 - Train Loss: 0.2630 | Val Loss: 0.3618\n",
            "Epoch 62/80 - Train Loss: 0.2636 | Val Loss: 0.3325\n",
            "Epoch 63/80 - Train Loss: 0.2930 | Val Loss: 0.4170\n",
            "Epoch 64/80 - Train Loss: 0.3490 | Val Loss: 0.3515\n",
            "Epoch 65/80 - Train Loss: 0.2646 | Val Loss: 0.3229\n",
            "⏹️ Early stopping.\n",
            "Evaluation Metrics:\n",
            "pixel_accuracy: 0.9110337583480342\n",
            "precision: [0.97387518 0.66210841 0.7087241  0.60231576]\n",
            "recall: [0.92214794 0.91722686 0.740533   0.62278122]\n",
            "f1_score: [0.94730594 0.76906231 0.72427947 0.61237754]\n",
            "iou: [0.89988724 0.62477761 0.56774149 0.44131424]\n",
            "dice_score: [0.94730594 0.76906231 0.72427947 0.61237754]\n",
            "Total params: 5,540,704\n",
            "Model size: 21.14 MB\n"
          ]
        }
      ],
      "source": [
        "#run training\n",
        "!python train.py \\\n",
        "  --model ddrnet \\\n",
        "  --data-dir data \\\n",
        "  --output-dir /content/Finaldraft/outputs \\\n",
        "  --img-size 640 \\\n",
        "  --batch-size 8 \\\n",
        "  --epochs 80 \\\n",
        "  --lr 1e-4 \\\n",
        "  --patience 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import shutil\n",
        "shutil.make_archive('/content/Finaldraft', 'zip', '/content/Finaldraft')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMeDAjB2vHHH"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download('/content/Finaldraft.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
